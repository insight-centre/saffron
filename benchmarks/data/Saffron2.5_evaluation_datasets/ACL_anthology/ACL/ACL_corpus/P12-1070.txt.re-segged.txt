Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics , pages 666?674,
Jeju , Republic of Korea , 814 July 2012. c?2012 Association for Computational Linguistics
MIX Is Not a Tree-Adjoining Language
Makoto Kanazawa
National Institute of Informatics
2?1?2 Hitotsubashi , Chiyoda-ku
Tokyo , 101?8430, Japan
kanazawa@nii.ac.jp
Sylvain Salvati
INRIA Bordeaux Sud-Ouest , LaBRI
351, Cours de la Libe?ration
F-33405 Talence Cedex , France
sylvain.salvati@labri.fr
Abstract
The language MIX consists of all strings over the three-letter alphabet { a , b , c } that contain an equal number of occurrences of each letter.
We prove Joshi?s (1985) conjecture that MIX is not a tree-adjoining language.
1 Introduction
The language
MIX = { w ? { a , b , c }? | | w|a = | w|b = | w|c } has attracted considerable attention in computational linguistics.1 This language was used by Bach (1981) in an exercise to show that the permutation closure of a contextfree language is not necessarily context-free.2 MIX may be considered a prototypical example of free word order language , but , as remarked by Bach (1981), it seems that no human language ? has such complete freedom for order ?, because ? typically , certain constituents act as ? boundary domains ? for scrambling ?. Joshi (1985) refers to MIX as representing ? an extreme case of the degree of free word order permitted in a language ?, which is ? linguistically not relevant ?. Gazdar (1988) adopts a similar position regarding the relation between MIX 1If w is a string and d is a symbol , we write | w|d to mean the number of occurrences of d in w . We will use the notation | w | to denote the length of w , i.e ., the total number of occurrences of symbols in w.
2According to Gazdar (1988), ? MIX was originally described by Emmon Bach and was so-dubbed by students in the 1983 Hampshire College Summer Studies in Mathematics?.
According to Bach (1988), the name MIX was ? the happy invention of Bill Marsh?.
and natural languages , noting that ? it seems rather unlikely that any natural language will turn out to have a MIX-like characteristic?.
It therefore seems natural to assume that languages such as MIX should be excluded from any class of formal languages that purports to be a tight formal characterization of the possible natural languages . It was in this spirit that Joshi et al (1991) suggested that MIX should not be in the class of socalled mildly context-sensitive languages : ?[ mildly context-sensitive grammars ] capture only certain kinds of dependencies , e.g ., nested dependencies and certain limited kinds of cross-serial dependencies ( for example , in the subordinate clause constructions in Dutch or some variations of them , but perhaps not in the socalled
MIX ( or Bach ) language ) . . . .?
Mild contextsensitivity is an informally defined notion first introduced by Joshi (1985); it consists of the three conditions of limited cross-serial dependencies , constant growth , and polynomial parsing.
The first condition is only vaguely formulated , but the other two conditions are clearly satisfied by tree-adjoining grammars . The suggestion of Joshi et al (1991) was that MIX should be regarded as a violation of the condition of limited cross-serial dependencies.
Joshi (1985) conjectured rather strongly that MIX is not a tree-adjoining language : ? TAGs cannot generate this language , although for TAGs the proof is not in hand yet ?. An even stronger conjecture was made by Marsh (1985), namely , that MIX is not an languages properly include the tree-adjoining languages .) Joshi et al (1991), however , expressed a more pessimistic view about the conjecture : ? It is not known whether TAG . . . can generate MIX . This has turned out to be a very difficult problem . In fact , it is not even known whether an IG [( indexed grammar )] can generate MIX .? This open question has become all the more pressing after a recent result by Salvati (2011). This result says that MIX is in the class of multiple contextfree languages ( Seki et al , 1991), or equivalently , languages of linear contextfree rewriting systems ( Vijay-Shanker et al , 1987; Weir , 1988), which has been customarily regarded as a formal counterpart of the informal notion of a mildly context-sensitive language.4 It means that either we have to abandon the identification of multiple contextfree languages with mildly context-sensitive languages , or we should revise our conception of limited cross-serial dependencies and stop regarding MIX-like languages as violations of this condition . Surely , the resolution of Joshi?s (1985) conjecture should crucially affect the choice between these two alternatives.
In this paper , we prove that MIX is not a tree-adjoining language . Our proof is cast in terms of the formalism of head grammar ( Pollard , 1984; Roach , 1987), which is known to be equivalent to TAG ( Vijay-Shanker and Weir , 1994). The key to our proof is the notion of an n-decomposition of a string over { a , b , c }, which is similar to the notion of a derivation in head grammars , but independent of any particular grammar . The parameter n indicates how unbalanced the occurrence counts of the three letters can be at any point in a decomposition . We first 3The relation of MIX with indexed languages is also of interest in combinatorial group theory . Gilman (2005) remarks that ? it does not . . . seem to be known whether or not the word problem of Z ? Z is indexed ?, alluding to the language O2 = { w ? { a , a ?, b , b ?}? | | w|a = | w|a ?, | w|b = | w|b ? }. Since O2 and MIX are rationally equivalent , O2 is indexed if and only if MIX is indexed ( Salvati , 2011).
4Joshi et al (1991) presented linear contextfree rewriting systems as mildly context-sensitive grammars . Groenink (1997) wrote ? The class of mildly context-sensitive languages seems to be most adequately approached by LCFRS .? show that if MIX is generated by some head grammar , then there is an n such that every string in MIX has an n-decomposition . We then prove that if every string in MIX has an n-decomposition , then every string in MIX must have a 2-decomposition . Finally , we exhibit a particular string in MIX that has no 2-decomposition . The length of this string is 87, and the fact that it has no 2-decomposition was first verified by a computer program accompanying this paper . We include here a rigorous , mathematical proof of this fact not relying on the computer verification.
2 Head Grammars
A head grammar is a quadruple G = ( N ,?, P , S ), where N is a finite set of nonterminals , ? is a finite set of terminal symbols ( alphabet ), S is a distinguished element of N , and P is a finite set of rules.
Each nonterminal is interpreted as a binary predicate on strings in ??. There are four types of rules:
A(x1x2y1, y2)? B(x1, x2),C(y1, y2)
A(x1, x2y1y2)? B(x1, x2),C(y1, y2)
A(x1y1, y2x2)? B(x1, x2),C(y1, y2)
A(w1,w2)?
Here , A , B,C ? N , x1, x2, y1, y2 are variables , and w1,w2 ? ? ? {?}.5 Rules of the first three types are binary rules and rules of the last type are terminating rules . This definition of a head grammar actually corresponds to a normal form for head grammars that appears in section 3.3 of Vijay-Shanker and Weir?s (1994) paper.6 The rules of head grammars are interpreted as implications from right to left , where variables can be instantiated to any terminal strings . Each binary 5We use ? to denote the empty string.
6This normal form is also mentioned in chapter 5, section 4 of Kracht?s (2003) book . The notation we use to express rules of head grammars is borrowed from elementary formal systems ( Smullyan , 1961; Arikawa et al , 1992), also known as literal movement grammars ( Groenink , 1997; Kracht , 2003), which are logic programs over strings . In Vijay-Shanker and Weir?s (1994) notation , the four rules are expressed as follows:
A ? C2,2(B,C)
A ? C1,2(B,C)
A ? W(B,C)
A ? C1,1(w1 ? w2) of strings to form a new pair . The operation involved in the third rule is known as wrapping ; the operations involved in the first two rules we call left concatenation and right concatenation , respectively.
If G = ( N ,?, P , S ) is a head grammar , A ? N , and w1,w2 ? ??, then we say that a fact A(w1,w2) is derivable and write ` G A(w1,w2), if A(w1,w2) can be inferred using the rules in P . More formally , we have ` G A(w1,w2) if one of the following conditions holds : ? A(w1,w2)? is a terminating rule in P.
? ` G B(u1, u2), ` G C(v1, v2), and there is a binary rule A(?1, ?2) ? B(x1, x2),C(y1, y2) in P such that ( w1,w2) is the result of substituting u1, u2, v1, v2 for x1, x2, y1, y2, respectively , in (?1, ?2).
The language of G is
L(G ) = { w1w2 | ` G S(w1,w2) }.
Example 1. Let G = ( N ,?, P , S ), where N = { S , A , A?,C,D , E , F }, ? = { a , a ?, #}, and P consists of the following rules:
S(x1y1, y2x2)? D(x1, x2),C(y1, y2)
C (?, #)?
D (?, ?)?
D(x1y1, y2x2)? F(x1, x2),D(y1, y2)
F(x1y1, y2x2)? A(x1, x2), E(y1, y2)
A(a , a ) ?
E(x1y1, y2x2)? D(x1, x2), A?(y1, y2)
A?(a ?, a?)?
We have L(G ) = { w#wR | w ? D { a,a ?} }, where D{a,a ?} is the Dyck language over { a , a ?} and wR is the reversal of w . All binary rules of this grammar are wrapping rules.
If ` G A(w1,w2), a derivation tree for A(w1,w2) is a finite binary tree whose nodes are labeled by facts that are derived during the derivation of A(w1,w2).
A derivation tree for A(w1,w2) represents a ? proof ? of ` G A(w1,w2), and is formally defined as follows : ? If A(w1,w2)? is a terminating rule , then a tree with a single node labeled by A(w1,w2) is a derivation tree for A(w1,w2).
S(aaa?a?aa ?, # a?aa?a?aa)
D(aaa?a?aa ?, a?aa?a?aa)
F(aaa?a ?, a?a?aa)
A(a , a ) E(aa?a ?, a?a?a)
D(aa ?, a?a)
F(aa ?, a?a)
A(a , a ) E(a ?, a?)
D (?, ?) A?(a ?, a?)
D (?, ?)
A?(a ?, a?)
D(aa ?, a?a)
F(aa ?, a?a)
A(a , a ) E(a ?, a?)
D (?, ?) A?(a ?, a?)
D (?, ?)
C (?, #)
Figure 1: An example of a derivation tree of a head grammar.
? If ` G A(w1,w2) is derived from ` G B(u1, u2) and ` G C(v1, v2) by some binary rule , then a binary tree whose root is labeled by A(w1,w2) and whose immediate left ( right ) subtree is a derivation tree for B(u1, u2) ( for C(v1, v2), respectively ) is a derivation tree for A(w1,w2).
If w ? L(G ), a derivation tree for w is a derivation tree for some S(w1,w2) such that w1w2 = w.
Example 1 ( continued ). Figure 1 shows a derivation tree for aaa?a?aa?#a?aa?a?aa.
The following lemma should be intuitively clear from the definition of a derivation tree : Lemma 1. Let G = ( N ,?, P , S ) be a head grammar and A be a nonterminal in N . Suppose that w ? L(G ) has a derivation tree in which a fact A(v1, v2) appears as a label of a node . Then there are strings z0, z1, z2 with the following properties : ( i ) w = z0v1z1v2z2, and ( ii ) ` G A(u1, u2) implies z0u1z1u2z2 ? L(G).
Proof . We can prove by straightforward induction on the height of derivation trees that whenever A(v1, v2) appears on a node in a derivation tree for B(w1,w2), then there exist z0, z1, z2, z3 that satisfy one of the following conditions : ( a ) w1 = z0v1z1v2z2, w2 = z3, and ` G A(u1, u2) implies ` G B(z0u1z1u2z2, z3).
(b ) w1 = z0, w2 = z1v1z2v2z3, and ` G A(u1, u2) implies ` G B(z0, z1u1z2u2z3).
668 ( c ) w1 = z0v1z1, w2 = z2v2z3, and ` G A(u1, u2) implies ` G B(z0u1z1, z2u2z3).
We omit the details . 
We call a nonterminal A of a head grammarG useless if A does not appear in any derivation trees for strings in L(G ). Clearly , useless nonterminals can be eliminated from any head grammar without affecting the language of the grammar.
3 Decompositions of Strings in MIX
Henceforth , ? = { a , b , c }. Let Z denote the set of integers . Define functions ?1, ?2 : ?? ? Z , ? : ?? ?
Z ? Z by ?1(w ) = | w|a ? | w|c , ?2(w ) = | w|b ? | w|c , ?( w ) = (?1(w ), ?2(w)).
Clearly , we have ?( a ) = (1, 0), ?( b ) = (0, 1), ?( c ) = (?1,?1), and w ? MIX iff ?( w ) = (0, 0).
Note that for all strings w1,w2 ? ??, ?( w1w2) = ?( w1)+?(w2). In other words , ? is a homomorphism from the free monoid ?? to Z ? Z with addition as the monoid operation and (0, 0) as identity.
Lemma 2. Suppose that G = ( N ,?, P , S ) is a head grammar without useless nonterminals such that L(G ) ? MIX . There exists a function ? G : N ? Z ? Z such that ` G A(u1, u2) implies ?( u1u2) = ? G(A).
Proof . Since G has no useless nonterminals , for each nonterminal A of G , there is a derivation tree for some string in L(G ) in which A appears in a node label . By Lemma 1, there are strings z0, z1, z2 such that ` G A(u1, u2) implies z0u1z1u2z2 ? L(G ). Since L(G ) ? MIX , we have ?( z0u1z1u2z2) = (0, 0), and hence ?( u1u2) = ??( z0z1z2).  A decomposition of w ? ?? is a finite binary tree satisfying the following conditions : ? the root is labeled by some ( w1,w2) such that w = w1w2, ? each internal node whose left and right children are labeled by ( u1, u2) and ( v1, v2), respectively , is labeled by one of ( u1u2v1, v2), ( u1, u2v1v2), ( u1v1, v2u2).
? each leaf node is labeled by some ( s1, s2) such that s1s2 ? { b , c }? ? { a , c }? ? { a , b}?.
Thus , the label of an internal node in a decomposition is obtained from the labels of its children by left concatenation , right concatenation , or wrapping . It is easy to see that ifG is a head grammar over the alphabet ?, any derivation for w ? L(G ) induces a decomposition ofw . ( Just strip off nonterminals .) Note that unlike with derivation trees , we have placed no bound on the length of a string that may appear on a leaf node of a decomposition . This will be convenient in some of the proofs below.
When p and q are integers , we write [ p , q ] for the set { r ? Z | p ? r ? q }. We call a decomposition of w an n-decomposition if each of its nodes is labeled by some ( v1, v2) such that ?( v1v2) ? [? n , n]?[?n , n].
Lemma 3. If MIX = L(G ) for some head grammar G = (?, N , P , S ), then there exists an n such that each w ? MIX has an n-decomposition.
Proof . We may suppose without loss of generality that G has no useless nonterminal . Since MIX = L(G ), there is a function ? G satisfying the condition of Lemma 2. Since the set N of nonterminals of G is finite , there is an n such that ? G(A ) ? [? n , n ] ? [? n , n ] for all A ? N . Then it is clear that a derivation tree for w ? L(G ) induces an n-decomposition of w .  If w = d1 . . . dm ? ? m , then for 0 ? i ? j ? m , we write w[i , j ] to refer to the substring di+1 . . . dj of w . ( As a special case , we have w[i , i ] = ?.) The following is a key lemma in our proof:
Lemma 4. If each w ? MIX has an n-decomposition , then each w ? MIX has a 2-decomposition.
Proof . Assume that each w ? MIX has an n-decomposition . Define a homomorphism ? n : ?? ? ? ? by ? n(a ) = an , ? n(b ) = b n , ? n(c ) = c n .
669
Clearly , ? n is an injection , and we have ?(? n(v )) = n ? ?( v ) for all v ? ??.
Let w ? MIX with | w | = m . Then w ? = ? n(w ) ? MIX and | w ?| = mn . By assumption , w ? has an n-decomposition D . We assign a 4-tuple ( i , j , k , l ) of natural numbers to each node of D in such a way that ( w?[i , j],w?[k , l ]) equals the label of the node.
This is done recursively in an obvious way , starting from the root . If the root is labeled by ( w1,w2), then it is assigned (0, | w1|, | w1|, | w1w2|). If a node is assigned a tuple ( i , j , k , l ) and has two children labeled by ( u1, u2) and ( v1, v2), respectively , then the 4-tuples assigned to the children are determined according to how ( u1, u2) and ( v1, v2) are combined at the parent node : u1 u2 v1 v2 i j k l i + | u1| i + | u1u2| u1 u2 v1 v2 i j k l k + | u2| k + | u2v1| u1 v1 v2 u2 i j k l i + | u1| k + | v2| Now define a function f : [0,mn ] ? { kn | 0 ? k ? m } by f ( i ) = ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i if n divides i , n ? bi/nc if n does not divide i and w?[i ? 1, i ] ? { a , b }, n ? di/ne if n does not divide i and w?[i ? 1, i ] = c.
Clearly , f is weakly increasing in the sense that i ? j implies f ( i ) ? f ( j ). LetD ? be the result of replacing the label of each node inD by ( w ?[ f ( i ), f ( j)],w ?[ f ( k ), f ( l )]), where ( i , j , k , l ) is the 4-tuple of natural numbers assigned to that node by the above procedure . It is easy to see that D ? is another decomposition of w ?. Note that since each of f ( i ), f ( j ), f ( k ), f ( l ) is an integral multiple of n , we always have ( w ?[ f ( i ), f ( j)],w ?[ f ( k ), f ( l )]) = (? n(u ), ? n(v )) for some substrings u , v of w . This implies that for h = 1, 2, ? h(w ?[ f ( i ), f ( j)]w ?[ f ( k ), f ( l )]) is an integral multiple of n.
Claim . D ? is a 2n-decomposition.
We have to show that every node label ( v1, v2) in D ? satisfies ?( v1v2) ? [?2n , 2n ] ? [?2n , 2n ]. For h = 1, 2, define ? h : [0,mn ] ? [0,mn ]? Z as follows : ? h(i , j ) = ? ? ? ? ? ? ? ? h(w?[i , j ]) if i ? j , ?? h(w ?[ j , i ]) otherwise.
Then it is easy to see that for all i , j , i ?, j ? ? [0,mn ], ? h(i ? , j ?) = ? h(i ? , i ) + ? h(i , j ) + ? h ( j , j ?).
Inspecting the definition of the function f , we can check that ? h ( f ( i ), i ) ? [0, n ? 1] always holds . Suppose that ( i , j , k , l ) is assigned to a node in D . By assumption , we have ? h(w?[i , j]w?[k , l ]) ? [? n , n ], and ? h(w ?[ f ( i ), f ( j)]w ?[ f ( k ), f ( l )]) = ? h(w ?[ f ( i ), f ( j )]) + ? h(w ?[ f ( k ), f ( l )]) = ? h ( f ( i ), f ( j )) + ? h ( f ( k ), f ( l )) = ? h ( f ( i ), i ) + ? h(i , j ) + ? h ( j , f ( j )) + ? h ( f ( k ), k ) + ? h(k , l ) + ? h(l , f ( l )) = ? h ( f ( i ), i ) + ? h(w?[i , j ]) + ? h ( j , f ( j )) + ? h ( f ( k ), k ) + ? h(w ?[ k , l ]) + ? h(l , f ( l )) = ? h(w ?[ i , j]w?[k , l ]) + ? h ( f ( i ), i ) + ? h ( f ( k ), k ) + ? h ( j , f ( j )) + ? h(l , f ( l )) ? { p + q1 + q2 + r1 + r2 | p ? [? n , n ], q1, q2 ? [0, n ? 1], r1, r2 ? [? n + 1, 0] } = [?3n + 2, 3n ? 2].
Since ? h(w ?[ f ( i ), f ( j)]w ?[ f ( k ), f ( l )]) must be an integral multiple of n , it follows that ? h(w ?[ f ( i ), f ( j)]w ?[ f ( k ), f ( l )]) ? {?2n,?n , 0, n , 2n}.
This establishes the claim.
670
We have shown that each node ofD ? is labeled by a pair of strings of the form (? n(u ), ? n(v )) such that ?(? n(u)?n(v )) ? {?2n,?n , 0, n , 2n } ? {?2n,?n , 0, n , 2n}.
Now it is easy to see that inverting the homomorphism ? n at each node of D ? (? n(u ), ? n(v )) 7? ( u , v ) gives a 2-decomposition of w .  4 A String in MIX That Has No 2-Decomposition By Lemmas 3 and 4, in order to prove that there is no head grammar for MIX , it suffices to exhibit a string in MIX that has no 2-decomposition . The following is such a string : z = a5b14a19c29b15a5.
In this section , we prove that the string z has no 2-decomposition.7 It helps to visualize strings in MIX as closed curves in a plane . If w is a string in MIX , by plotting the coordinates of ?( v ) for each prefix v of w , we can represent w by a closed curve C together with a map t : [0, | w |] ? C . The representation of the string z is given in Figure 2.
Let us call a string w ? { a , b , c }? such that ?( w ) ? [?2, 2] ? [?2, 2] long if w contains all three letters , and short otherwise . ( If ?( w ) < [?2, 2] ? [?2, 2], then w is neither short nor long .) It is easy to see that a short string w always satisfies | w|a ? 4, | w|b ? 4, | w|c ? 2.
The maximal length of a short string is 6. ( For example , a4c2 and b4c2 are short strings of length 6.) We also call a pair of strings ( v1, v2) long ( or short ) if v1v2 is long ( or short , respectively).
According to the definition of an n-decomposition , a leaf node in a 2-decomposition 7This fact was first verified by the computer program accompanying this paper . The program , written in C , implements a generic , memoized topdown recognizer for the language { w ? MIX | w has a 2-decomposition }, and does not rely on any special properties of the string z.
0 5 19 38 87 a5 b14 a19 c29 b15 a5
Figure 2: Graphical representation of the string z = a5b14a19c29b15a5. Note that every point ( i , j ) on the diagonal segment has i > 7 or j < ?2.
must be labeled by a short pair of strings . We call a 2-decomposition normal if the label of every internal node is long . Clearly , any 2-decomposition can be turned into a normal 2-decomposition by deleting all nodes that are descendants of nodes with short labels.
One important property of the string z is the following : Lemma 5. If z = x1vx2 and ?( v ) ? [?2, 2]? [?2, 2], then either v or x1x2 is short.
Proof . This is easy to see from the graphical representation in Figure 2. If a substring v of z has ?( v ) ? [?2, 2] ? [?2, 2], then the subcurve corresponding to v must have initial and final coordinates whose difference lies in [?2, 2] ? [?2, 2]. If v contains all three letters , then it must contain as a substring at least one of ba19c , ac29b , and cb15a.
The only way to satisfy both these conditions is to have the subcurve corresponding to v start and end very close to the origin , so that x1x2 is short . ( Note that the distance between the coordinate (5, 0) corresponding to position 5 of z and the diagonal segment corresponding to the substring c29 is large enough that it is impossible for v to start at position 5 and end in the middle of c29 without violating the condition ?( v ) ? [?2, 2] ? [?2, 2].)  Lemma 5 leads to the following observation . Let us call a decomposition of a string concatenation-free if each of its nonleaf labels is the wrapping of the labels of the children.
671
Lemma 6. If z has a 2-decomposition , then z has a normal , concatenation-free 2-decomposition.
Proof . Let D be a 2-decomposition of z . Without loss of generality , we may assume that D is normal . Suppose that D contains a node ? whose label is the left or right concatenation of the labels of its children , ( u1, u2) and ( v1, v2). We only consider the case of left concatenation since the case of right concatenation is entirely analogous ; so we suppose that the node ? is labeled by ( u1u2v1, v2).
It follows that z = x1u1u2x2 for some x1, x2, and by Lemma 5, either u1u2 or x1x2 is short . If u1u2 is short , then the left child of ? is a leaf because D is normal . We can replace its label by ( u1u2, ?); the label ( u1u2v1, v2) of ? will now be the wrapping ( as well as left concatenation ) of the two child labels , ( u1u2, ?) and ( v1, v2). If x1x2 is short , then we can combine by wrapping a single node labeled by ( x1, x2) with the subtree ofD rooted at the left child of ?, to obtain a new 2-decomposition of z . In either case , the result is a normal 2-decomposition of z with fewer instances of concatenation . Repeating this procedure , we eventually obtain a normal , concatenation-free 2-decomposition of z .  Another useful property of the string z is the following : Lemma 7. Suppose that the following conditions hold : ( i ) z = x1u1v1yv2u2x2, ( ii ) x1yx2 is a short string , and ( iii ) both ?( u1u2) and ?( v1v2) are in [?2, 2] ? [?2, 2].
Then either ( u1, u2) or ( v1, v2) is short.
Proof . Suppose ( u1, u2) and ( v1, v2) are both long.
Since ( u1, u2) and ( v1, v2) must both contain c , either u1 ends in c and v1 starts in c , or else v2 ends in c and u2 starts in c.
Case 1. u1 ends in c and v1 starts in c . Since ( v1, v2) must contain at least one occurrence of a , the string v1yv2 must contain cb15a as a substring.
a5b14 a19 c29 b15 a5 v1yv2
Since x1yx2 is short , we have | y|b ? 4. It follows that | v1v2|b ? 11. But v1yv2 is a substring of c28b15a5, so | v1v2|a ? 5. This clearly contradicts ?( v1v2) ? [?2, 2] ? [?2, 2].
Case 2. v2 ends in c and u2 starts in c . In this case , cb15a5 is a suffix of u2x2. Since x1yx2 is short , | x2|a ? 4. This means that cb15a is a substring of u2 and hence | u2|b = 15.
a5b14 a19 c29 b15 a5 u2 x2v1yv2u1
On the other hand , since ( v1, v2) must contain at least one occurrence of b , the string v1yv2 must contain ba19c as a substring . This implies that | u1u2|a ? 10.
But since | u2|b = 15, we have | u1u2|b ? 15. This clearly contradicts ?( u1u2) ? [?2, 2] ? [?2, 2]. 
We now assume that z has a normal , concatenation-free 2-decomposition D and derive a contradiction . We do this by following a certain path in D . Starting from the root , we descend in D , always choosing a nonleaf child , as long as there is one . We show that this path will never terminate.
The ith node on the path will be denoted by ? i , counting the root as the 0th node . The label of ? i will be denoted by ( wi,1,wi,2). With each i , we associate three strings xi,1, yi , xi,2 such that xi,1wi,1yiwi,2xi,2 = z , analogously to Lemma 1. Since ?( wi,1wi,2) ? [?2, 2] ? [?2, 2] and ?( z ) = (0, 0), we will always have ?( xi,1yixi,2) ? [?2, 2] ? [?2, 2].
Initially , ( w0,1,w0,2) is the label of the root ?0 and x0,1 = y0 = x0,2 = ?. If ? i is not a leaf node , let ( ui,1, ui,2) and ( vi,1, vi,2) be the labels of the left and right children of ? i , respectively . If the left child is not a leaf node , we let ? i+1 be the left child , in which case we have ( wi+1,1,wi+1,2) = ( ui,1, ui,2), xi+1,1 = xi,1, xi+1,2 = xi,2, and yi+1 = vi,1yvi,2. Otherwise , ? i+1 will be the right child of ? i , and we have ( wi+1,1,wi+1,2) = ( vi,1, vi,2), xi+1,1 = xi,1ui,1, xi+1,2 = ui,2xi,2, and yi+1 = yi.
The path ?0, ?1, ?2, . . . is naturally divided into two parts . The initial part of the path consists of nodes where xi,1yixi,2 is short . Note that x0,1y0x0,2 = ? is short . As long as xi,1yixi,2 is short , ( wi,1,wi,2) must be long and ? i has two children labeled by ( ui,1, ui,2) and ( vi,1, vi,2). By Lemma 7, either ( ui,1, ui,2) or ( vi,1, vi,2) must be short . Since the length exactly one of ( ui,1, ui,2) and ( vi,1, vi,2) must be long.
We must eventually enter the second part of the path , where xi,1yixi,2 is no longer short . Let ? m be the first node belonging to this part of the path . Note that at ? m , we have ?( xm,1ymxm,2) = ?( xm?1,1ym?1xm?1,2) + ?( v ) for some short string v.
(Namely , v = um?1,1um?1,2 or v = vm?1,1vm?1,2.) Lemma 8. If u and v are short strings and ?( uv ) ? [?2, 2]? [?2, 2], then | uv|d ? 4 for each d ? { a , b , c}.
Proof . Since u and v are short , we have | u|a ? 4, | u|b ? 4, | u|c ? 2 and | v|a ? 4, | v|b ? 4, | v|c ? 2. It immediately follows that | uv|c ? 4. We distinguish two cases.
Case 1. | uv|c ? 2. Since ?( uv ) ? [?2, 2] ? [?2, 2], we must have | uv|a ? 4 and | uv|b ? 4.
Case 2. | uv|c ? 3. Since | u|c ? 2 and | v|c ? 2, we must have | u|c ? 1 and | v|c ? 1. Also , ?( uv ) ? [?2, 2] ? [?2, 2] implies that | uv|a ? 1 and | uv|b ? 1.
Since u and v are short , it follows that one of the following two conditions must hold : ( i ) | u|a ? 1, | u|b = 0 and | v|a = 0, | v|b ? 1.
(ii ) | u|a = 0, | u|b ? 1 and | v|a ? 1, | v|b = 0.
In the former case , | uv|a = | u|a ? 4 and | uv|b = | v|b ? 4. In the latter case , | uv|a = | v|a ? 4 and | uv|b = | u|b ? 4.  By Lemma 8, the number of occurrences of each letter in xm,1ymxm,2 is in [1, 4]. This can only be if xm,1xm,2 = a j , ym = c kbl , for some j , k , l ? [1, 4]. This means that the string z must have been split into two strings ( w0,1,w0,2) at the root of D somewhere in the vicinity of position 67 ( see Figure 2).
It immediately follows that for all i ? m , wi,1 is a substring of a5b14a19c28 and wi,2 is a substring of b14a5. We show by induction that for all i ? m , the following condition holds : (?) ba19c17 is a substring of wi,1.
The condition (?) clearly holds for i = m . Now assume (?). Then ( wi,1,wi,2) is long , and ? i has left and right children , labeled by ( ui,1, ui,2) and ( vi,1, vi,2), respectively , such that wi,1 = ui,1vi,1 and wi,2 = vi,2ui,2.
We consider two cases.
Case 1. ui,1 contains c . Then ba19c is a substring of ui,1. Since ui,2 is a substring of b14a5, it cannot contain any occurrences of c . Since ?1(ui,1ui,2) ? [?2, 2], it follows that ui,1 must contain at least 17 occurrences of c ; hence ba19c17 is a substring of ui,1.
Since ( ui,1, ui,2) is long , ( wi+1,1,wi+1,2) = ( ui,1, ui,2).
Therefore , the condition (?) holds with i + 1 in place of i.
Case 2. ui,1 does not contain c . Then ( ui,1, ui,2) is short and ( wi+1,1,wi+1,2) = ( vi,1, vi,2). Note that vi,1 must contain at least 17 occurrences of c , but vi,2 is a substring of b14a5 and hence cannot contain more than 14 occurrences of b . Since ?2(vi,1vi,2) ? [?2, 2], it follows that vi,1 must contain at least one occurrence of b . Therefore , ba19c17 must be a substring of vi,1 = wi+1,1, which shows that (?) holds with i+1 in place of i.
We have proved that (?) holds for all i ? m . It follows that for all i , ? i has two children and hence ? i+1 is defined . This means that the path ?0, ?1, ?2, . . .
is infinite , contradicting the assumption that D is a 2-decomposition of z.
We have proved the following:
Lemma 9. There is a string in MIX that has no 2-decomposition.
Theorem 10. There is no head grammar G such that
L(G ) = MIX.
Proof . Immediate from Lemmas 3, 4, and 9. 
References
Setsuo Arikawa , Takeshi Shinohara , and Akihiro Yamamoto . 1992. Learning elementary formal systems.
Theoretical Computer Science , 95(1):97?113.
Emmon Bach . 1981. Discontinuous constituents in generalized categorial grammars . In Victoria Burke and James Pustejovsky , editors , Proceedings of the 11th Annual Meeting of the North East Linguistic Society , pages 1?12.
Emmon Bach . 1988. Categorial grammars as theories of language . In Richard T . Oehrle , Emmon Bach , and Deirdre Wheeler , editors , Categorial Grammars and Natural Language Structures , pages 17?34. D . Reidel,
Dordrecht.
673
Gerald Gazdar . 1988. Applicability of indexed grammars to natural languages . In U . Reyle and C . Rohrer , editors,Natural Language Parsing and Linguistic Theories , pages 69?94. D . Reidel Publishing Company,
Dordrecht.
Robert Gilman . 2005. Formal languages and their application to combinatorial group theory . In Alexandre V . Borovik , editor , Groups , Languages , Algorithms , number 378 in Contemporary Mathematics , pages 1?36. American Mathematical Society , Providence , RI.
Annius V . Groenink . 1997. Mild contextsensitivity and tuple-based generalizations of contextfree grammar.
Linguistics and Philosophy , 20:607?636.
Aravind K . Joshi , Vijay K . Shanker , and David J . Weir.
1991. The converence of mildly context-sensitive grammar formalisms . In Peter Sells , Stuart M.
Shieber , and ThomasWasow , editors , Foundational Issues in Natural Language Processing , pages 31?81.
The MIT Press , Cambridge , MA.
Aravind K . Joshi . 1985. Tree-adjoining grammars : How much context sensitivity is required to provide reasonable structural descriptions ? In David Dowty , Lauri Karttunen , and Arnold M . Zwicky , editors , Natural Language Parsing , pages 206?250. Cambridge University Press , Cambridge.
Markus Kracht . 2003. The Mathematics of Language , volume 63 of Studies in Generative Grammar . Mouton de Gruyter , Berlin.
William Marsh . 1985. Some conjectures on indexed languages . Paper presented to the Association for Symbolic Logic Meeting , Stanford University , July 15?19. Abstract appears in Journal of Symbolic
Logic 51(3):849 (1986).
Carl J . Pollard . 1984. Generalized Phrase Structure Grammars , Head Grammars , and Natural Language.
Ph.D . thesis , Department of Linguistics , Stanford University.
Kelly Roach . 1987. Formal properties of head grammars . In Alexis Manaster-Ramer , editor , Mathematics of Language , pages 293?347. John Benjamins , Amsterdam.
Sylvain Salvati . 2011. MIX is a 2-MCFL and the word problem in Z2 is captured by the IO and the OI hierarchies . Technical report , INRIA.
Hiroyuki Seki , Takashi Matsumura , Mamoru Fujii , and Tadao Kasami . 1991. On multiple context free grammars . Theoretical Computer Science , 88(2):191?229.
Raymond M . Smullyan . 1961. Theory of Formal Systems . Princeton University Press , Princeton , NJ.
K . Vijay-Shanker and D . J . Weir . 1994. The equivalence of four extensions of contextfree grammars . Mathematical Systems Theory , 27:511?546.
K . Vijay-Shanker , David J . Weir , and Aravind K . Joshi.
1987. Characterizing structural descriptions produced by various grammatical formalisms . In 25th Annual Meeting of the Association for Computational Linguistics , pages 104?111.
David J . Weir . 1988. Characterizing Mildly Context-Sensitive Grammar Formalisms . Ph.D . thesis , University of Pennsylvania , Philadephia , PA.
674
