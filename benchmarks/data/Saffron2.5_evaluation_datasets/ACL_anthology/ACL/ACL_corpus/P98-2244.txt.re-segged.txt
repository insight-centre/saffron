Optimal Multi-Paragraph Text Segmentation by Dynamic Programming 
Oskari Heinonen
University of Helsinki , Department of Computer Science
P . O . Box 26 ( Teollisuuskatu23) , FIN-00014 University of Helsinki , Finland
Oskari . Heinonen@cs . Helsinki . FI

There exist several methods of calculating a similarity curve  , or a sequence of similarity values , representing the lexical cohesion of successive text constituents  , e . g . , paragraphs . Methods for deciding the locations of fragment boundaries are  , however , scarce . We propose a fragmentation method based on dynamic programming  . The method is theoretically sound and guaranteed to provide an optimal splitting on the basis of a similarity curve  , a preferred fragment length , and a cost function defined . 
The method is especially useful when control on fragment size is of importance  . 
1 Introduction
Electronic full text documents and digital libraries make the utilization of texts much more effective than before  ; yet , they pose new problems and requirements . For example , document retrieval based on string searches typically returns either the whole document or just the occurrences of the searched words  . What the user often is after , however , is mi-crodocument : a part of the document that contains the occurrences and is reasonably self -contained  . 
Micro documents can be created by utilizing lexical cohesion  ( term repetition and semantic relations ) present in the text . There exist several methods of calculating a similarity curve  , or a sequence of similarity values , representing the lexical cohesion of successive constituents  ( uchas paragraphs ) of text ( see , e . g . , ( Hearst , 1994; Hearst , 1997; Koz-ima , 1993; Morris and Hirst , 1991; Yaari , 1997; Youmans ,  1991)) . Methods for deciding the locations of fragment boundaries are  , however , not that common , and those that exist are often rather heuristic in nature  . 
To evaluate our fragmentation method , to be explained in Section 2 , we calculate the paragraph similarities as follows  . We employ stemming , remove stop words , and count the frequencies of the remaining words , i . e . , terms . Then we take a predefined number , e . g . , 50 , of the most frequent terms to represent the paragraph  , and count the similarity using the cosine coefficient  ( see , e . g . , ( Salton , 1989)) . Furthermore , we have applied a sliding window method : instead of just one paragraph  , several paragraphs on both sides of each paragraph boundary are considered  . The paragraph vectors are weighted based on their distance from the boundary in question with immediate paragraphs having the highest weight  . The benefit of using a larger window is that we can smooth the effect of short paragraphs and such  , perhaps example-type , paragraphs that interrupt a chain of coherent paragraphs  . 
2 Fragmentation by Dynamic

Fragmentation is a problem of choosing the paragraph boundaries that make the best fragment boundaries  . The local minima of the similarity curve are the points of low lexical cohesion and thus the natural candidates  . To get reasonably-sized mi-crodocuments , the similarity information alone is not enough ; also the lengths of the created fragments have to be considered  . In this section , we describe an approach that performs the fragmentation by using both the similarities and the length information in a robust manner  . The method is based on a programming paradigm called dynamic programming  ( see , e . g . , ( Cormen et al , 1990)) . Dynamic programming as a method guarantees the optimality of the result with respect othe input and the parameters  . 
The idea of the fragmentation algorithm is as follows  ( see also Fig .  1) . We start from the first boundary and calculate a cost for it as if the first paragraph was a single fragment  . Then we take the second boundary and attach to it the minimum of the two available possibilities : the cost of the first two paragraphs as if they were a single fragment and the cost /* n no  . of pars , p p referred frag length , hscaling*/I*len\[1 . .n \] par lengths , sim\[1 . .n - 1\] similarities */  sire\[O \] := 0 . 0; cost\[O\]:=0 . 0 ; B := 0 ; for par := 1 to n lensum := 0 ; /* cumulative fragment length */ emin := MAX REAL ; for i := part o I lensum := lensurn + len\[i\] ; c := Cle , ( lensum , p , h ) ; if e ~> emin /* optimization */ exit the innermost for loop  ; e := c + cost\[i-1\]+sim\[i-1\] ; if C < C minC min := C ; IOC-Cmin := i--1 ; cost ~ ar\]:=Cmin ; link p , ev\[par\]:=lot-train ; j := n ; while link prev\[j\]> 0 B := Bt_J link prev\[j\] ; j := link prev\[j\] ; ) return ( B ) ; /* set of chosen fragment boundaries */ Figure 1: The dynamic programming algorithm for fragment boundary detection  . 
of the second paragraph as a separate fragment . In the following steps , the evaluation moves on by one paragraph at each time  , and all the possible locations of the previous break point are considered  . We continue this procedure till the end of the text  , and finally we can generate a list of break points that indicate the fragmentation  . 
The cost at each boundary is a combination of three components : the cost of fragment length Clen  , and the cost cost \[ . \] and similarity sim\[ . \] of some previous boundary . The cost function Clen gives the lowest cost for the preferred fragment length given by the user  , say , e . g . , 500 words . A fragment which is either shorter or longer gets a higher cost  , i . e . , is punished for its length . We have experimented with two families of cost functions  , a family of second degree functions ( parabol as ) , ~ z+1) , and V-shape linear functions , 
Clen(X , p , h ( ~-1) 1, i0 . S0 . 4  . ,~ 0 . 3 t ? 0 . 2 0 . 10 IT 2 O O O
I ' i , i . . . .
3000 4000 5000 wocd counl(a ) " W6ClinHO . 25 L "" W6 Clin H 0 . SL""W6 Clin H0 . 75L "" W6ClinH 1 . 0L " " W6ClinH 1 . 25L "" W6ClinH 1 . SL"?W6L ? .   .   .   . 
II 1~11-7....

Mars . Chapter IL Section I.
i 0.6" ~0.5 0.4 0.3 0.2 0.1
IHI 1000 2000 3000 4000" W6CparH0 . 25 L "?" W6C~rH 0 . SL"?"W6CparH0 . 75L "?" W6CparH 1 . 0L " ?
T"W6CI~d-11 . 2$L "*' WSC par HI . SL "??" W 61 . " - - -
If 111-ii--7....
5000 6000 7000 wo tdt ~ mnt(b)
Figure 2: Similarity curve and detected fragment boundaries with different cost functions  . ( a ) Linear . (b ) Parabola . p is 600 words in both ( a ) & ( b) . 
"H0 . 25", etc . , indicates the value of h . Vertical bars indicate fragment boundaries while short bars below horizontal axis indicate paragraph boundaries  . 
where x is the actual fragment length , p is the preferred fragment length given by the user  , and his a scaling parameter that allows us to adj us the weight given to fragment length  . The smaller the value of h , the less weight is given to the preferred fragment length in comparison with the similarity measure  . 
3 Experiments
As test data we used Mars by Percival Lowell ,  1895 . 
As an illustrative xample , we present he analysis of Section I . Evidence of it of Chapter II . Atmosphere . The length of the section is approximately 6600 words and it contains 55 paragraphs . The fragments found with different parameter settings can be seen in Figure  2  . One of the most interesting is the one with parabol a cost function and h =  . 5 . In this case the fragment length adjusts nicely according to the similarity curve  . Looking at the text , most fragments have an easily identifiable topic , like at-mosp be richemistry in fragment 7 . Fragments 2 and 3 seem to have roughly the same topic : measuring the diameter of the planet Mars  . The fact that they do not form a single fragment can be explained cost function linear parabol a h  . 25  . 50  . 75 1 . 00 1 . 25 1 . 50  . 25  . 50  . 75 1 . 00 1 . 25 1 . 50 lavg/min/maxdavg 10 96 . 1 501 3101 476 . 5 706 . 4 501 1328 110 . 5 635 . 7 515 835 60 . 1 635 . 7 515 835 59 . 5 635 . 7 515 835 59 . 5 635 . 7 515 835 57 . 6 908 . 2 501 1236 269 . 4 691 . 0 319 1020 126 . 0 676 . 3 371 922 105 . 8 662 . 2 371 866 94 . 2 648 . 7 466 835 82 . 4 635 . 7 473 835 69 . 9 Table 1: Variation of fragment length . Columns : lavg , lmin , Imax average , minimum , and maximum fragment length ; and d avg average deviation . 
by the preferred fragment length requirement.
Table 1 summarizes the effect of the scaling factor h in relation to the fragment length variation with the two cost functions over those  8 sections of Mars that have a length of at least 20 paragraphs . The average deviation davg with respect to the preferred fragment length p is defined as davg =   ( ~-'~ n=1\[P--lil ) /m where li is the length of fragment i , and m is the number of fragments . The parametric cost function chosen affects the result a lot  . As expected , the second degree cost function allows more variation than the linear one but roles change with a small h  . Although the experiment is insufficient , we can see that in this example a factor h > 1 . 0 is unsuitable with the linear cost function ( and h = 1 . 5 with the parabol a ) since in these cases so much weight is given to the fragment length that fragment boundaries can appear very close to quite strong local maxima of the similarity curve  . 
4 Conclusions
In this article , we presented a method for detecting fragment boundaries in text  . The fragmentation method is based on dynamic programming and is guaranteed to give an optimal solution with respect to a similarity curve  , a preferred fragment length , and a parametric fragment-length cost function defined  . The method is independent of the similarity calculation  . This means that any method , not necessarily based on lexical cohesion , producing a suit-able sequence of similarities can be used prior to our fragmentation method  . For example , the lexical cohesion profile ( Kozima ,  1993 ) should be perfectly usable with our fragmentation method  . 

The method is especially useful when control over fragment size is required  . This is the case in passage retrieval since windows of  1000 bytes ( Wilkinson and Zobel , 1995) or some hundred words ( Callan , 1994) have been proposed as best passage sizes . Furthermore , we believe that fragments of reasonably similar size are beneficial in our intended purpose of document assembly  . 

This work has been supported by the Finnish Technology Development Centre  ( TEKES ) together with industrial partners , and by a grant from the 350th Anniversary Foundation of the University of Helsinki  . The author thanks Helena Ahonen , Barbara Heikkinen , Mika Klemettinen , and Juha K ~ kk ~ iinen for their contributions to the work described  . 

J . P . Callan .  1994 . Passage-level vidence in document retrieval . In Proc . SIGIR'94, Dublin , Ireland . 
T . H . Cormen , C . E . Leiserson , and R . L . Rivest . 
1990. Introduction to Algorithms . MIT Press,
Cambridge , MA , USA.
M . A . Hearst .  1994 . Multiparagraph segmentation of expository text . In Proc . ACL-gg , Las Cruces,
NM , USA.
M . A . Hearst .  1997 . TextTiling : Segmenting text into multiparagraph subtopic passages  . Computational Linguistics , 23(1):33-64, March . 
H . Kozima .  1993 . Text segmentation based on similarity between words  . In Proc . ACL93, Columbus , OH , USA . 
J . Morris and G . Hirst .  1991 . Lexical cohesion computed by thesaural relation as an indicator of the structure of text  . Computational Linguistics , 17(1):21-48 . 
G . Salton .  1989 . Automatic Text Processing : The Transformation , Analysis , and Retrieval of lnfor-mation by Computer . Addison-Wesley , Reading,
MA , USA.
R . Wilkinson and J . Zobel .  1995 . Comparison of fragmentation schemes for document retrieval  . In Overview of TREC3, Gaithersburg , MD , USA . 
Y . Yaari .  1997 . Segmentation fexpository texts by hierarchical agglomerative clustering  . In Proc . 
RANLP'97, Tzigov Chark , Bulgaria.
G . Youmans .  1991 . A new tool for discourse analysis . Language , 67(4):763-789 . 
