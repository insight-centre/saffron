Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP , pages 985?993,
Suntec , Singapore , 27 August 2009. c?2009 ACL and AFNLP
An Optimal-Time Binarization Algorithm
for Linear ContextFree Rewriting Systems with Fan-Out Two
Carlos Go?mez-Rodr??guez
Departamento de Computacio?n
Universidade da Corun?a , Spain
cgomezr@udc.es
Giorgio Satta
Department of Information Engineering
University of Padua , Italy
satta@dei.unipd.it
Abstract
Linear contextfree rewriting systems ( LCFRSs ) are grammar formalisms with the capability of modeling discontinuous constituents . Many applications use
LCFRSs where the fanout ( a measure of the discontinuity of phrases ) is not allowed to be greater than 2. We present an efficient algorithm for transforming LCFRS with fanout at most 2 into a binary form , whenever this is possible . This results in asymptotical runtime improvement for known parsing algorithms for this class.
1 Introduction
Since its early years , the computational linguistics field has devoted much effort to the development of formal systems for modeling the syntax of natural language . There has been a considerable interest in rewriting systems that enlarge the generative power of contextfree grammars , still remaining far below the power of the class of context-sensitive grammars ; see ( Joshi et al , 1991) for discussion . Following this line , ( Vijay-Shanker et al , 1987) have introduced a formalism called linear contextfree rewriting systems ( LCFRSs ) that has received much attention in later years by the community.
LCFRSs allow the derivation of tuples of strings,1 i.e ., discontinuous phrases , that turn out to be very useful in modeling languages with relatively free word order . This feature has recently been used for mapping nonprojective dependency grammars into discontinuous phrase structures ( Kuhlmann and Satta , 2009). Furthermore , LCFRSs also implement socalled synchronous 1In its more general definition , an LCFRS provides a framework where abstract structures can be generated , as for instance trees and graphs . Throughout this paper we focus on socalled string-based LCFRSs , where rewriting is defined over strings only.
rewriting , up to some bounded degree , and have recently been exploited , in some syntactic variant , in syntaxbased machine translation ( Chiang , 2005; Melamed , 2003) as well as in the modeling of syntax-semantic interface ( Nesson and Shieber , 2006).
The maximum number f of tuple components that can be generated by an LCFRS G is called the fanout of G , and the maximum number r of nonterminals in the righthand side of a production is called the rank of G . As an example , contextfree grammars are LCFRSs with f = 1 and r given by the maximum length of a production righthand side . Tree adjoining grammars ( Joshi and Levy , 1977), or TAG for short , can be viewed as a special kind of LCFRS with f = 2, since each elementary tree generates two strings , and r given by the maximum number of adjunction sites in an elementary tree.
Several parsing algorithms for LCFRS or equivalent formalisms are found in the literature ; see for instance ( Seki et al , 1991; Boullier , 2004; Burden and Ljunglo?f , 2005). All of these algorithms work in time O(|G | ? | w|f ?( r+1)). Parsing time is then exponential in the input grammar size , since | G | depends on both f and r . In the development of efficient algorithms for parsing based on LCFRS the crucial goal is therefore to optimize the term f ? ( r + 1).
In practical natural language processing applications the fanout of the grammar is typically bounded by some small number . As an example , in the case of discontinuous parsing discussed above , we have f = 2 for most practical cases.
On the contrary , LCFRS productions with a relatively large number of nonterminals are usually observed in real data . The reduction of the rank of a LCFRS , called binarization , is a process very similar to the reduction of a contextfree grammar into Chomsky normal form . While in the special case of CFG and TAG this can always be achieved , eral case , an increase in the fanout of the grammar much larger than the achieved reduction in the rank . Worst cases and some lower bounds have been discussed in ( Rambow and Satta , 1999; Satta , 1998).
Nonetheless , in many cases of interest binarization of an LCFRS can be carried out without any extra increase in the fanout . As an example , in the case where f = 2, binarization of a LCFRS would result in parsing time of O(|G | ? | w|6).
With the motivation of parsing efficiency , much research has been recently devoted to the design of efficient algorithms for rank reduction , in cases in which this can be carried out at no extra increase in the fanout . ( Go?mez-Rodr??guez et al , 2009) reports a general binarization algorithm for LCFRS.
In the case where f = 2, this algorithm works in time O(|p|7), where p is the input production.
A more efficient algorithm is presented in ( Kuhlmann and Satta , 2009), working in time O(|p |) in case of f = 2. However , this algorithm works for a restricted typology of productions , and does not cover all cases in which some binarization is possible . Other linear time algorithms for rank reduction are found in the literature ( Zhang et al , 2008), but they are restricted to the case of synchronous contextfree grammars , a strict subclass of the LCFRS with f = 2.
In this paper we focus our attention on LCFRS with a fanout of two . We improve upon all of the above mentioned results , by providing an algorithm that computes a binarization of an LCFRS production in all cases in which this is possible and works in time O(|p |). This is an optimal result in terms of time complexity , since ?(| p |) is also the size of any output binarization of an LCFRS production.
2 Linear contextfree rewriting systems
We briefly summarize here the terminology and notation that we adopt for LCFRS ; for detailed definitions , see ( Vijay-Shanker et al , 1987). We denote the set of nonnegative integers by N . For i , j ? N , the interval { k | i ? k ? j } is denoted by [ i , j ]. We write [ i ] as a shorthand for [1, i ]. For an alphabet V , we write V ? for the set of all ( finite ) strings over V .
As already mentioned in Section 1, linear contextfree rewriting systems generate tuples of strings over some finite alphabet . This is done by associating each production p of a grammar with a function g that rearranges the string components in the tuples generated by the nonterminals in p?s righthand side , possibly adding some alphabet symbols . Let V be some finite alphabet.
For natural numbers r ? 0 and f , f1, . . . , fr ? 1, consider a function g : ( V ?) f1 ? ? ? ? ? ( V ?) fr ? ( V ?) f defined by an equation of the form g(?x1,1, . . . , x1,f1?, . . . , ? xr,1, . . . , xr,fr ?) = ~?, where ~? = ??1, . . . , ? f ? is an f - tuple of strings over g?s argument variables and symbols in V . We say that g is linear , nonerasing if ~? contains exactly one occurrence of each argument variable.
We call r and f the rank and the fanout of g , respectively , and write r(g ) and f(g ) to denote these quantities.
A linear contextfree rewriting system ( LCFRS ) is a tuple G = ( VN , VT , P , S ), where VN and VT are finite , disjoint alphabets of nonterminal and terminal symbols , respectively . Each A ? VN is associated with a value f(A ), called its fanout . The nonterminal S is the start symbol , with f(S ) = 1. Finally , P is a set of productions of the form p : A ? g(A1, A2, . . . , Ar(g )) , where A,A1, . . . , Ar(g ) ? VN , and g : ( V ?
T ) f(A1) ? ? ? ?? ( V ? T ) f(Ar(g )) ? ( V ? T ) f(A ) is a linear , nonerasing function.
A production p of G can be used to transform a sequence of r(g ) string tuples generated by the nonterminals A1, . . . , Ar(g ) into a tuple of f(A ) strings generated by A . The values r(g ) and f(g ) are called the rank and fanout of p , respectively , written r(p ) and f(p ). The rank and fanout of G , written r(G ) and f(G ), respectively , are the maximum rank and fanout among all of G?s productions . Given that f(S ) = 1, S generates a set of strings , defining the language of G.
Example 1 Consider the LCFRS G defined by the productions p1 : S ? g1(A ), g1(?x1,1, x1,2?) = ? x1,1x1,2? p2 : A ? g2(A ), g2(?x1,1, x1,2?) = ? ax1,1b , cx1,2d ? p3 : A ? g3(), g3() = ??, ?? We have f(S ) = 1, f(A ) = f(G ) = 2, r(p3) = 0 and r(p1) = r(p2) = r(G ) = 1. G generates the string language { anbncndn | n ? N }. For instance , the string a3b3c3d3 is generated by means tuple ??, ?? is generated by A through p3. We then iterate three times the application of p2 to ??, ??, resulting in the tuple ? a3b3, c3d3?. Finally , the tuple ( string ) ? a3b3c3d3? is generated by S through application of p1. 2 3 Position sets and binarizations Throughout this section we assume an LCFRS production p : A ? g(A1, . . . , Ar ) with g defined through a tuple ~? as in section 2. We also assume that the fanout ofA and the fanout of eachAi are all bounded by two.
3.1 Production representation
We introduce here a specialized representation for p . Let $ be a fresh symbol that does not occur in p . We define the characteristic string of p as the string ? N ( p ) = ? ? 1$? ? 2$ ? ? ? $? ? f(A ), where each ?? j is obtained from ? j by removing all the occurrences of symbols in VT . Consider now some occurrence Ai of a nonterminal symbol in the righthand side of p . We define the position set of Ai , written XAi , as the set of all nonnegative integers j ? [|? N ( p )|] such that the jth symbol in ? N ( p ) is a variable of the form xi,h for some h.
Example 2 Let p : A ? g(A1, A2, A3), where g(?x1,1, x1,2?, ? x2,1?, ? x3,1, x3,2?) = ~? with ~? = ? x1,1ax2,1x1,2, x3,1bx3,2? .
We have ? N ( p ) = x1,1x2,1x1,2$x3,1x3,2, XA1 = {1, 3}, XA2 = {2} and XA3 = {5, 6}. 2 Each position set X ? [|? N ( p )|] can be represented by means of nonnegative integers i1 < i2 < ? ? ? < i2k satisfying
X = k ? j=1 [ i2j?1 + 1, i2j ].
In other words , we are decomposing X into the union of k intervals , with k as small as possible.
It is easy to see that this decomposition is always unique . We call set E = { i1, i2, . . . , i2k } the endpoint set associated with X , and we call k the fanout of X , written f(X ). Throughout this paper , we will represent p as the collection of all the position sets associated with the occurrences of nonterminals in its righthand side.
Let X1 and X2 be two disjoint position sets ( i.e ., X1 ? X2 = ?), with f(X1) = k1 and f(X2) = k2 and with associated endpoint sets E1 and E2, respectively . We define the merge of X1 and X2 as the set X1 ? X2. We extend the position set and endpoint set terminology to these merge sets as well . It is easy to check that the endpoint set associated to position set X1 ? X2 is ( E1?E2)\ ( E1?E2). We say thatX1 andX2 are 2-combinable if f(X1 ? X2) ? 2. We also say that X1 and X2 are adjacent , written X1 ? X2, if f(X1 ? X2) ? max(k1, k2). It is not difficult to see that X1 ? X2 if and only if X1 and X2 are disjoint and | E1 ? E2| ? min(k1, k2). Note also that X1 ? X2 always implies that X1 and X2 are 2-combinable ( but not the other way around).
Let X be a collection of mutually disjoint position sets . A reduction of X is the process of merging two position sets X1, X2 ? X , resulting in a new collectionX ? = ( X \{ X1, X2})?{X1?X2}.
The reduction is 2-feasible if X1 and X2 are 2-combinable . A binarization of X is a sequence of reductions resulting in a new collection with two or fewer position sets . The binarization is 2-feasible if all of the involved reductions are 2-feasible . Finally , we say that X is 2-feasible if there exists at least one 2-feasible binarization for
X .
As an important remark , we observe that when a collection X represents the position sets of all the nonterminals in the righthand side of a production p with r(p ) > 2, then a 2-feasible reduction merging XAi , XAj ? X can be interpreted as follows . We replace p by means of a new production p ? obtained from p by substituting Ai and Aj with a fresh nonterminal symbol B , so that r(p ?) = r(p ) ? 1. Furthermore , we create a new production p ?? with Ai and Aj in its righthand side , such that f(p ??) = f(B ) ? 2 and r(p ??) = 2.
Productions p ? and p ?? together are equivalent to p , but we have now achieved a local reduction in rank of one unit.
Example 3 Let p be defined as in example 2 and let X = { XA1 , XA2 , XA3}. We have that XA1 and XA2 are 2-combinable , and their merge is the new position set X = XA1 ? XA2 = {1, 2, 3}.
This merge corresponds to a 2-feasible reduction of X resulting in X ? = { X,XA3}. Such a reduction corresponds to the construction of a new production p ? : A ? g?(B,A3) with g?(?x1,1?, ? x3,1, x3,2?) = ? x1,1, x3,1bx3,2? ; g??(?x1,1, x1,2?, ? x2,1?) = ? x1,1ax2,1x1,2? . 2 It is easy to see that X is 2-feasible if and only if there exists a binarization of p that does not increase its fanout.
Example 4 It has been shown in ( Rambow and Satta , 1999) that binarization of an
LCFRS G with f(G ) = 2 and r(G ) = 3 is always possible without increasing the fanout , and that if r(G ) ? 4 then this is no longer true . Consider the LCFRS production p : A ? g(A1, A2, A3, A4), with g(?x1,1, x1,2?, ? x2,1, x2,2?, ? x3,1, x3,2?, ? x4,1, x4,2?) = ~?, ~? = ? x1,1x2,1x3,1x4,1, x2,2x4,2x1,2x3,2?. It is not difficult to see that replacing any set of two or three nonterminals in p?s righthand side forces the creation of a fresh nonterminal of fanout larger than two . 2 3.2 Greedy decision theorem The binarization algorithm presented in this paper proceeds by representing each LCFRS production p as a collection of disjoint position sets , and then finding a 2-feasible binarization of p . This binarization is computed deterministically , by an iterative process that greedily chooses merges corresponding to pairs of adjacent position sets.
The key idea behind the algorithm is based on a theorem that guarantees that any merge of adjacent sets preserves the property of 2-feasibility : Theorem 1 LetX be a 2-feasible collection of position sets . The reduction of X by merging any two adjacent position sets D1, D2 ? X results in a new collection X ? which is 2-feasible.
To prove Theorem 1 we consider that , sinceX is 2-feasible , there must exist at least one 2-feasible binarization for X . We can write this binarization ? as a sequence of reductions , where each reduction is characterized by a pair of position sets ( X1, X2) which are merged into X1 ? X2, in such a way that both each of the initial sets and the result of the merge have fanout at most 2.
We will show that , under these conditions , for every pair of adjacent position sets D1 and D2, there exists a binarization that starts with the reduction merging D1 with D2.
Without loss of generality , we assume that f(D1) ? f(D2) ( if this inequality does not hold we can always swap the names of the two position sets , since the merging operation is commutative ), and we define a function hD1?D2 : 2
N ? 2N as follows : ? hD1?D2(X ) = X ; if D1 * X ? D2 * X .
? hD1?D2(X ) = X ; if D1 ? X ? D2 ? X .
? hD1?D2(X ) = X ? D1; if D1 * X ? D2 ?
X .
? hD1?D2(X ) = X \ D1; if D1 ? X ? D2 *
X .
With this , we construct a binarization ?? from ? as follows : ? The first reduction in ?? merges the pair of position sets ( D1, D2), ? We consider the reductions in ? in order , and for each reduction o merging ( X1, X2), if X1 6= D1 and X2 6=
D1, we append a reduction o ? merging ( hD1?D2(X1), hD1?D2(X2)) to ? ?.
We will now prove that , if ? is a 2-feasible binarization , then ?? is also a 2-feasible binarization.
To prove this , it suffices to show the following:2 ( i ) Every position set merged by a reduction in ?? is either one of the original sets in X , or the result of a previous merge in ??.
(ii ) Every reduction in ?? merges a pair of position sets ( X1, X2) which are 2-combinable.
To prove ( i ) we note that by construction of ??, if an operand of a merging operation in ?? is not one of the original position sets in X , then it must be an hD1?D2(X ) for some X that appears as an operand of a merging operation in ?. Since the binarization ? is itself valid , this X must be either one of the position sets in X , or the result of a previous merge in the binarization ?. So we divide the proof into two cases : ? If X ? X : First of all , we note that X cannot be D1, since the merging operations of ? that have D1 as an operand do not produce 2It is also necessary to show that no position set is merged in two different reductions , but this easily follows from the fact that hD1?D2(X ) = hD1?D2(Y ) if and only if X ? D1 = Y ? D1. Thus , two reductions in ? can only produce conflicting reductions in ?? if they merge two position sets differing only by D1, but in this case , one of the reductions must merge D1 so it does not produce any reduction in ??.
988 a corresponding operation in ??. If X equals D2, then hD1?D2(X ) is D1 ? D2, which is the result of the first merging operation in ??.
Finally , if X is one of the position sets in X , and not D1 or D2, then hD1?D2(X ) = X , so our operand is also one of the position sets in X .
? If X is the result of a previous merging operation o in binarization ?: Then , hD1?D2(X ) is the result of a previous merging operation o ? in binarization ??, which is obtained by applying the function hD1?D2 to the operands and result of o . 3 To prove ( ii ), we show that , under the assumptions of the theorem , the function hD1?D2 preserves 2-combinability . Since two position sets of fanout ? 2 are 2-combinable if and only if they are disjoint and the fanout of their union is at most 2, it suffices to show that , for everyX,X1, X2 unions of one or more sets of X , having fanout ? 2, such that X1 6= D1, X2 6= D1 and X 6= D1; ( a ) The function hD1?D2 preserves disjointness , that is , if X1 and X2 are disjoint , then hD1?D2(X1) and hD1?D2(X2) are disjoint.
(b ) The function hD1?D2 is distributive with respect to the union of position sets , that is , hD1?D2(X1 ? X2) = hD1?D2(X1) ? hD1?D2(X2).
(c ) The function hD1?D2 preserves the property of having fanout ? 2, that is , ifX has fanout ? 2, then hD1?D2(X ) has fanout ? 2.
If X1 and X2 do not contain D1 or D2, or if one of the two unionsX1 orX2 containsD1?D2, properties ( a ) and ( b ) are trivial , since the function hD1?D2 behaves as the identity function in these cases.
It remains to show that ( a ) and ( b ) are true in the following cases : ? X1 contains D1 but not D2, and X2 does not contain D1 or D2: 3Except if one of the operands of the operation o was D1.
But in this case , if we call the other operand Z , then we have that X = D1 ? Z . If Z contains D2, then X = D1 ? Z = hD1?D2(X ) = hD1?D2(Z ), so we apply this same reasoning with hD1?D2(Z ) where we cannot fall into this case , since there can be only one merge operation in ? that uses D1 as an operand . If Z does not contain D2, then we have that hD1?D2(X ) = X \ D1 = Z = hD1?D2(Z ), so we can do the same.
In this case , ifX1 andX2 are disjoint , we can writeX1 = Y1?D1, such that Y1, X2, D1 are pairwise disjoint . By definition , we have that hD1?D2(X1) = Y1, and hD1?D2(X2) =
X2, which are disjoint , so ( a ) holds.
Property ( b ) also holds because , with these expressions for X1 and X2, we can calculate hD1?D2(X1 ? X2) = Y1 ? X2 = hD1?D2(X1) ? hD1?D2(X2).
? X1 containsD2 but notD1,X2 does not contain D1 or D2: In this case , if X1 and X2 are disjoint , we can write X1 = Y1 ? D2, such that Y1, X2, D1, D2 are pairwise disjoint . By definition , hD1?D2(X1) = Y1 ? D2 ? D1, and hD1?D2(X2) = X2, which are disjoint , so ( a ) holds.
Property ( b ) also holds , since we can check that hD1?D2(X1 ? X2) = Y1 ? X2 ? D2 ?
D1 = hD1?D2(X1) ? hD1?D2(X2).
? X1 contains D1 but not D2, X2 contains D2 but not D1: In this case , ifX1 andX2 are disjoint , we can writeX1 = Y1?D1 andX2 = Y2?D2, such that Y1, Y2, D1, D2 are pairwise disjoint . By definition , we know that hD1?D2(X1) = Y1, and hD1?D2(X2) = Y2 ? D1 ? D2, which are disjoint , so ( a ) holds.
Finally , property ( b ) also holds in this case , since hD1?D2(X1 ? X2) = Y1 ? X2 ? D2 ?
D1 = hD1?D2(X1) ? hD1?D2(X2).
This concludes the proof of ( a ) and ( b).
To prove ( c ), we consider a position set X , union of one or more sets of X , with fanout ? 2 and such that X 6= D1. First of all , we observe that if X does not contain D1 or D2, or if it contains D1 ? D2, ( c ) is trivial , because the function hD1?D2 behaves as the identity function in this case . So it remains to prove ( c ) in the cases where X contains D1 but not D2, and where X contains D2 but not D1. In any of these two cases , if we call E(Y ) the endpoint set associated with an arbitrary position set Y , we can make the following observations : 1. Since X has fanout ? 2, E(X ) contains at most 4 endpoints.
2. SinceD1 has fanout f(D1),E(D1) contains at most 2f(D1) endpoints.
989 3. SinceD2 has fanout f(D2),E(D2) contains at most 2f(D2) endpoints.
4. Since D1 and D2 are adjacent , we know that E(D1) ? E(D2) contains at least min(f(D1), f(D2)) = f(D1) endpoints.
5. Therefore , E(D1) \ ( E(D1) ? E(D2)) can contain at most 2f(D1) ? f(D1) = f(D1) endpoints.
6. On the other hand , sinceX contains only one of D1 and D2, we know that the endpoints where D1 is adjacent to D2 must also be endpoints of X , so that E(D1) ? E(D2) ?
E(X ). Therefore , E(X)\(E(D1)?E(D2)) can contain at most 4? f(D1) endpoints.
Now , in the case where X contains D1 but not D2, we know that hD1?D2(X ) = X\D1. We calculate a bound for the fanout ofX\D1 as follows : we observe that all the endpoints in E(X \ D1) must be either endpoints of X or endpoints of
D1, since E(X ) = ( E(X \ D1) ? E(D1)) \ ( E(X \ D1) ? E(D1)), so every position that is in E(X \ D1) but not in E(D1) must be in E(X).
But we also observe that E(X \ D1) cannot contain any of the endpoints where D1 is adjacent to D2 ( i.e ., the members of E(D1) ? E(D2)), since X \ D1 does not contain D1 or D2. Thus , we can say that any endpoint of X \ D1 is either a member of E(D1) \ ( E(D1) ? E(D2)), or a member of E(X ) \ ( E(D1) ? E(D2)).
Thus , the number of endpoints in E(X \ D1) cannot exceed the sum of the number of endpoints in these two sets , which , according to the reason-ings above , is at most 4 ? f(D1) + f(D1) = 4.
Since E(X \ D1) cannot contain more than 4 endpoints , we conclude that the fanout of X \ D1 is at most 2, so the function hD1?D2 preserves the property of position sets having fanout ? 2 in this case.
In the other case , where X contains D2 but not D1, we follow a similar reasoning : in this case , hD1?D2(X ) = X ? D1. To bound the fanout of X ? D1, we observe that all the endpoints in E(X ? D1) must be either in E(X ) or in E(D1), since E(X ? D1) = ( E(X)?E(D1)) \ ( E(X )? E(D1)). But we also know that E(X ? D1) cannot contain any of the endpoints where D1 is adjacent to D2 ( i.e ., the members of E(D1)?E(D2)), since X ? D1 contains both D1 and D2. Thus , we can say that any endpoint of X ? D1 is either a 1: Function BINARIZATION(p ) 2: A ? ?; { working agenda } 3: R ? ??; { empty list of reductions } 4: for all i from 1 to r(p ) do 5: A ? A ? { XAi }; 6: while | A | > 2 and A contains two adjacent position sets do 7: choose X1, X2 ? A such that X1 ? X2; 8: X ? X1 ? X2; 9: A ? ( A \ { X1, X2}) ? { X }; 10: append ( X1, X2) toR ; 11: if | A | = 2 then 12: return R ; 13: else 14: return fail ; Figure 1: Binarization algorithm for a production p : A ? g(A1, . . . , Ar(p )). Result is either a list of reductions or failure.
member of E(D1)\ ( E(D1)?E(D2)), or a member of E(X ) \ ( E(D1) ? E(D2)). Reasoning as in the previous case , we conclude that the fanout of X ? D1 is at most 2, so the function hD1?D2 also preserves the property of position sets having fanout ? 2 in this case.
This concludes the proof of Theorem 1.
4 Binarization algorithm
Let p : A ? g(A1, . . . , Ar(p )) be a production with r(p ) > 2 from some LCFRS with fanout not greater than 2. Recall from Subsection 3.1 that each occurrence of nonterminal Ai in the righthand side of p is represented as a position setXAi .
The specification of an algorithm for finding a 2-feasible binarization of p is reported in Figure 1.
The algorithm uses an agenda A as a working set , where all position sets that still need to be processed are stored . A is initialized with the position sets XAi , 1 ? i ? r(p ). At each step in the algorithm , the size of A represents the maximum rank among all productions that can be obtained from the reductions that have been chosen so far in the binarization process . The algorithm also uses a list R , initialized as the empty list , where all reductions that are attempted in the binarization process are appended.
At each iteration , the algorithm performs a reduction by arbitrarily choosing a pair of adjacent endpoint sets from the agenda and by merging them . As already discussed in Subsection 3.1, this input production p that preserves its generative capacity and that decreases its rank by one unit.
We stop the iterations of the algorithm when we reach a state in which there are no more than two position sets in the agenda . This means that the binarization process has come to an end with the reduction of p to a set of productions equivalent to p and with rank and fanout at most 2. This set of productions can be easily constructed from the output list R . We also stop the iterations in case no adjacent pair of position sets can be found in the agenda . If the agenda has more than two position sets , this means that no binarization has been found and the algorithm returns a failure.
4.1 Correctness
To prove the correctness of the algorithm in Figure 1, we need to show that it produces a 2-feasible binarization of the given production p whenever such a binarization exists . This is established by the following theorem : Theorem 2 LetX be a 2-feasible collection of position sets , such that the union of all sets in X is a position set with fanout ? 2. The procedure : while ( X contains any pair of adjacent sets X1, X2 ) reduce X by merging X1 with X2; always finds a 2-feasible binarization of X .
In order to prove this , the loop invariant is that X is a 2-feasible set , and that the union of all position sets in X has fanout ? 2: reductions can never change the union of all sets in X , and Theorem 1 guarantees us that every change to the state of X maintains 2-feasibility . We also know that the algorithm eventually finishes , because every iteration reduces the amount of position sets in X by 1; and the looping condition will not hold when the number of sets gets to be 1.
So it only remains to prove that the loop is only exited if X contains at most two position sets . If we show this , we know that the sequence of reductions produced by this procedure is a 2-feasible binarization . Since the loop is exited when X is 2-feasible but it contains no pair of adjacent position sets , it suffices to show the following : Proposition 1 Let X be a 2-feasible collection of position sets , such that the union of all the sets in X is a position set with fanout ? 2. IfX has more than two elements , then it contains at least a pair of adjacent position sets . 2 Let X be a 2-feasible collection of more than two position sets . Since X is 2-feasible , we know that there must be a 2-feasible binarization of X .
Suppose that ? is such a binarization , and let D1 and D2 be the two position sets that are merged in the first reduction of ?. Since ? is 2-feasible , D1 and D2 must be 2-combinable.
If D1 and D2 are adjacent , our proposition is true . If they are not adjacent , then , in order to be 2-combinable , the fanout of both position sets must be 1: if any of them had fanout 2, their union would need to have fanout > 2 for D1 and D2 not to be adjacent , and thus they would not be 2-combinable . Since D1 and D2 have fanout 1 and are not adjacent , their sets of endpoints are of the form { b1, b2} and { c1, c2}, and they are disjoint.
If we call EX the set of endpoints corresponding to the union of all the position sets in X and ED1D2 = { b1, b2, c1, c2}, we can show that at least one of the endpoints in ED1D2 does not appear in EX , since we know that EX can have at most 4 elements ( as the union has fanout ? 2) and that it cannot equalED1D2 because this would mean that X = { D1, D2}, and by hypothesis X has more than two position sets . If we call this endpoint x , this means that there must be a position set D3 in X , different from D1 and D2, that has x as one of its endpoints . Since D1 and D2 have fanout 1, this implies that D3 must be adjacent either to D1 or to D2, so we conclude the proof.
4.2 Implementation and complexity
We now turn to the computational analysis of the algorithm in Figure 1. We define the length of an LCFRS production p , written | p |, as the sum of the length of all strings ? j in ~? in the definition of the linear , nonerasing function associated with p . Since we are dealing with LCFRS of fanout at most two , we easily derive that | p | = O(r(p)).
In the implementation of the algorithm it is convenient to represent each position set by means of the corresponding endpoint set . Since at any time in the computation we are only processing position sets with fanout not greater than two , each endpoint set will contain at most four integers.
The for-loop at lines 4 and 5 in the algorithm can be easily implemented through a left-to-right scan of the characteristic string ? N ( p ), detecting the endpoint sets associated with each position set XAi . This can be done in constant time for each At each iteration of the while-loop at lines 6 to 10 we have that A is reduced in size by one unit . This means that the number of iterations is bounded by r(p ). We will show below that each iteration of this loop can be executed in constant time . We can therefore conclude that our binarization algorithm runs in optimal time O(|p|).
In order to run in constant time each single iteration of the while-loop at lines 6 to 10, we need to perform some additional bookkeeping . We use two arrays Ve and Va , whose elements are indexed by the endpoints associated with characteristic string ? N ( p ), that is , integers i ? [0, |? N ( p)|].
For each endpoint i , Ve[i ] stores all the endpoint sets that share endpoint i . Since each endpoint can be shared by at most two endpoint sets , such a data structure has sizeO(|p |). If there exists some position setX inAwith leftmost endpoint i , then Va[i ] stores all the position sets ( represented as endpoint sets ) that are adjacent to X . Since each position set can be adjacent to at most four other position sets , such a data structure has size O(|p |). Finally , we assume we can go back and forth between position sets in the agenda and their leftmost endpoints.
We maintain arrays Ve and Va through the following simple procedures.
? Whenever a new position set X is added to A , for each endpoint i of X we add X to Ve[i ]. We also check whether any position set in Ve[i ] other than X is adjacent to X , and add these position sets to Va[il ], where il is the leftmost end point of X .
? Whenever some position set X is removed from A , for each endpoint i of X we remove X from Ve[i ]. We also remove all of the position sets in Va[il ], where il is the leftmost end point of X .
It is easy to see that , for any position set X which is added/removed from A , each of the above procedures can be executed in constant time.
We maintain a set I of integer numbers i ? [0, |? N ( p )|] such that i ? I if and only if Va[i ] is not empty . Then at each iteration of the while-loop at lines 6 to 10 we pick up some index in I and retrieve at Va[i ] some pairX,X ? such thatX ? X ?.
Since X,X ? are represented by means of endpoint sets , we can compute the endpoint set ofX?X ? in constant time . Removal of X,X ? and addition of X?X ? in our data structures Ve and Va is then performed in constant time , as described above . This proves our claim that each single iteration of the while loop can be executed in constant time.
5 Discussion
We have presented an algorithm for the binarization of a LCFRS with fanout 2 that does not increase the fanout , and have discussed how this can be applied to improve parsing efficiency in several practical applications . In the algorithm of Figure 1, we can modify line 14 to return R even in case of failure . If we do this , when a binarization with fanout ? 2 does not exist the algorithm will still provide us with a list of reductions that can be converted into a set of productions equivalent to p with fanout at most 2 and rank bounded by some rb , with 2 < rb ? r(p ). In case rb < r(p ), we are not guaranteed to have achieved an optimal reduction in the rank , but we can still obtain an asymptotic improvement in parsing time if we use the new productions obtained in the transformation.
Our algorithm has optimal time complexity , since it works in linear time with respect to the input production length . It still needs to be investigated whether the proposed technique , based on determinization of the choice of the reduction , can also be used for finding binarizations for LCFRS with fanout larger than two , again without increasing the fanout . However , it seems unlikely that this can still be done in linear time , since the problem of binarization for LCFRS in general , i.e ., without any bound on the fanout , might not be solvable in polynomial time . This is still an open problem ; see ( Go?mez-Rodr??guez et al , 2009) for discussion.
Acknowledgments
The first author has been supported by Ministerio de Educacio?n y Ciencia and FEDER ( HUM2007-66607-C04) and Xunta de Galicia ( PGIDIT07SIN005206PR , INCITE08E1R104022ES,
INCITE08ENA305025ES , INCITE08PXIB302179PR and Rede Galega de Procesamento da Linguaxe e Recuperacio?n de Informacio?n).
The second author has been partially supported by MIUR under project PRIN No . 2007TJN-
ZRE 002.
992
References
Pierre Boullier . 2004. Range concatenation grammars.
In H . Bunt , J . Carroll , and G . Satta , editors , New Developments in Parsing Technology , volume 23 of Text , Speech and Language Technology , pages 269? 289. Kluwer Academic Publishers.
Ha?kan Burden and Peter Ljunglo?f . 2005. Parsing linear contextfree rewriting systems . In IWPT05, 9th International Workshop on Parsing Technologies.
David Chiang . 2005. A hierarchical phrasebased model for statistical machine translation . In Proceedings of the 43rd ACL , pages 263?270.
Carlos Go?mez-Rodr??guez , Marco Kuhlmann , Giorgio Satta , and David Weir . 2009. Optimal reduction of rule length in linear contextfree rewriting systems.
In Proc . of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies Conference ( NAACL?09:HLT),
Boulder , Colorado . To appear.
Aravind K . Joshi and Leon S . Levy . 1977. Constraints on local descriptions : Local transformations . SIAM
J . Comput ., 6(2):272?284.
Aravind K . Joshi , K . Vijay-Shanker , and David Weir.
1991. The convergence of mildly context-sensitive grammatical formalisms . In P . Sells , S . Shieber , and T . Wasow , editors , Foundational Issues in Natural Language Processing . MIT Press , Cambridge MA.
Marco Kuhlmann and Giorgio Satta . 2009. Treebank grammar techniques for nonprojective dependency parsing . In Proc . of the 12th Conference of the European Chapter of the Association for Computational Linguistics ( EACL09), pages 478?486,
Athens , Greece.
I . Dan Melamed . 2003. Multitext grammars and synchronous parsers . In Proceedings of HLTNAACL 2003.
Rebecca Nesson and Stuart M . Shieber . 2006. Simpler TAG semantics through synchronization . In Proceedings of the 11th Conference on Formal Grammar , Malaga , Spain , 29?30 July.
Owen Rambow and Giorgio Satta . 1999. Independent parallelism in finite copying parallel rewriting systems . Theoretical Computer Science , 223:87?120.
Giorgio Satta . 1998. Trading independent for synchronized parallelism in finite copying parallel rewriting systems . Journal of Computer and System
Sciences , 56(1):27?45.
Hiroyuki Seki , Takashi Matsumura , Mamoru Fujii , and Tadao Kasami . 1991. On multiple contextfree grammars . Theoretical Computer Science , 88:191? 229.
K . Vijay-Shanker , David J . Weir , and Aravind K . Joshi.
1987. Characterizing structural descriptions produced by various grammatical formalisms . In Proceedings of the 25th Meeting of the Association for
Computational Linguistics ( ACL?87).
Hao Zhang , Daniel Gildea , and David Chiang . 2008.
Extracting synchronous grammar rules from word-level alignments in linear time . In 22nd International Conference on Computational Linguistics ( Coling ), pages 1081?1088, Manchester , England,
UK.
993
