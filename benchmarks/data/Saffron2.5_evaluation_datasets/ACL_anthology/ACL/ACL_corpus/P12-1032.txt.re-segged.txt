Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics , pages 302?310,
Jeju , Republic of Korea , 814 July 2012. c?2012 Association for Computational Linguistics
Learning Translation Consensus with Structured Label Propagation

?Shujie Liu *, ? Chi-Ho Li , ? Mu Li and ? Ming Zhou
? Harbin Institute of Technology ? Microsoft Research Asia
Harbin , China Beijing , China
shujieliu@mtlab.hit.edu.cn

{chl , muli , mingzhou}@microsoft.com


Abstract
In this paper , we address the issue for learning better translation consensus in machine translation ( MT ) research , and explore the search of translation consensus from similar , rather than the same , source sentences or their spans . Unlike previous work on this topic , we formulate the problem as structured labeling over a much smaller graph , and we propose a novel structured label propagation for the task.
We convert such graphbased translation consensus from similar source strings into useful features both for nbest output reranking and for decoding algorithm.
Experimental results show that , our method can significantly improve machine translation performance on both IWSLT and NIST data , compared with a state-of-the-art baseline.
1 Introduction
Consensus in translation has ? gained more and more attention in recent years . The principle of consensus can be sketched as ? a translation candidate is deemed more plausible if it is supported by other translation candidates .? The actual formulation of the principle depends on whether the translation candidate is a complete sentence or just a span of it , whether the candidate is the same as or similar to the supporting candidates , and whether the supporting candidates come from the same or different MT system.
? This work has been done while the first author was visiting
Microsoft Research Asia.
Translation consensus is employed in those minimum Bayes risk ( MBR ) approaches where the loss function of a translation is defined with respect to all other translation candidates . That is , the translation with the minimal Bayes risk is the one to the greatest extent similar to other candidates . These approaches include the work of Kumar and Byrne (2004), which reranks the nbest output of a MT decoder , and the work of Tromble et al (2008) and Kumar et al (2009), which does MBR decoding for lattices and hypergraphs.
Others extend consensus among translations from the same MT system to those from different MT systems . Collaborative decoding ( Li et al , 2009) scores the translation of a source span by its ngram similarity to the translations by other systems . Hypothesis mixture decoding ( Duan et al , 2011) performs a second decoding process where the search space is enriched with new hypotheses composed out of existing hypotheses from multiple systems.
All these approaches are about utilizing consensus among translations for the same ( span of ) source sentence . It should be noted that consensus among translations of similar source sentences/spans is also helpful for good candidate selection . Consider the examples in Figure 1. For the source ( Chinese ) span ??? ? ?? ? ? ?, the MT system produced the correct translation for the second sentence , but it failed to do so for the first one . If the translation of the first sentence could take into consideration the translation of the second sentence , which is similar to but not exactly the same as the first one , the final translation output may be improved.
Following this line of reasoning , a discriminative learning method is proposed to constrain the translation of an input sentence using translation memory ( TM ) systems ( Ma et al , 2011). A classifier is applied to rerank the nbest output of a decoder , taking as features the information about the agreement with those similar translation examples . Alexandrescu and Kirchhoff (2009) proposed a graphbased semisupervised model to rerank nbest translation output . Note that these two attempts are about translation consensus for similar sentences , and about reranking of nbest output . It is still an open question whether translation consensus for similar sentences/spans can be applied to the decoding process . Moreover , the method in Alexandrescu and Kirchhoff (2009) is formulated as a typical and simple label propagation , which leads to very large graph , thus making learning and search inefficient.
(c.f . Section 3.)
In this paper , we attempt to leverage translation consensus among similar ( spans of ) source sentences in bilingual training data , by a novel graphbased model of translation consensus.
Unlike Alexandrescu and Kirchhoff (2009), we reformulate the task of seeking translation consensus among source sentences as structured labeling . We propose a novel label propagation algorithm for structured labeling , which is much more efficient than simple label propagation , and derive useful MT decoder features out of it . We conduct experiments with IWSLT and NIST data , and experimental results show that , our method can improve the translation performance significantly on both data sets , compared with a state-of-the-art baseline.
2 Graphbased Translation Consensus
Our MT system with graphbased translation consensus adopts the conventional loglinear model . For the source string ? , the conditional probability of a translation candidate ? is defined as : ???|?? ? exp ?? ???????, ???? ?? ? exp ?? ????????, ???? ????????? (1) where ? is the feature vector , ? is the feature weights , and ???? is the set of translation hypotheses in the search space.
Based on the commonly used features , two kinds of feature are added to equation (1), one is graphbased consensus features , which are about consensus among the translations of similar sentences/spans ; the other is local consensus features , which are about consensus among the translations of the same sentence/span . We develop a structured label propagation method , which can calculate consensus statistics from translation candidates of similar source sentences/spans.
In the following , we explain why the standard , simple label propagation is not suitable for translation consensus , and then introduce how the problem is formulated as an instance of structured labeling , with the proposed structured label propagation algorithm , in section 3. Before elaborating how the graph model of consensus is constructed for both a decoder and Nbest output reranking in section 5, we will describe how the consensus features and their feature weights can be trained in a semisupervised way , in section 4.
3 Graphbased Structured Learning
In general , a graphbased model assigns labels to instances by considering the labels of similar instances . A graph is constructed so that each instance is represented by a node , and the weight of the edge between a pair of nodes represents the similarity between them . The gist of graphbased model is that , if two instances are connected by a strong edge , then their labels tend to be the same ( Zhu , 2005).

IWSLT Chinese to English Translation Task
Src ? ??? ?? ? ?? ? ? ?
Ref Do you have any tea under five hundred dollars ?
Best1 Do you have any less than five hundred dollars tea ?
Src ? ?? ?? ? ?? ? ? .
Ref I would like some tea under five hundred dollars .
Best1 I would like tea under five hundred dollars .
Figure 1. Two sentences from IWSLT ( Chinese to English ) data set . " Src " stands for the source sentence , and " Ref " means the reference sentence . " Best1" is the final output of the decoder.
303
In MT , the instances are source sentences or spans of source sentences , and the possible labels are their translation candidates . This scenario differs from the general case of graphbased model in two aspects . First , there are an indefinite , or even intractable , number of labels . Each of them is a string of words rather than a simple category . In the following we will call these labels as structured labels ( Berlett et al , 2004). Second , labels are highly ? instance-dependent ?. In most cases , for any two different ( spans of ) source sentences , however small their difference is , their correct labels ( translations ) are not exactly the same . Therefore , the principle of graphbased translation consensus must be reformulated as , if two instances ( source spans ) are similar , then their labels ( translations ) tend to be similar ( rather than the same).
Note that Alexandrescu and Kirchhoff (2009) do not consider translation as structured labeling . In their graph , a node does not represent only a source sentence but a pair of source sentence and its candidate translation , and there are only two possible labels for each node , namely , 1 ( this is a good translation pair ) and 0 ( this is not a good translation pair ). Thus their graphbased model is a normal example of the general graphbased model.
The biggest problem of such a perspective is inefficiency . An average MT decoder considers a vast amount of translation candidates for each source sentence , and therefore the corresponding graph also contains a vast amount of nodes , thus rendering learning over a large dataset is infeasible.
3.1 Label Propagation for General Graphbased Models A general graphbased model is iteratively trained by label propagation , in which ??,?, the probability of label l for the node ?, is updated with respect to the corresponding probabilities for ?? s neighboring nodes ???? . In Zhu (2005), the updating rule is expressed in a matrix calculation . For convenience , the updating rule is expressed for each label here : ??,???? ? ? ???, ????,?? ?????? (2) where ???, ??, the propagating probability , is defined as : ???, ?? ? ??,?? ??,????????? (3) ??,? defines the weight of the edge , which is a similarity measure between nodes ? and ?.
Note that the graph contains nodes for training instances , whose correct labels are known . The probability of the correct label to each training instance is reset to 1 at the end of each iteration.
With a suitable measure of instance/node similarity , it is expected that an unlabeled instance/node will find the most suitable label from similar labeled nodes.
3.2 Structured Label Propagation for Graphbased Learning In structured learning like MT , different instances would not have the same correct label , and so the updating rule (2) is no longer valid , as the value of ??,? should not be calculated based on ??,? . Here we need a new updating rule so that ??,? can be updated with respect to ??,?? , where in general ? ? ??.
Let us start with the model in Alexandrescu and Kirchhoff (2009). According to them , a node in the graph represents the pair of some source sentence/span ?? and its translation candidate ?? .
The updating rule ( for the label 1 or 0) is : ???,????? ? ? ????, ??, ???, ????????,???? ???,????????,?? ??4? where ????, ?? is the set of neighbors of the node ??, ?).
When the problem is reformulated as structured labeling , each node represents the source sentence/span only , and the translation candidates become labels . The propagating probability ????, ??, ???, ????? has to be reformulated accordingly . A natural way is to decompose it into a component for nodes and a component for labels.
Assuming that the two components are independent , then : ????, ??, ???, ???? ? ????, ??? ????, ????????????5? where ????, ??? is the propagating probability from source sentence/span ?? to ? , and ????, ??? is that from translation candidate ?? to ?.
The set of neighbors ????, ?? of a pair ??, ?? has also to be reformulated in terms of the set of neighbors ???? of a source sentence/span ?: ????, ?? ? ????, ???|?? ? ????, ?? ? ????????6? for?source???.?The new updating rule will then be :? ??,???? ? ? ????, ??? ????, ??????,??? ???????,???????? ? ? ? ? ????, ??? ????, ??????,??? ??????????????? ? ? ? ????, ??? ? ????, ??????,??? ??????????????? ???7? The new rule updates the probability of a translation ? of a source sentence/span ? with probabilities of similar translations ?? s of some similar source sentences/spans ?? s.
Propagation probability ????, ??? is as defined in equation (3), and ????, ??? is defined given some similarity measure ?????, ??? between labels ? and ??: ????, ??? ? ??? ??, ??? ? ?????, ????????????? ? ?????????????8? Note that rule (2) is a special case of rule (7), when ?????, ??? is defined as : ?????, ??? ? ? ??????????? ???? ? ???; ?????????; 4 Features and Training The last section sketched the structured label propagation algorithm . Before elaborating the details of how the actual graph is constructed , we would like to first introduce how the graphbased translation consensus can be used in an MT system.
4.1 Graphbased Consensus Features
The probability as estimated in equation (7) is taken as a group of new features in either a decoder or an nbest output reranker . We will call these features collectively as graphbased consensus features ( GC ): ????, ?? ?????????????????????????????????????????????????????????????????9?? log ?? ? ????, ??? ? ????, ??????,?? ??????????????? ?? Recall that , ???? refers to source sentences/spans which are similar with ? , and ????? refers to translation candidates of ?? . ???,?? is initialized with the translation posterior of ?? given ?? . The translation posterior is normalized in the nbest list.
For the nodes representing the training sentence pairs , this posterior is fixed . ? ????, ??? is the propagating probability in equation (8), with the similarity measure ?????, ??? defined as the Dice coefficient over the set of all ngrams in ? and those in ??. That is , ?????, ??? ? ????????????, ????????? where ??????? is the set of ngrams in string ?, and ??????, ?? is the Dice coefficient over sets ? and ?: ??????, ?? ? 2|? ? ?||?| ? |?| We take 1 ? ? ? 4 for similarity between translation candidates , thus leading to four features.
The other propagating probability ????, ??? , as defined in equation (3), takes symmetrical sentence level BLEU as similarity measure1: ??,?? ? ?? ? ??? ????????, ??? where ??? ???????, ??? is defined as follows ( Liang et al , 2006): ??? ???????, ??? ?? ? ? ??????, ? ?? 2????? ? ??? ????10? where ? ? ??????, ??? is the IBM BLEU score computed over igrams for hypothesis ? using ?? as reference.
In theory we could use other similarity measures such as edit distance , string kernel . Here simple ngram similarity is used for the sake of efficiency.
4.2 Other Features
In addition to graphbased consensus features , we also propose local consensus features , defined over the nbest translation candidates as : ????, ?? ? log ? ? ????|?? ?????, ??? ??????? ?? (11) 1 BLEU is not symmetric , which means , different scores are obtained depending on which one is reference and which one is hypothesis.
305 where ????|??? is translation posterior . Like ?? , there are four features with respect to the value of n in ngram similarity measure.
We also use other fundamental features , such as translation probabilities , lexical weights , distortion probability , word penalty , and language model probability.
4.3 Training Method
When graphbased consensus is applied to an MT system , the graph will have nodes for training data , development ( dev ) data , and test data ( details in Section 5). There is only one label/translation for each training data node . For each dev/test data node , the possible labels are the nbest translation candidates from the decoder . Note that there is mutual dependence between the consensus graph and the decoder . On the one hand , the MT decoder depends on the graph for the GC features . On the other hand , the graph needs the decoder to provide the translation candidates as possible labels , and their posterior probabilities as initial values of various ??,? . Therefore , we can alternatively update graphbased consensus features and feature weights in the loglinear model.
Algorithm 1 Semi-Supervised Learning ??? ? 0; ??=??????????, ????, ????; while not converged do ?? ? ?????????????, ??????, ????, ?????, ???.
????? ? ????????????.
???? ? ?????????, ????, ?????? end while return last (???,???) Algorithm 1 outlines our semisupervised method for such alternative training . The entire process starts with a decoder without consensus features . Then a graph is constructed out of all training , dev , and test data . The subsequent structured label propagation provides ?? feature values to the MT decoder . The decoder then adds the new features and retrains all the feature weights?by Minimum Error Rate Training ( MERT ) ( Och , 2003). The decoder with new feature weights then provides new nbest candidates and their posteriors for constructing another consensus graph , which in turn gives rise to next round of MERT . This alternation of structured label propagation and MERT stops when the BLEU score on dev data converges , or a preset limit (10 rounds ) is reached.
5 Graph Construction
A technical detail is still needed to complete the description of graphbased consensus , namely , how the actual consensus graph is constructed . We will divide the discussion into two sections regarding how the graph is used.
5.1 Graph Construction for ReRanking
When graphbased consensus is used for reranking the nbest outputs of a decoder , each node in the graph corresponds to a complete sentence . A separate node is created for each source sentence in training data , dev data , and test data . For any node from training data ( henceforth training node ), it is labeled with the correct translation , and ??,? is fixed as 1. If there are sentence pairs with the same source sentence but different translations , all the translations will be assigned as labels to that source sentence , and the corresponding probabilities are estimated by MLE . There is no edge between training nodes , since we suppose all the sentences of the training data are correct , and it is pointless to reestimate the confidence of those sentence pairs.
Each node from dev/test data ( henceforth test node ) is unlabeled , but it will be given an nbest list of translation candidates as possible labels from a MT decoder . The decoder also provides translation posteriors as the initial confidences of 1, e1 a1 c b 2, e1 a1 b c 3, e2 a1 b c
E A B C 1, f1 b c d1 2, f1 d1 b c 3, f2 d1 b c e1 a1 m n e1 a1 b n e1 d1 b n 0.5 0.5 0.75 0.5 Figure 2. A toy graph constructed for reranking.
306 the labels . A test node can be connected to training nodes and other test nodes . If the source sentences of a test node and some other node are sufficiently similar , a similarity edge is created between them.
In our experiment we measure similarity by symmetrical sentence level BLEU of source sentences , and 0.3 is taken as the threshold for edge creation.
Figure 2 shows a toy example graph . Each node is depicted as rectangle with the upper half showing the source sentence and the lower half showing the correct or possible labels . Training nodes are in grey while test nodes are in white.
The edges between the nodes are weighted by the similarities between the corresponding source sentences.
5.2 Graph Construction for Decoding
Graphbased consensus can also be used in the decoding algorithm , by reranking the translation candidates of not only the entire source sentence but also every source span . Accordingly the graph does not contain only the nodes for source sentences but also the nodes for all source spans . It is needed to find the candidate labels for each source span.
It is not difficult to handle test nodes , since the purpose of MT decoder is to get al possible segmentations of a source sentence in dev/test data , search for the translation candidates of each source span , and calculate the probabilities of the candidates . Therefore , the cells in the search space of a decoder can be directly mapped as test nodes in the graph.
Training nodes can be handled similarly , by applying forced alignment . Forced alignment performs phrase segmentation and alignment of each sentence pair of the training data using the full translation system as in decoding ( Wuebker et al ., 2010). In simpler term , for each sentence pair in training data , a decoder is applied to the source side , and all the translation candidates that do not match any substring of the target side are deleted.
The cells of in such a reduced search space of the decoder can be directly mapped as training nodes in the graph , just as in the case of test nodes . Note that , due to pruning in both decoding and translation model training , forced alignment may fail , i.e . the decoder may not be able to produce target side of a sentence pair . In such case we still map the cells in the search space as training nodes.
Note also that the shorter a source span is , the more likely it appears in more than one source sentence . All the translation candidates of the same source span in different source sentences are merged.
Edge creation is the same as that in graph construction for nbest reranking , except that two nodes are always connected if they are about a span and its subspan . This exception ensures that shorter spans can always receive propagation from longer ones , and vice versa.
Figure 3 shows a toy example . There is one node for the training sentence " E A M N " and two nodes for the test sentences " E A B C " and " F D B C ". All the other nodes represent spans . The node " M N " and " E A " are created according to the forced alignment result of the sentence " E A M N".
As we see , the translation candidates for " M N " and " E A " are not the substrings from the target sentence of " E A M N ". There are two kinds of edges . Dash lines are edges connecting nodes of a span and its subspan , such as the one between " E A B C " and " E ". Solid lines are edges connecting nodes with sufficient source side ngram similarity , such as the one between " E A M N " and " E A B
C".

Figure 3. A toy example graph for decoding.
Edges in dash line indicate relation between a span and its subspan , whereas edges of solid line indicate source side similarity.
307 6 Experiments and Results
In this section , graphbased translation consensus is tested on the Chinese to English translation tasks.
The evaluation method is the case insensitive IBM BLEU4 ( Papineni et al , 2002). Significant testing is carried out using bootstrap resampling method proposed by Koehn (2004) with a 95% confidence level.
6.1 Experimental Data Setting and Baselines We test our method with two data settings : one is IWSLT data set , the other is NIST data set . Our baseline decoder is an inhouse implementation of Bracketing Transduction Grammar ( Dekai Wu , 1997) ( BTG ) in CKY-style decoding with a lexical reordering model trained with maximum entropy ( Xiong et al , 2006). The features we used are commonly used features as standard BTG decoder , such as translation probabilities , lexical weights , language model , word penalty and distortion probabilities.
Our IWSLT data is the IWSLT 2009 dialog task data set . The training data include the BTEC and SLDB training data . The training data contains 81k sentence pairs , 655k Chinese words and 806 English words . The language model is 5gram language model trained with the target sentences in the training data . The test set is devset9, and the development set for MERT comprises both devset8 and the Chinese DIALOG set . The baseline results on IWSLT data are shown in Table 1.
devset8+dialog devset9
Baseline 48.79 44.73
Table 1. Baselines for IWSLT data
For the NIST data set , the bilingual training data we used is NIST 2008 training set excluding the Hong Kong Law and Hong Kong Hansard . The training data contains 354k sentence pairs , 8M Chinese words and 10M English words . The language model is 5gram language model trained with the GigaWord corpus plus the English sentences in the training data . The development data utilized to tune the feature weights of our decoder is NIST?03 evaluation set , and test sets are NIST?05 and NIST?08 evaluation sets . The baseline results on NIST data are shown in Table 2.
NIST'03 NIST'05 NIST'08
Baseline 38.57 38.21 27.52
Table 2. Baselines for NIST data 6.2 Experimental Result Table 3 shows the performance of our consensus-based reranking and decoding on the IWSLT data set . To perform consensus-based reranking , we first use the baseline decoder to get the nbest list for each sentence of development and test data , then we create graph using the nbest lists and training data as we described in section 5.1, and perform semisupervised training as mentioned in section 4.3. As we can see from Table 3, our consensus-based reranking ( G-Re-Rank ) outperforms the baseline significantly , not only for the development data , but also for the test data.
Instead of using graphbased consensus confidence as features in the loglinear model , we perform structured label propagation ( Struct-LP ) to rerank the nbest list directly , and the similarity measures for source sentences and translation candidates are symmetrical sentence level BLEU ( equation (10)). Using Struct-LP , the performance is significantly improved , compared with the baseline , but not as well as G-Re-Rank.
devset8+dialog devset9
Baseline 48.79 44.73
Struct-LP 49.86 45.54
G-Re-Rank 50.66 46.52
G-Re-Rank-GC 50.23 45.96
G-Re-Rank-LC 49.87 45.84
G-Decode 51.20 47.31
G-Decode-GC 50.46 46.21
G-Decode-LC 50.11 46.17
Table 3. Consensus-based reranking and decoding for IWSLT data set . The results in bold type are significantly better than the baseline.
We use the baseline system to perform forced alignment procedure on the training data , and create span nodes using the derivation tree of the forced alignment . We also saved the spans of the sentences from development and test data , which will be used to create the responding nodes for consensus-based decoding . In such a way , we create the graph for decoding , and perform semi-consensus features , and tune the weights for all the features we used . In Table 3, we can see that our consensus-based decoding ( G-Decode ) is much better than baseline , and also better than consensus-based reranking method . That is reasonable since the neighbor/local similarity features not only rerank the final nbest output , but also the spans during decoding.
To test the contribution of each kind of features , we first remove all the local consensus features and perform consensus-based reranking and decoding ( G-Re-Rank-GC and G-Decode-GC ), and then we remove all the graphbased consensus features to test the contribution of local consensus features ( G-Re-Rank-LC and G-Decode-LC).
Without the graphbased consensus features , our consensus-based reranking and decoding is simplified into a consensus reranking and consensus decoding system , which only rerank the candidates according to the consensus information of other candidates in the same nbest list.
From Table 3, we can see , the G-Re-Rank-LC and G-Decode-LC improve the performance of development data and test data , but not as much as G-Re-Rank and G-Decode do . G-Re-Rank-GC and G-Decode-GC improve the performance of machine translation according to the baseline . G-
Re-Rank-GC does not achieve the same performance as G-Re-Rank-LC does . Compared with G-Decode-LC , the performance with G-
Decode-GC is much better.
NIST'03 NIST'05 NIST'08
Baseline 38.57 38.21 27.52
Struct-LP 38.79 38.52 28.06
G-Re-Rank 39.21 38.93 28.18
G-Re-Rank-GC 38.92 38.76 28.21
G-Re-Rank-LC 38.90 38.65 27.88
G-Decode 39.62 39.17 28.76
G-Decode-GC 39.42 39.02 28.51
G-Decode-LC 39.17 38.70 28.20
Table 4. Consensus-based reranking and decoding for NIST data set . The results in bold type are significantly better than the baseline.
We also conduct experiments on NIST data , and results are shown in Table 4. The consensus-based reranking methods are performed in the same way as for IWSLT data , but for consensus-based decoding , the data set contains too many sentence pairs to be held in one graph for our machine . We apply the method of Alexandrescu and Kirchhoff (2009) to construct separate graphs for each development and test sentence without losing global connectivity information . We perform modified label propagation with the separate graphs to get the graphbased consensus for nbest list of each sentence , and the graphbased consensus will be recorded for the MERT to tune the weights.
From Table 4, we can see that , Struct-LP improves the performance slightly , but not significantly . Local consensus features ( G-Re-
Rank-LC and G-Decode-LC ) improve the performance slightly . The combination of graphbased and local consensus features can improve the translation performance significantly on SMT reranking . With graphbased consensus features , G-Decode-GC achieves significant performance gain , and combined with local consensus features , G-Decode performance is improved farther.
7 Conclusion and Future Work
In this paper , we extend the consensus method by collecting consensus statistics , not only from translation candidates of the same source sentence/span , but also from those of similar ones.
To calculate consensus statistics , we develop a novel structured label propagation method for structured learning problems , such as machine translation . Note that , the structured label propagation can be applied to other structured learning tasks , such as POS tagging and syntactic parsing . The consensus statistics are integrated into the conventional loglinear model as features . The features and weights are tuned with an iterative semisupervised method . We conduct experiments on IWSLT and NIST data , and our method can improve the performance significantly.
In this paper , we only tried Dice coefficient of ngrams and symmetrical sentence level BLEU as similarity measures . In the future , we will explore other consensus features and other similarity measures , which may take document level information , or syntactic and semantic information into consideration . We also plan to introduce feature to model the similarity of the source our paper , and optimize the parameters with CRF model.
References
Andrei Alexandrescu , Katrin Kirchhoff . 2009. Graphbased learning for statistical machine translation . In Proceedings of Human Language Technologies and Annual Conference of the North American Chapter of the ACL , pages 119-127.
Peter L . Bertlett , Michael Collins , Ben Taskar and David McAllester . 2004. Exponentiated gradient algorithms for large-margin structured classification.
In Proceedings of Advances in Neural Information
Processing Systems.
John DeNero , David Chiang , and Kevin Knight . 2009.
Fast consensus decoding over translation forests . In Proceedings of the Association for Computational
Linguistics , pages 567-575.
John DeNero , Shankar Kumar , Ciprian Chelba and Franz Och . 2010. Model combination for machine translation . In Proceedings of the North American Association for Computational Linguistics , pages 975-983.
Nan Duan , Mu Li , Dongdong Zhang , and Ming Zhou.
2010. Mixture model-based minimum bayes risk decoding using multiple machine translation Systems.
In Proceedings of the International Conference on Computational Linguistics , pages 313-321.
Philipp Koehn . 2004. Statistical significance tests for machine translation evaluation . In Proceedings of the Conference on Empirical Methods on Natural
Language Processing , pages 388-395.
Shankar Kumar and William Byrne . 2004. Minimum bayes-risk decoding for statistical machine translation . In Proceedings of the North American Association for Computational Linguistics , pages 169-176.
Shankar Kumar , Wolfgang Macherey , Chris Dyer , and Franz Och . 2009. Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices . In Proceedings of the Association for Computational Linguistics , pages 163-171.
Mu Li , Nan Duan , Dongdong Zhang , Chi-Ho Li , and Ming Zhou . 2009. Collaborative decoding : partial hypothesis reranking using translation consensus between decoders . In Proceedings of the Association for Computational Linguistics , pages 585-592.
Percy Liang , Alexandre Bouchard-Cote , Dan Klein , and Ben Taskar . 2006. An end-to-end discriminative approach to machine translation . In Proceedings of the International Conference on Computational Linguistics and the ACL , pages 761-768 Yanjun Ma , Yifan He , Andy Way , Josef van Genabith.
2011. Consistent translation using discriminative learning : a translation memory-inspired approach . In Proceedings of the Association for Computational
Linguistics , pages 1239-1248.
Franz Josef Och . 2003. Minimum error rate training in statistical machine translation . In Proceedings of the Association for Computational Linguistics , pages 160-167.
Kishore Papineni , Salim Roukos , Todd Ward and Weijing Zhu . 2002. BLEU : a method for automatic evaluation of machine translation . In Proceedings of the Association for Computational Linguistics , pages 311-318.
Roy Tromble , Shankar Kumar , Franz Och , and Wolfgang Macherey . 2008. Lattice minimum bayes-risk decoding for statistical machine translation . In Proceedings of the Conference on Empirical Methods on Natural Language Processing , pages 620-629.
Dekai Wu . 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.
Computational Linguistics , 23(3).
Joern Wuebker , Arne Mauser and Hermann Ney . 2010.
Training phrase translation models with leaving-one-out . In Proceedings of the Association for Computational Linguistics , pages 475-484.
Deyi Xiong , Qun Liu and Shouxun Lin . 2006.
Maximum entropy based phrase reordering model for statistical machine translation . In Proceedings of the Association for Computational Linguistics , pages 521-528.
Xiaojin Zhu . 2005. Semisupervised learning with graphs . Ph.D . thesis , Carnegie Mellon University.
CMU-LTI-05-192.

