Towards Fuzzy Query-Relaxation for RDF

Aidan Hogan1, Marc Mellotte1, Gavin Powell2, and Dafni Stampouli2

1 Digital Enterprise Research Institute (DERI),
National University of Ireland, Galway, Ireland

{aidan.hogan,marc.mellotte}@deri.org

2 Innovation Works, European Aeronautic Defence and Space Company (EADS),

Newport, UK

{gavin.powell,dafni.stampouli}@eads.com

Abstract. In this paper, we argue that query relaxation over RDF data
is an important but largely overlooked research topic: the Semantic Web
standards allow for answering crisp queries over crisp RDF data, but
what of use-cases that require approximate answers for fuzzy queries over
crisp data? We introduce a use-case from an EADS project that aims
to aggregate intelligence information for police post-incident analysis.
Query relaxation is needed to match incomplete descriptions of entities
involved in crimes to structured descriptions thereof. We first discuss
the use-case, formalise the problem, and survey current literature for
possible approaches. We then present a proof-of-concept framework for
enabling relaxation of structured entity-lookup queries, evaluating different distance measures for performing relaxation. We argue that beyond
our specific scenario, query relaxation is important to many potential
use-cases for Semantic Web technologies, and worthy of more attention.

1 Introduction

RDF is a flexible data format, and is well-suited to data integration scenarios.
However, specifying precise queries over integrated, incomplete, heterogeneous
data is much more challenging than likewise in closed, homogeneous settings.
Writing precise queries requires precise knowledge of the modelling and content
of the data. Even if a querying agent knows its exact information needsand is
able to specify those needs in a crisp, structured requestoften, the query will
not align well with heterogeneous data. Further, a querying agent may not be
able to specify the precise scope of answers it is interested in, but may instead
only be able to specify some ideal criteria that would be desirable.

Current Semantic Web standards and tools only go so far towards matching
the needs of the querying agent and the content of the dataset. RDFS and OWL
only facilitate finding more crisp answers to queriesanswers matched directly
by the data or its entailmentsand do not directly support a continuous notion
of distance (or similarity) for resources. For example, a query asking for a 2012
blue sports car on sale in New York may also be interested in a 2010 navy
roadster on sale in Newark. Although the subsumption relationship between a
sports car and a roadster could be modelled in RDFS, the distance of resources

E. Simperl et al. (Eds.): ESWC 2012, LNCS 7295, pp. 687702, 2012.
 Springer-Verlag Berlin Heidelberg 2012

A. Hogan et al.

such as blue/navy (vs. blue/red) and New York/Newark (vs. New York/Los
Angeles) cannot be succinctly axiomatised in RDFS/OWL for interpretation by
the query answering system. Instead, we argue that the RDF descriptions of
resources can be used to compute an inductive, generic notion of distance.

In this paper, we thus advocate a relaxed form of RDF query-answering where
the query should be interpreted as specifying the ideal criteria for answers, such
that other relevant (but non-crisp) scored answers are returned. This is similar to
top-k query-answering for Information Retrieval engines: a paradigm that works
well in highly-heterogeneous, incomplete scenarios, including Web search.

We first present an industrial use-case from the European Aeronautic Defence and Space Company (EADS) that requires matching witness observations
against crisp knowledge integrated from various law-enforcement and intelligence
agencies ( 2). Next, we provide a survey of literature that relates to the needs
of EADS use-case and to query relaxation ( 3). We then propose a generic
framework for building a relaxed RDF query engine ( 4); we currently focus on
entity-lookup queries using similarities of RDF terms. Subsequently, we discuss
a generic technique for extracting distance/similarity scores between resources
based on their structured descriptions ( 5). We then outline an early prototype
for relaxing queriesthat represent witness observationsagainst a dataset of
vehicle descriptions, testing different similarity measures ( 6). We conclude that
our own results are too preliminary for deployment, but argue that RDF query
relaxation (or more generally fuzzy querying) is an important, timely research
topic not only for EADS use-case, but may unlike various potential and diverse
Semantic Web applications involving vague/uncertain user requirements.

2 Use-Case Overview

Our use-case arises from an on-going research project at the European Aeronautic Defence and Space Company (EADS): a large European aerospace, defence
and military contractor. EADS Innovation Works is the corporate research and
technology department of EADS that explores areas of mobility, security and
environment. One of the teams key interests relates to civilian security, and enabling increased agency collaboration through use of intelligent systems. EADS
has been working on the development of systems for intelligence analysis to aid
post-crime police investigations [30], where analysts need to process raw infor-
mation, determine valuable evidence, and identify the entities involved and their
relationships. Investigations often rely on human observations, including police
reports, or statements from victims, witnesses and informers.

Such data are the result of subjective assessment and often carry inherent
vagueness and uncertainty. Human observations provide an estimate of the entity
observed, described in natural language, and may be imprecise (i.e., stating that
a suspect was 1.77 m tall when (s)he was 1.79 m tall) or vague (i.e., between
1.7 m  1.85 m, or average height, etc.). Previous work [28,29] analysed issues
with using human intelligence data (HUMINT), and presented methods to align
data in different formats (numeric, textual and ranges). Herein, we view such
observations as structured fuzzy queries to be executed over crisp data.
?

?

?
Posing complex but potentially vague/approximate queries against a crisp index broaches various issues. Numeric attributessuch as heightcan be made
vague using standard range queries. However, answers will not be scored: those
near the sweet-spot of the range are not distinguished from those near the borders of plausibility. Given multiple attributes, the need for scoring becomes more
pronounced. Further, given non-numeric attributes (e.g., a navy getaway car,
probably a Toyota), standard query answering offers no support for vagueness.
Ideally, the query engine should return ranked approximate answers by relaxing
both numeric and non-numeric values. Further, the query should allow for specifying different levels of relaxation for different attributes; e.g., that Toyota is
more vague and should be relaxed more than navy in the results.

We first considered applying ontologies and deductive methods to the use-
case, looking to formalise the domain and to use fuzzy/annotated reasoning and
querying techniques [20]. We abandoned this approach since (i) no legacy formal
models were already in use; (ii) creating a speculative formal model from scratch
(and fostering agreement) was deemed infeasible given the idiomatic nature of
observations; (iii) inference would be too coarse-grained given the low resolution
of formal knowledge available for the scenario. Instead, we decided to pursue an
inductive approach, touching upon the area of cooperative answering.

3 Background and State-of-the-Art

Cooperative answering involves the application of Grices Maxims [13]which
describe how to be helpful in conversationto information systems. Cooperative answering covers a broader area than our current scope, also trying to
detect/circumvent user misconception, to provide additional justifications for
the answer set, and to include entailed answers (as per deductive reasoning). We
refer the reader to a survey of seminal works by Gaasterland et al. [10] and to a
more recent survey of cooperative databases by Chu [5]. A pertinent technique in
the area of cooperative answering is query relaxation or generalisations, whereby
the criteria specified by the user are relaxed to include further, relevant content in the answers [9]. For example, Schumacher and Bergmann [27] propose
using similarity measures to perform query relaxation in support of case-based
reasoning over databases. Bruno et al. [3] investigate the use of query relaxation
for efficient top-k retrieval over numeric, multi-attribute database relations.

Recently, some authors have looked at deductive query relaxation mechanisms
for RDF [16,17,7,25]. Huang et al. [16], Hurtado et al. [17] and Poulovassilis &
Wood [25] all propose using RDFS semantics to perform relaxation, through,
e.g., generalising query patterns up class or property hierarchies, etc. Dolog et
al. [7] use query rewriting rules to perform logical relaxation based on explicit
user-preference models. For our use-case, logical relaxation alone is too coarse;
e.g., members of the same class are viewed analogously for type relaxation, etc.
Other authors have proposed similarity-based, inductive query relaxation for
RDF [19,8], but focus on lexical analyses. Kiefer et al. [19] propose integrating
customised similarity functions into SPARQL, allowing for string similarity

A. Hogan et al.

%

n

measures such as Levenstein, Jaccard and TFIDF to be invoked. More recently,
Elbassuoni et al. [8] propose relaxation based primarily on measuring entity similarity as the JensenShannon divergence of the language models of virtual prose
documents constructed for each entity. Again, such lexical similarity techniques
are too shallow for our use-case (consider red vs. blue vs. navy); they still do not
leverage the rich, structured descriptions of entities during matching. (Herein,
we may use the dual terms distance and similarity interchangeably.)

Where numerical values are consistently defined for entities (e.g., lat./long. for
places, or L*a*b* triplets for colours, etc.), distances can be computed based on
i=1(ai  bi)2 for
Euclidean spaces where each attribute is a dimension (i.e.,
ai, bi comparable numerical values for entity A and B resp.). However, matching based on categorical attributeswhich are prevalent in RDF datais more
difficult [2]. An overlap measure coarsely assigns a constant distance d (typically
d = 1) between entities that do not match for a given categorical attribute, or
zero distance otherwise. Otherwise, Boriah et al. [2] survey a number of finergrained methods for categorical matching; e.g., the Goodall measure [12] assigns
a higher similarity between entities sharing a more selective category (i.e., a
rare string value). Such measures are data-driven, relying on statistics from the
data to compute distances: consequently, the similarity of two entities can be
influenced by other peers (unlike, e.g., absolute Euclidean distances).

RDF similarity measures are also studied for instance matching. Although instance matching focuses on finding owl:sameAs alignmentsand although many
such frameworks rely on deductive methods (e.g., LN2R [26]) or lexical similarity methods (e.g., KnoFuss [22], RDFSim [18]) to generate alignmentsa
few inductive similarity metrics have been proposed based on overlaps in the
descriptions of entities [23,15,14]; one such approach is later used in  5.

4 Relaxation Framework

We now propose a conceptual framework for relaxation of an entity query: a list
of attributevalue or attributevariable pairs Q := (p1, o1), . . . , (pn, on) such
that each pi is a property URI and each oi is either a variable, a URI or a literal
(i.e., Q  U  VUL).1 A crisp response consists of entities (subjects) with
predicateobject edges directly matching the query, as well as bindings for any
variables in o1, . . . , on. In SPARQL terms, this query model roughly corresponds
to basic graph patterns with a common subject variable; for example:
SELECT * WHERE {?s :colour :blue ; :city :NY ; :type :Sport ; year 2010 ; reg ?r .}
To relax queries, we define a matcher as a function M : VUL  UL  R[0,1]
that maps a pair of values into a relaxation score: a value in [0, 1] where 1
indicates that the two values are not interchangeable, and 0 indicates perfect
interchangeability (e.g., M(c, c) := 0, M(?v, c) := 0). Each matcher is a distance
function between the query and entity values, respectively. The match function
1 The query is given an ordering for later convenience. We re-use standard RDF no-
tation: V denotes variables, U URIs and L RDF literals. AB denotes A  B.
?

?

?
may not be symmetric for pairs of values at different levels of specificity: e.g.,
M(:blue, :navy) might be 0.2 suggesting :navy as a good relaxation for generic
:blue, whereas M(:navy, :blue) might be 0.5 since :navy is more specific.

qoieoi

maximini

. For string attributes with functional character strings

Matchers then form the core of the relaxation framework, and can be instantiated in different ways (cf. [24]). For numeric attribute matchers (e.g. :year),
normalised distances can be used: letting maxi and mini denote the max./min.
values for a numeric property pi appearing in the data, qvi a value in the query
and evi a value for an entity, we can apply a normalised numeric matcher Mi :
(qoi, eoi) 
(e.g., registration plates), lexical matchers can be used; we later use a Levenshtein
edit-distance matcher for licence plates such that Mi : (qoi, eoi)  Lev(qvi,evi)
max(|qoi|,|eoi|);
other matchers can be used as appropriate. For categorical attributeswith URIs
or a discrete set of literals as values (e.g., colour, city)creating a matcher often requires background knowledge about the different values; as per Schumacher
and Bergmann [27], we thus propose to use a similarity table for such attributes,
computed by a background matching process (discussed later in  5).

Thus, the relaxation framework may involve multiple matchers: a toolbox
of appropriate matchers can be offered to an administrator. Where a suitable
matcher is not found for a pair of values, the query engine can resort to returning
standard crisp answers, allowing for an ad-hoc, incremental relaxation frame-
work. We currently do not consider inference or relaxation of properties etc.; our
framework could perhaps be extended as per the literature surveyed in  3.
For a query Q = (p1, o1) . . . (pn, on) and entity E, the matchers generate a
tuple of numeric distances Mi...n(Q, E) = d1, . . . , dn. Considering the query as
the origin, the matchers map entities onto points in an n-dimensional Euclidean
space with each dimension ranging over [0, 1] (a unit n-cube). Where an entity
has multiple values for a given attribute, the closest to the query is used; where
an entity is not assigned a query-attribute, the matcher returns 1.2 Thereafter,
entities on the origin are crisp matches. Otherwise, the distance from an entity to
the query-origin can be measured straightforwardly as a Euclidean distance (in
).
this case,
The overall distance from the query-origin to each entity gives an overall
relaxation score that can be used to order presentation of results, or to perform
top-k thresholding. Further, users can annotate query attributevalue pairs with
a vagueness score that allows for controlling the relaxation of individual facets
(e.g., to allow more relaxation for :colour than :city). Thus a vague query is
:= (p1, o1, v1, ) . . . , (pn, on, vn) where v1, . . . , vn  R[0,1] (i.e.,
defined as Q
Q  U  VUL  R[0,1]). A value vi indicates a threshold for di such that the
entity will only be considered a result if di  vi (e.g., if v1 := 0, then (pi, oi) must
have a crisp match). Thus, the origin and the coordinate v1, . . . , vn prescribe a
region of space (an m-orthotope for m the number of non-crisp query attributes)
within which results fall into, allowing to tweak relaxation results.

i ), or with root-mean squared deviation (RMSD:

%

&

i=1 d2
n

i=1 d2

n

n

i

2 Intuitively, this is the relaxed form of standard conjunctive query answering.

A. Hogan et al.

5 Generating Similarity Tables for Categorical Values

The query relaxation framework relies on matchers to define distances between
attribute values. We discussed direct matchers for numerical values (based on
normalised Euclidean distance/RMSD) and for string values (based on normalised edit distances), but left the generation of similarity tables for categorical
values. Such tables can be generated in a number of ways. First, if the set of
categorical values is small enough, tables can be generated manually (on a pay-as-
you-go basis); however, the number of scores needed is quadratic for the number
of values. Otherwise, tables can be (semi-)automatically generated by any form
of similarity measure; e.g., certain categorical attributes (like colours or places)
are described using numeric attributes, allowing use of Euclidean distances.

Background information about the values can also be used to compute similarity scores. For instance, given a sufficient unstructured corpus, distributional
semantic relatedness [11] can generate similarities between terms based on their
co-occurrences in prose text. Given a sufficient structured RDF corpus describing
the terms, instance-matching techniques can be used to generate similarity mea-
sures. Herein, we investigate the latter approach, using a generic RDF similarity
technique which we had previously proposed [14], viz. concurrence, which is designed to cope with diverse RDF corpora; the core premises of concurrence have
also been extended for the purposes of instance matching by other authors [15].
We now introduce the concurrence algorithm, which we use later ( 6) to mine
makemodel similarity scores from an RDF corpus extracted from DBpedia.

Concurrence matches RDF resources based on their shared property-value
pairs (generalising in-links and out-links: i.e., considering both sp and po pairs).
Values are considered purely categorical, such that only crisp matches on shared
pairs are used. Similarity is influenced more by pairs that are determined to be
highly selective (i.e., to be exclusive): if a group of resources share a categorical
value, the similarity score between these resources is boosted proportionate to
the size of the group. This is similar in principle to Goodalls measures [12,2].

Since RDF assumes an Open World (i.e., incomplete data), the concurrence
method is monotonic: similarity is not punished when two resources have different values for an attribute since attributes can have multiple values, and
(without OWL machinery checking cardinalities and ground (in)equalities), it is
difficult to ascertain whether or not two RDF resources necessarily disagree on
an attribute value (as opposed to just the known values differing). Instead, each
additional shared pair monotonically increases the similarity score.

Formally, for an RDF dataset, let card(p, v) denote the number of resources
that share a given propertyvalue pair (abstracting subject/object directional-
ity), indicating how exclusive that pair is in the data. Next, let card(p) denote
the mean cardinality of p across all such values v in the data, indicating how
exclusive the property is (in general). The base similarity score given to all re-
cardcard(p,v),
sources sharing the pair (p, v) is then defined as concur(p, v) :=
which returns a value in [0, 0.5) if the pair (p, v) is shared at least once.
Now, two resources sharing multiple pairs are given a multiset of concur scores
C := {c1, . . . , cn}. The concurrence method combines these using a probabilistic
?

?

?
sum, such that sum(ca, cb) := ca + cb  ca  cb. Since this function is associative
and commutative, it is well-defined for the multiset C (i.e., by summing pairs
in whichever order).3 The function is also monotonic and outputs a value in
[0, 1] (assuming ci  C(0  ci  1)). The intuition behind this aggregation
function is that each additional match score reduces the current distance between
the two resources by a product of itself; for example sum(0.5, 0.5) = 0.75, or
sum(0.8, 0.2) = 0.8+(10.8)0.2 = 0.84. As per the examples, the probabilistic
sum gives stronger weight to individual high values than an arithmetic sum.

The baseline concurrence method is also adjusted to account for some cases of
dependence between property-value pairs. To reduce the effect of groups of (e.g.,
sub-)properties being given the same valuei.e., pairs {(p1, v), . . . , (pn, v)}
only the most exclusive such pair (for which concur(pi, v) gives the highest score)
will be used, and the rest discarded. To reduce the effect of repeated shared
values for a given propertyi.e., pairs {(p, v1), . . . , (p, vn)}all shared pairs for
each property p are (probabilistically) summed up separately to a maximum
value of card(p), with these scores then summed to an overall total.

Finally, generating quadratic pair-wise similarity scores may not be feasible
for large datasets. Thus, a threshold t (s.t. t > 2) is specified for large-scale
scenarios where pairs card(p, v) > t are ignored: the number of matches generated
are quadratic wrt. card(p, v) but the respective scores are inverse-proportional.
For example, if card(type, vehicle) = 50, 000, this shared pair would require
generating 50,000250,000
50,000. The threshold
thus allows for pruning potentially massive volumes of low-scoring matches.

atomic matches with a score of < 1

Concurrence is implemented using batch processing techniques (sorts/scans),
and have been demonstrated on a corpus of one billion quadruples of openlycrawled Linked Data (with t := 38). Further details are available in [14].

6 Proof of Concept

In this section, we investigate proof-of-concept for the original use-case.

6.1 Vehicles Scenario and Data

Relating to the crime observation use-case, we focus on vehicle descriptions:
automobile observations are often integral to police investigations, and it would
be easier to find rich, publically available, representative, structured datasets for
the vehicles use-case than, e.g., for weapons or criminals.

The case study was then to match structured, partial, possibly vague and imprecise queries against a crisp set of car instances. This dataset would emulate
information provided by the UK Driver and Vehicle Licensing Agency (DVLA),
or a Home Office database of recently stolen cars, etc. An observation by a witness would be something like "a blue getaway car that looked like a Toyota with
3 The probabilistic sum (aka. algebraic sum) is the dual t-conorm of the product t-

norm; it also refers to the probability of a disjunction of independent events.

A. Hogan et al.

an LD licence plate". The relaxation framework is used to derive a ranked list
of cars from the dataset in order of their relevance to the observation. In this
respect, the observation acts like a query which should be executed against the
car instances. Results should include not only those cars which directly match
the characteristics given in the observation, but also similar cars. Different characteristics of the observation can be annotated with different vagueness values.
For demonstration purposes, we decided that the chosen dataset should contain information about a significant number of car instances, with attributes for
(at least) make, model, colour and body-type, covering common facets of vehicle observations. We thus took an existing structured dataset describing 50,000
car instances based on a popular Irish website advertising used cars. Each car
instance is described using the following six properties: vehicle make (48 unique
values; e.g., Toyota), makemodel (491 values; e.g., Toyota Corolla), body style
(8 values; e.g., Saloon), fuel type (5 values; e.g., Diesel), colour (13 values after
normalisation; e.g., navy), and registration (i.e., unique licence plate; 50,000 val-
ues). Taking the raw data, colours were normalised into a set of thirteen defined
values, a new set of UK-style licence plates was randomly generated, and the
data were modelled in RDF using Hepps Vehicle Sales Ontology (VSO).4

Notably, all vehicle attributes except licence-plates are categorical, and thus
require tables that encode similarity/distance scores. To relax licence-plate val-
ues, we allow wildcard characters in the query and use the normalised Levenshtein measure mentioned earlier. For colour, the thirteen values were mapped to
an L*a*b* three-dimensional colour space, where Delta-E was used to compute
(Euclidean) distances between the colours and generate a matrix for relaxation.5
An open, non-trivial challenge was then posed by the other properties. For fuel-
type, it was particularly unclear what kind of relaxation behaviour should be
expected for the use-case; a set of regular distance scores were manually defined.
Of more interest were the makemodel, model and body-style attributes, for
which further background information was needed.

6.2 Mining DBpedia for Background Information
To acquire a background, structured corpus on the make and makemodel values
appearing in the data, we enriched the baseline RDF data with selected DBpedia
exports [1] from Wikipedia: we noted that DBpedia exported a rich set of data
about many of the vehicle makemodels, including width, height, categories,
engine, transmission, etc. The resulting RDF data would then serve as input for
similarity techniques to generate scores for subsequent query relaxation.

The first step was to map string values in the data (e.g., Toyota Corolla)
to DBpedia URIs (e.g., http://dbpedia.org/resource/Ford_Mondeo). First attempts were made using the reconciliation function of the RDF Extension for
Google Refine6, which allows for mapping strings to resources in a SPARQL
4 Available at http://www.heppnetz.de/ontologies/vso/ns; retr. 2011/12/12.
5 Distances in the L*a*b* colour space correspond more closely with discrepancies in

human perception than RGB/CMYK models [32].

6 See http://lab.linkeddata.deri.ie/2010/grefine-rdf-extension/; retr. 2011/12/12/
?

?

?
Table 1. Top ten makemodel matches overall (left) and for distinct makes (right)

Honda_Odyssey

Suzuki_Wagon_R

Top Overall Matches

No
1 Honda_Accord
2 Mercedes-Benz_S-Class Mercedes-Benz_SL-Class
3 Suzuki_Alto
4 Ford_Tourneo_Connect Ford_Transit_Connect
5 Mitsubishi_Colt
6 Volvo_S60
7 Nissan_Maxima
8 Audi_80
9 Merdeces-Benz_S-Class Merdeces-Benz_W220
10 SEAT_Cordoba

Mitsubishi_Mirage
Volvo_S80
Nissan_Murano
Volkswagen Passat

SEAT_Ibiza

No Top Matches Across Makes
8 Audi_80
11 Audi A3
13 Audi_TT
25 Citroen_C1
27 Hyundai_i10
28 Audi_A3
30 Daewoo_Winstorm Opel_Antara
38 Hyundai_Tuscan
Kia_Sportage
39 Citroen_C3
Hyundai_Getz
40 SEAT_Toledo
Volkswagen_Jetta

Volkswagen Passat
Skoda_Octavia
SEAT_Leon
Peugeot_107
Kia_Picanto
Seat_Leon

endpoint and refining these mappings in a second phase [21]. Although numerous
matches were found, many makemodels were not reconciled to DBpedia URIs.
Instead, we adopted a manual approach by appending makemodel strings
onto the DBpedia namespace URI, replacing space with underscore. However,
this approach also encountered problems. First, of the 491 string values, 68 models (14%) did not have a corresponding reference in DBpedia (404 Not Found):
some of the unmatched models were colloquial UK/Irish names (e.g., the make
model Citroen Distpatch is known elsewhere as Citroen Jumpy), some were
misspelt, and some had encoding issues. These values were manually mapped
based on suggestions from Wikipedia search. Second, some of the matches that
were found returned little data. Of these, some were redirect stub resources
(e.g., Citroen C3 redirects to Citroen C3), where we forwarded the mapping
through the redirect. Others still were disambiguation pages (e.g., Ford Focus
disambiguates to Ford Focus International, Ford Focus America and Ford
Focus BEV). Furthermore, some resources redirected to disambiguation pages
(e.g., Ford Focus ST redirect to the Ford Focus disambiguation page). Here,
we mapped strings to multiple resources, where Ford Focus was mapped to the
set of DBpedia resources for { Ford Focus, Ford Focus America, Ford Focus
International and Ford Focus BEV }. In total, 90 strings (18.3%) had to be
manually mapped to DBpedia. Given the mappings, we retrieved 53k triples of
RDF data from DBpedia, following redirects and disambiguation links.

We applied concurrence over the dataset with a threshold t := 200 (each
shared pair with card(p, v) = 200 would generate >20,000 raw concur scores at
least below 0.005). For the 491 original makemodel values, concurrence found
non-zero similarity scores for 184k (76%) of the 241k total car-model pairs pos-
sible, with an average absolute match score of 0.08 across all models.

The top ten overall results are presented in Table 1, where we also present
the top ten matches for models with different makes; note that matches are
symmetric and that all matches presented in the table had a similarity score

A. Hogan et al.

exceeding 0.99 indicating highly-relaxable values. Similarity scores are convertible to distance scores for relaxation using dist = 1  sim.7

The results were of varying quality for our use-case. For the top makemodel
matchHonda Accord/Honda Odysseythe former is a saloon and the latter
is a minivan, and as such, the two models are physically diverse; however both
models share specific/exclusive components (e.g., the same engine) which causes
the high concurrence score. Another such example is given by Nissan Max-
ima/Nissan Murano; also the Seat Cordoba is the saloon version of the SEAT
Ibiza hatchback. This raises a more general issue with the subjective nature
of relaxation: although these pairs may be dissimilar for a witness-observation
use-case, they are similar from a sales or manufacturing perspective. Still, we
see some potentially interesting relaxation for the witness use-case. Many of
the highest-scoring cars are physically similar; besides those of the same make,
many of the matches with different makes are (or have been) based on the same
platform: i.e., are fundamentally the same car with different skins.

Besides manual inspection of top-ranked results, in the absence of a gold stan-
dard, evaluating the large set of concurrence results from DBpedia is difficult.
Although inspection yielded promising examples of relaxation, conversely, unin-
tuitive/undesirable results were also discovered. For example, the Westfield SE
(a rare model of kit sports-car) had very little information in DBpedia, and
hence had no notable concurrence matches; similar problems were encountered
for other rare models.


AB +


BC =


AB,


BC and

A major disadvantage of concurrence is that distances are not geometric in

nature: considering resources A, B, C as points, then the concurrence distance-

AC cannot be considered as true spatial vectors since the
vectors
additive property thereof does not hold:
AC. Thus, for example,
if concurrence gives a score of 1 indicating near-perfect similarity between B
and C (distance of 0), this does not imply that B and C have similar scores to
other cars (|
CA|). Taking an example from our evaluation,
the Audi RS4 and Audi A4 were matched closely with 0.97; the Audi RS4 and
Audi A8 models were matched with a score of 0.8; but the Audi A4 and Audi
A8 models were matched with a low score of 0.29 despite being very closely
matched to a common model: the first two pairs gained their concurrence scores
through a largely distinct of (incomplete) attributes. This results in unintuitive,
incomparable distance scores when looking beyond just pairs of resources.

BC|  0  |

BA|  |

Furthermore, the results of the concurrence method is heavily dependent on
the underlying data. DBpedia does not distinguish between different editions of
makemodels down through the years, where for example, the RDF data for six
diverse editions of Ford Fiestaspanning forty yearsare presented together
under one resource since they are described in one Wikipedia article (albeit with
separate info-boxes). Due to these, and other issues relating to data quality, we
decided to pursue tests over a smaller, cleaner dataset.

7 Alternatively, the similarities could be normalised into a non-parametric, rank-based

distance, where a relaxation value of 0.5 includes the top-half similar models.
?

?

?
6.3 Comparing Concurrence vs. Numerical Matching

For evaluating the concurrence method, we wanted to compare its results against
standard Euclidean distances over numerical attributes. We attempted to extract numerical values from the DBpedia makemodel data, but the presence
of multiple values per attribute and the incompleteness of the data precluded
any meaningful numerical analysis. Hence, a manual evaluation corpus was gathered directly from Wikipedia for which concurrence and standard numerical approaches could be compared. The corpus consisted of tabular data describing 200
makemodeledition values in terms of numerical values and ranges (years pro-
duced, doors, engine capacity, wheelbase, length, width, height and curb weight)
as well as categorical values (make, model, edition, body-style); the dataset was,
however, incomplete as not all values could be found for all editions surveyed.
Since this evaluation dataset focuses primarily on numeric values, we modified the discrete concurrence algorithm to consider continuous values. Given a
set of property-value pairs {(p, v1), . . . , (p, vn)} with each vi  R a value for
a specific car-edition, and given two resources (editions) with pairs (p, va) and
(p, vb) respectively (where va  vb), we define the numeric cardinality between
the two values as ncard(p, va, vb) := |{vi : (p, vi) and va  vi  vb}|, denoting
the number of resources that fall in the inclusive range of those two values for
that property [va, vb], assuming single-valued attributes for brevity. The concur-
card(p,v) and for
rence score for a crisp categorical value becomes concur(p, v) :=
ncard(p,va,vb). Further, we turned off
a numeric value becomes concur(p, va, vb) :=
concurrences thresholding and dependence filters, which were not required for
the clean, small dataset at hand (reverting to a simple probabilistic sum).

We then measured the correlation between results for the modified concurrence algorithm, and for non-normalised RMSD (distances not divided by the
max  min denominator) and normalised RMSD (distances for each attribute
pre-normalised into [0, 1]) computed over numerical attributes. To quantify the
correlation, we used Kendalls , which measures correlation between two order-
ings: the  value is in the range [1, 1] where 1 indicates a perfect negative correlation (the orderings are reversed), 0 indicates independence of orderings, and
1 indicates a perfect correlation (the same ordering). The correlation between
the concurrence and non-normalised RMSD was positive but weak (0.1): without the pre-normalisation of values, attributes with larger units (such as years
in the thousands) tended to have high influence. However, between concurrence
and normalised RMSD values, the correlation was higher at 0.54: the main
difference was attributable to the monotonic nature of concurrence, which did
not punish mismatches between single values to the same extent as the normalised RMSD measure. RMSD had the more favourable results in this regard
due in part to the clean nature of the data. Conversely, concurrence gave better
matches for incomplete data, where RMSD gave very high scores.

Finally, we compiled the 40,000 makemodeledition similarity scores for each
approach into similarity scores for makemodels, makes and body-styles by taking the average across all pairs in the generalised groups. For example, to generate a similarity score between saloon and hatchback body styles (say the sets S

A. Hogan et al.

and H resp.), we took the average of all edition-similarities between both groups
(i.e., the arithmetic mean of scores for all edition-pairs in S  H).

6.4 Experimenting with Query Relaxation
With various matcher mechanisms and tables in hand, we turned to testing query
relaxation against the 50k vehicles dataset. We developed a simple prototype
to take a vague query, perform a full scan of the dataset computing relaxation
scores for each entity based on the matchers, and return a ranked list of answers.
Although the query algorithm is linear, we acknowledge that sub-linear (and sub-
second) query times might be required for deployment. There are various avenues
to enable sub-linear performance (for entity search): (i) if crisp facets are given,
these can be looked up directly where relaxation is then used to filter initial
results (similar in principle to SPARQL FILTERs); (ii) given a matcher based
on a table of similarities or on numeric distance, the corresponding vagueness
score for the query facet can be used to compute a range query that can be
executed as a table lookup (assuming an index with the correct sort order is
available); (iii) special relaxation indices can be built, for example, using Locality
Sensitive Hashing to index Euclidean points and enable efficient neighbourhood
searches [4]. Different optimisations are feasible for different types of matchers.
We leave further investigations of optimisations for related work: our current
aim is to validate the proposed techniques and offer proof-of-concept.

Table 2 presents the top-5 results for three example witness observations,
which were modelled as structured vague queries and run against the vehicles
dataset. Vagueness scores are manually chosen for proof-of-concept: mapping
textual vagueness to numeric vagueness is out of scope. For the matchers, we
used a normalised Levenshtein edit-distance for licence plates; the L*a*b*-based
similarity table for colour; and for make, model, edition and body-style, we used
three configurations with similarities computed from the 200 vehicle-editions
dataset (for which we could compute three sets of results) using (i) concurrence,
(ii) normalised Euclidean and (iii) absolute Euclidean distance measures. The
scores are based on RMSD from the query origin (subtracted from one).

Observation A gives an example of relaxation for colours; however, note
that the original query also requests relaxation for models, but where colour
distances are typically much shorter. No difference occurs between the different matcher configurations for car-make (the first relaxed car-make appears in
position 1011). This is a weakness of the framework: different matchers may
produce incomparable distances, creating an imbalance in the relaxation across
different attributes; a possible solution is the use of rank-based distances. From
Observation B, we see maroon being returned as a crisp match for red and
see example relaxation of models; from the scoring, we also note that different
matchers may vary in terms of inclusiveness. Finally, Observation C uses the
Levenshtein edit-distance matcher for licence-plates in combination with colour
relaxation, where the black result is questionable.

In the absence of a gold standard, we could not evaluate precisely the effectiveness of the relaxation framework for generating relevant, approximate,
?

?

?
Table 2. Example observations, relaxed queries and results

Observation A:
Relaxed query:

No
?

?

?
result
Peugeot
Peugeot
Peugeot
Peugeot
Peugeot

A greenish car, maybe a Peugeot.

{(colour, green, 0.2), (make, Peugeot, 0.8)}

All Approaches (same results)

green
yellow
brown
teal
aqua

score
1.00
0.96
0.95
0.95
0.93

Observation B:
Relaxed query:

A red SUV, looked like a Land Rover Freelander.

{(colour, red, 0), (body, SUV, 0), (model, LR.-Freelander, 0.8)}

Concurrence

Norm. Euclidean

Abs. Euclidean

No

score
result
LR. Freelander red
1.00
LR. Freelander maroon 1.00
Hyundai Trajet red
0.86
red
0.86
maroon 0.86 Kia Sorento

score
result
LR. Freelander
1.00
LR. Freelander maroon 1.00
Hyundai Tuscon red
0.93
Hyundai Tuscon maroon 0.93
0.92
?

?

?
4 Kia Sorento
5 Kia Sorento

red

score
result
LR. Freelander
1.00
LR. Freelander maroon 1.00
Hyundai Tuscon red
0.84
Hyundai Tuscon maroon 0.84
Renault Scenic
0.84

red

red

red

Observation C:
Relaxed query:

A light Audi A3 8L, 2006 UK reg. starts with SW and ends with M .

{(colour, white, 0.4), (edition, Audi-A-8l, 0.1), (reg, SW?6??M, 0.4)}

No
?

?

?
result
Audi A3 8L
Audi A3 8L
Audi A3 8L
Audi A3 8L
Audi A3 8L

All Approaches (same results)

SW06RWM
SF56GCN
BW06LJN
SW04TVH
AE56MWM

yellow
white
gray
black
maroon

score
0.92
0.91
0.90
0.85
0.83

well-graded answers. Generating high-quality distance scores based on categorical values is much more challenging than for numeric attributes [2], but a crucial
part of inductive query relaxation for RDF. Table 2 provides some preliminary
results towards query relaxation for RDF, but based on the outlined problems,
the results were deemed currently unsuitable for deployment in the use-case.
However, we believe that with further investigation, such methods can be improved and adapted for use in other less critical applications, such as relaxing
query results from public SPARQL endpoints.

7 Conclusion

In this paper, we introduced a use-case from EADS involving matching witness observations against structured entity descriptions. We proposed queryrelaxation as a framework within which to tackle the problem. We discussed how
matchers can be used to enable query relaxation, how different matchers can be
combined and used for different attributes, and how RDF similarity techniques
can be used to compile similarity scores for categorical values. We presented
the results of various proof-of-concept experiments with the goal of performing query-relaxation over 50k car descriptions. We discussed using DBpedia to

A. Hogan et al.

mine background information for makemodel similarity scores, computed using
our proposed concurrence method. We subsequently compared the correlation
between the results of a modified version of our concurrence method and that
of standard Euclidean distance measures. Finally, we presented some example
query-relaxation results based on vague observations of vehicles as per the use-
case. Unfortunately, the results were not deemed reliable enough for deployment.
As such, lots more work is left to do and many challenges are left unaddressed.
Beyond our use-case, we argue that cooperative answering and query relaxation
is an important, timely topic for Semantic Web researchers to pursue: RDF
stores often index diverse datasets with complex schemata, against which writing precise queries is extremely challenging. Query relaxation would then find
application in various areas, including Web search and recommender systems [3],
e-commerce [6], case-based reasoning [27], reconciliation [21], etc. As discussed,
current instance matching techniques can be repurposed for relaxation.

In summary, we would hope to see further proposals towards cooperative
SPARQL engines which intelligently aid usersusing a mixture of deductive
and inductive techniquesin the daunting task of answering potentially vague
queries over diverse RDF datasets. We have taken tentative steps in this direc-
tion, looking at query relaxation for entity queries. Further focus on inductive
techniqueslike those proposed by Stuckenschmidt [31] or Hu et al. [15]will
also better position the Semantic Web community to support applications needing intelligence beyond just crisp semantics and logics.

Acknowledgements. This paper was funded in part by the Science Foundation
Ireland under Grant No. SFI/08/CE/I1380 (Lion-2). We thank Nuno Lopes, Axel
Polleres, Ali Hasnain and Maciej Dabrowski for their contributions.
