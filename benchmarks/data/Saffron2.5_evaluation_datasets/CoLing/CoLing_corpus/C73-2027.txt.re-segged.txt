JEANPIER REPM~LET
COMPUTATION ALLINGUISTICS ANDLINGUIS TICTHEORY
The present paper is an attempto justify and explain the direction 
of present research in Ottawa ( Carleton University and also University
of Ottawa ) on Computational manipulation of speech . Our actual realizations are not necessarily original  ; rather , we are trying to make use of the findings of other workers  , assembling them , however , in a different way , on the basis of a novel conception of linguistic organization  . 
1 , DESIDER A TAFORCOMPUTATION ALLING UISTICS The main problem facing computational linguists  , when they want to make use of linguistic theory , is the divergence of aims . Basically , computational linguists attemp to design devices which will automatically manipulate instances of speech  ( henceforth discourses ) in specified ways , to obtain particular results . Linguistic theories , on the other hand , are concerned with the overall structure of a language  , and consider what happens in particular cases as the interaction between the overall linguistic competence  ( general structural knowledge ) and many undetermined factors of individual performance  . Hence the computational linguist is left to find for himself pragmatic solutions to his particular problems  . We examine first what sort of theory the computational linguist could make good use of  . 
1 . 1 . It is possible to distinguish between formal and functional theories according to whether the main criteria for classification and description of units are based on their formal properties alone or rely on the role they play in conveying meaning  . It would appear , given the goals of computational linguistics , that functional theories might be more useful , since they give us direct access to the meat : meaning  . However , most of them are not precise enough to be used in a computer environment  . The best attempt at using one of them was made by T  . 
358 JEAN " PIERREPAILLET
WINOG~ . AD (1972) . It is significant that Winograd had to reformulate much of systemic grammar in order to be able to use it  . 
1 . 2 . Accordingly , most of the work in computational linguistics relies on formal theories of language  , starting with distributional linguistics . The problem here is reversed . A good formal theory will provide interesting possibilities for manipulating discourses  , but gives no reason for doing so . More explicitly , the schemas of manipulation sought by computational linguists must have some interesting functional property : semantic invariance  , logically oriented semantic relations , or the like . Hence the necessity for a theory presenting a well defined semantic aspect  , as well as allowing manipulations of the expression aspect of discourses  . 
1 . 3 . There are some such theories , among which most conspicuous are generative semantics and Lamb's stratificational grammar  . R . 
B~NNICK (1969) and S . LAMB (1973) respectively , have argued for applying these theories to computational work on language  . While widely different in most respects , these two theories h are two interrelated features  . First , they are theories of langue , that is , they try to account for wellformedness and systematic interrelationships within a set of objects  , called sentences of the language . Second , as a consequence of this feature , they establish a systematic , deterministic relation between expression and content  . In the case of generative semantics , this systematic relation is oriented from content o expression  ; the understanding of a particular sentence must then be viewed as the ~ undoing ~> of transformations  , which often yields ambiguity . In the case of strati-ficational grammar , which is basically non-oriented , the understanding of a sentence appears as the activation of a static network of connections from the expression end  . At the content end , this yields a complex of activated lines which , hopefully , represents the meaning of the sentence . There is here an interesting distinction , not explicit in generative semantics , between the static set of connections and their dynamic activation in a particular speech act  . However , both formulations rely heavily on wellformedness . Any speech act which is not perfect must be blocked somewhere in the encoding or decoding  . This is normal if the only interaction between speaker and hearer is to take place through wellformed speech expressions  . On the other hand , such a requirement is known to be unnatural in the human environment  , where wellform-edness is patently nonessential . Thus , if realizable , generative seman-COMPUTATION ALLING UISTICS AND LINGUISTICTHEORY  359 tics or stratificational grammar are at best an artificial simplification of human language  , for computing purposes . Even thus , we know that a particular sentence may have different ~ meanings ~  ) in different linguistic or nonlinguistic contexts  ; therefore , it is illusory to look for a purely linguistic mapping between content and expression  . We label direct hose theories which posit such a mapping  , and mediate those which allow for ( and , ideally , specify the conditions of ) the insertion of extralinguistic information in the speaking or understanding processes  . 
What is needed , thus , for computational linguistics , is a formalized , semantically specific , mediate theory of language . 
2 . SYNTAX AND THEDICTIONARY 2 . 1 . Among other things , the adoption of a mediate theory of language forces on us an interesting consequence : it is no longer possible to derive the wellformedness of expression from that of content  , or conversely . Each has to be specified in its own terms . This in turn requires the creation of an independent metalanguage for content  , a task started , with a limited scope , by symbolic logic . It also changes the outlook of syntax . In most formal theories of syntax , a large apparatus is devoted to selectional restrictions  . In as much as these are them an if estations of semantic wellformedness requirements  , to be handled any how in the semantic description , we can now reduce syntactic description to the specification of order structures and ~ strict subcategorization ~  . As a consequence , we may ignore , in syntax , such notions as that of transformation , which characterizes selectional invariance . 
2 . 2 . In order to see what kind of device might be used for such simplified syntactic description  , a detourth rough morphology is in order . 
In a recent paper , M . HALLE ( 1973 ) offers suggestions for the treatment of morphology in a generative grammar  .  1 1~ . BINNICK ( 1973 ) has written a penetrating review of Halle's paper  ; within the generative framework , he points out a very important feature of Halle's proposal : the confusion between irregularity in expression and irregularity in  1 The concern with morphology is rather new in generative grammar  , but has long been manifested by other linguists , e . g . G . Gtr ~ LAUM ~ (1971), or M . A . K . HaLLmAY (1961), in a functional approach . 
360 JEANPIERREPAILLET content . According to Binnick , the two types of structure should be carefully distinguished  ( which is precisely what a mediate theory does better than a direct heory  )  . On the other hand , there are some regularities in morphology , which involve a systematic or respondence b- tween expression and content : for instance  , in English , it is always possible to nominalize a verb . Whenever a " strong nominalisation " ( as in the arrival of the prime minister ) is not available , it is possible to use a " gerund " ( as in the second coming )  . It seems that the regular formations are less acceptable when a lexical possibility exists  ; they are therefore to be considered as " otherwise " solutions  . We have here a suggestion that the description of the lexicon must make extensive use of disjunctive ordering  ( this , incidentally , is built into the structure of strati-ficational theory  )  . 
The dictionary is " needed any how " either to list irregularities in morphology  , or to account for the link between expression and content aspects of morphemes  , or probably for both . This dictionary appears as a list of arbitrary associations between some content structures and some expression structures : nothing new  , on this point , since Saussure . We may borrow an argument from the practice of generative grammarians  , and argue that , since the dictionary is needed any how , we might as well use it for syntax as well . This will also remind one of F . DrS Atrssu ~ (1966) , who though that syntax could not entirely be part of langue : only " stereotyped expressions " would  . Translate : some recurrent syntagmatic patterns of morpheme classes are part of the linguistic toolbox  , just as morphemes are . The rest is up to the speaker . 
2 . 3 . Such a view would have two interesting consequences  . The first one , from the computational point of view , is that whatever device is needed for handling the dictionary it could doduty to handle syntagms as well  . The second , from the theoretical point of view , is that a theory of syntactic ill formedness would be naturally statable  , by analogy with morphology . To take an example from Halle's paper , arriv-ation is wellformed although nonoccurring , because of the specific properties of-ation and arrive  . Morphological wellformedness can be stated in terms of contiguity relationships  . On this model , we might want to state syntactic onditions in terms of contiguity relationships as well : that is precisely what string structure theory does  . A string structure description ( A . K . Josm , 1970; z . s . HARRtS , 1965) starts with a vocabulary of strings , each of which has occurrence properties , tat-COMPUTATION ALLINGUISTICS ANDLING UISTIC THEORY  361 able in terms of which strings or parts of strings they may or must be contiguous with  . 
2 . 4 . One frequent objection to assimilating morphology and syntax can be dealt with here  . It is often argued that the types of recursiveness found in syntactic structures do not appear in morphology  . This would be the reason why a finite state treatment  , which is feasible for morphology , is not adaptable to syntax . This argument reflects a biased view of morphology  , influenced mainly by indoeuropean languages . 
As a matter of fact , Eskimomorphology , for instance , exhibits instances of full recursiveness . Any solution to the problem of describing Eskimo words will be a likely solution for describing English syntax  , and conversely . In his axiomatic presentation f the string structure of English  , Harris offers such a solution , based on the fact that only very few types of syntagms are recursive : for English syntax  , they are those labeled c , Y  ~ , and Aby Harris . One can then describe English order structures by a finite state diagram  , where some of the transitions are labeled by one of these three symbols  . These transition simply a ( recursive ) call to the description of the corresponding syntagm  . 
The systems developed by W . A . WOODS (1970), J . THORPE (1968), and D . G . BOBROW (1969) exploit a similar trick . The only theoretical requirement is to keep track of the depth of recursion when running through the diagram  . Practically , the depth of recursion will be limited by the capacity of the processor  ; this turns out to be an advantage when one tries to model human performance  , which is notoriously limited in this respect . 
The transition diagrams used in this type of treatment are conspicuously similar to the organization of dictionaries for computer use  . 
Even if no other reason existed , this similarity should prompt the computational linguist to explore such a possibility  . 
2 . 5 . Such a scheme would not look very new to stratification alists  . 
They could argue , as pointed out earlier , that the ir theory distinguishes between the description of regularities and idiosyncracies on the one hand  , and the use made of them on the other . They might even argue that what I call dictionary is nothing but the set of static relationships represented in a stratificational network  . However , there are two basic differences to be dealt with . One is that I argued earlier that ira computational device is to model linguistic performance adequately  , it must be insensitive to noise , either in the form of occultation of the signal 362 J ~ ANPIERI~VAILL ~ T ( e . g . unrecognizable characters in a printed form , or morphemes of unknown classification ) or in the form of " mistakes " ( e . g . occurrences of ill-formedness ) . Thus recognition of a message cannot rely on the " activation " of a stratificational network  , which would be blocked in both cases . T .  1~ . HO rM^N ~ ( 1971 ) has proposed a device which he calls Vigilant Memory  , and which is capable of " recognizing " morphemes in a string  , in the presence of noise . It performs very well in the case of unrecognizable or substituted characters  , lightly less well in the case of insertions or deletions  , and still less well , but adequately , it seems , in the case of metatheses , which amounto a double substitution . We are now working on the task of combining the possibilities of the vigilant memory with the economy of conventional dictionary lookup procedures  . One important point is that the output of a vigilant memory is a decision on the identity of some form  , given a possibly faulty input . This output can be input to another vigilant memory  , which will recognize other forms in terms of the previous ones  ( e . g . 
words or syntagms in terms of morphemes ) . One thus obtains the el-egance of formulation of stratificational networks with a useful in sen -sitiveness to noise  . 
2 . 6 . The other important difference between our proposal and stratificational grammar stems from the fact that the latter is a direct  , structural theory : it offers no way of representing an isolated construct of expression or content independently of the general network of relationships describing the overall structure of the language  . We propose , on the contrary , to have two sets of wellformedness characterizations  , one for expression and one for content . The link between the two is to be seen as a collection of procedures  , called by the various recognizable forms of expression  , which build forms of content according to the wellformedness chemas of content  . To put it another way , units of expression ( morphemes , syntagms , entences , etc . ) do not have , or carry , or correspond to , a particular meaning , but induce certain computations whose result is some meaning structure  . This view , which Winograd also seems to hold , is at the center of our Integrative Semantics ( J . P . 
PAILt ~ T , T.l ~. HOrMANN , 1972).
3 . INTEGRATIVE SEMANTICS 3 . 1 . This proposal for a semantic theory started as an effort to develop an adequate notation for semantic structures  , which should , COMPUTATION ALLINGUISTICS ANDLINGUIS TICTHEORY 363 among other things , befree from syntax-induced biases ( J . p . PAILLET , 1973) . By combining the insights of logicians like Frege and Tarski  , and of linguists like Hjelms lev and Tesni~re , we come to distinguish first semantic forms from semantic processes  . 
3 . 2 . Semantic processes are of several kinds . The simplest kind to understand is the object of logical proof theory  . It consists in manipulating semantic forms to obtain other semantic forms systematically related to the original ones  . Our cognitive activity , however , does not consist merely in manipulation of abstract forms  . We find two other kinds of semantic processes , also represented in Winograd's system . 
Interpretation processes have long been studied by logicians  . They consist inputting the abstract forms which we hold into correspondence with a portion of some universe  . Evaluation processes consist in reaching decisions as to the response which is appropriate in a particular case  . An important point to keep in mind is that such processes are not limited to speech activity  . They are ever present in our conscious life . We can look upon speech as a particularly effective way of nudging someone's cognitive activity in a certain direction  . That this particularly effective tool need not always be successful is apparent in all cases where the hearer fails to understand  , misunderstands , etc . 
3 . 3 . In a human language , expression is contrained by wellform-edness conditions which limit the possible use and arrengement of morphemes  . Consequently , expression is organized in such units as phrases and sentences  , which need not correspond to " complete thoughts  "  , or , more specifically , to complete structures , of content . If a new form of content is to be transmitted to a hearer  , it will be imparted piecemeal , by the use of separate ( usually successive ) sentences . The process of building a new structure of content  , which , for obvious reasons , we call integration , has to be directed by specific devices ( morphemes or constructions ) called integration functors . Similarly , there are devices to direct interpretation , such as the deictics , which make a description definite , often with recourse to nonlinguistic information . Finally there are also evaluation functors , which direct the evaluation of the appropriate response  . These functors could not be said to have meaning independently of the precise conditions of use  . Their action must therefore be described in terms of the computational procedures which they call for in the hearer  . The simplicity argument suggests that we treat lexical items in the same way  . 
364 JEAN PIERREPA ~ LLET 4 . A MODEL OF THE HEARER'S PERFOR MANCE 4 . 1 . It is apparent from the foregoing that our proposal is basically hearer-oriented  . We believe , indeed , that the speaker must have recours-ed to a set of heuristics  , taking into account his knowledge ( or imagined knowledge ) of the hearer , his status with respecto him , and many other variables . In most tasks of computational linguistics , however , the full complexity of human interactions is fortunately not present  . 
There are a number of simplifying assumptions one can make as to subject matter  , vocabulary , style , etc . , so that the task of giving expression to given semantic structures is not overwhelmingly complex  . 
However , from the point of view of linguistic theory , it is much easier to formalize the understanding of speech  ( phonological perception excluded ) than the production of sensible discourses . 
4 . 2 . A hearer is primarily a cognitive system capable of building  , holding and manipulating semantic forms . These forms consist of individual objects , descriptions for and relations between these objects  , and various interacting modalitie such as quantifiers  , moods , aspects , and the like . The manipulation of semantic forms may yield other semantic forms as well as judgements of contradiction  , consistency , implication , and the like ( note that these judgments are not limited to linguistically induced semantic forms : optical illusions are examples of visual paradoxes  , i . e . contradiction between two cognitive forms v is -ually extracted from the same object  )  . 
4 . 3 . It is conceivable , although not shown , that the cognitive procedures used for building semantic forms in nonlinguistic situations are the same as those called forth by lexical items and integrative functors : this is a restatement of Whorf's hypothesis  ( B . L . WHom ~, 1965) . In any case , lexical items and integration functors are seen as subroutine names  ( to use computer terminology ) whose perception usually triggers the corresponding building procedure  . Similarly , integration ftmc-tors callforth procedures for interrelating parts of semantic forms which are in the building or already built  . 
4 . 4 . A hearer is also able to relate semantic forms to a universe of interpretation  . This may be part of what we traditionally call attention  . 
In this case , the interpretation functors may be said to direct the heater's COMPUTATION ALLING UISTICS AND LINGUISTICTHEORY  365 attention . Their action can also be represented by procedures in which the best possible referent for a given description is computed  . Some interpretation functors direct the selection of an appropriate universe of reference  . Similarly performatives and other devices are calls for procedures of evaluation  , in preparation for an appropriater sponse . 
4 . 5 . Naturally , the various kinds of procedures called by elements of expression ia discourse are often insufficient in themselves to produce all the results mentioned  . Part of the speaker's communicative ability consists in leaving out much of the information eeded  , stricto sensu , to build , interpret and evaluate semantic forms , and in selecting only what is absolutely necessary to lead the hearer in the proper direction : hence the term " nudging " used in  3  . 2 . The rest of the information , left out by the speaker , has to be provided by the hearer , either through autonomous manipulation of his semantic forms  , or through recourse to his store of previous information : his " knowledge of the world "  . In order to implement this last aspect , R . . QUILLIAN'S ( 1969 ) concept of a semantic network is very attractive , and is probably preferable to Lamb's version , cognitive networks , which do not to my knowledge incorporate any notion of semantic proximity  . 
4 . 6 . If syntax is indeed reducible , in its " order structure " aspect , to a set of patterns recognizable by a device like a Vigilant Memory  , we have an explanation of why syntactic ill formedness in ot more destructive  . The only thing which counts , from the heater's point of view , is to be able to recognize some pattern present in his syntactic dictionary  , which will then call some building or integrating procedure  . 
Illformedness becomes destructive only when the error-correcting capabilities of the vigilant memory are overwhelmed  . On the other hand , it is always possible , even when recognition occurs , to detect syntactic ill formedness through the workings of the memory  . 
REFERENCES t ~. BINNICK , Generative Semantics and
Automatic Translation COLING , Stockholm , 1969.
IL . BINIqlCK , E pile gomena to a Theory of
Word Formation , unpublished , 1973.
D . G . BOBROW , J . B . FRASm ~ , An augmen-ted state transition etwork analysis procedure  , in Proc . Int . Joint Conf . on Art . 
int ., Washington , D.C ., 1969.
G . GUIL~AUM ~, Lecons de linguistique , vols . 1&2, Qu6bec , 1971 . 
M . H~LE , Prolegomena to a Theory of
Word Formation , in ~ Linguistic Inquiry ~) , IV (1973) 1 . 
M . A . K . HAtUDAY , Categories of the theory of grammar , in ~ Word ~ , XVII (1961) . 
Z . S . HAaa IS , String Analysis of sentence structure , The Hague ,  1965 . 
T.IL . Ho~raAN ~, Lexical redundancy in
Speech Perception : Vigilant Memory , in
VII International Congress of Phonetic
Sciences , Montreal , 1971.
A.K . JosHx , String adjunct grammars , in
TDAP no .75, Philadelphia , 1970.
S . LArca 3 , Stratificational Linguistics as a basis for Machine translation  , in MAKKAI , LOCKWOOD ( eds . ) , Readings in Stratifi-cational Linguistics , University of Alabama Press ,  1973 . 
J . P . PA Il . LET , Prd requis pour unethdorie semantique , in , Cahier de linguisti-que ~ , no . 2, Montr & l , 1973 . 
J.P . PaILL ~ T , T.tL . Hor MA ~, Integrative
Semantics 1, SILG Monograph No.2,
Carleton University , Ottawa , 1972.
g . . QmLLIAN , The teachable Language
Comprehender , in ~ Communications of the ACM ~) ,  (1969) . 
F . DES aussum ~ , Cours de linguistique gd-n&ale , Paris ,  1966 , pp .  170-171 . 
J . THORPE , P . ~ BRATLEY , H . DEWAa , The
Syntactic analysis of English by Machine , in D . MIcHte . ( ed . ), Machine Intelligence 3, New York , 1968 . 
B . L . WHOR ~, Selected writings , Cambridge ( Mass . ), 1965 . 
, T . WINOGaAD , Understanding Naturar
Language , New York & London , 1972-
W . A . WOoDs , Transition networks fol natural language analysis  , in * Commu . 
nications of the ACM *, XIII (1970)10.
