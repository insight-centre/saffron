C
oling
2008:
E
ducationalN
aturalL
anguage
P
rocessing
?
Tutorialnotes
M
anchester,A
ugust2008
Educational Natural Language ProcessingTutorial at COLING?08
Iryna Gurevych , Delphine Bernhard
Educational Natural Language Processing
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 2/206
Iryna Gurevych Delphine Bernhard
Presenters
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 3/206
Technische Universit?t Darmstadt
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 4/206
Quality ineLearning
Ambient learning // University 2020
Serious Games
E-Didactics
Ubiquitous Knowledge Processing
Semantics-based knowledge acquis.
CRE?E-Learning?
Graduate School Research Unit
Research Unit
Center of Research Excellence eLearning 2.0
1
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 5/206
UKP Lab Research Topics
Text Mining
Natural Language Processing / SemanticsSemantic Information Management
Web 2
.0 \ Se
rvices
eLearn
ing 2.0
User-g
enerat
ed Dis
course
Darmstadt Knowledge Processing Repository WikiMining 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 6/206
Profession 3
Profession 1
Profession 2
Profession ... Query
Profession ...
Profession ...
Profession ...
Semantic Information Retrieval ( SIR)
AQUA
Sentiment Analysis in User Generated Discourse ( SentAL)
Internet der Dienste ( THESEUS ) ?
Semantic Question Answering for eLearning 2.0 ( QA-EL)
Self-Improving WikisWikis 2.0
WikiMining NLP
Wiki
Darmstadt Knowledge Processing Repository
Data export Project specific analysis
Semantic analysis
Syntactic analysis
Morphological analysis
Linguistic preprocessing
Data import
Research Projects and eLearning 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 7/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 8/206 Educational Natural Language Processing eLearning NLP Computer-assisted learning / instruction Analysis and use of language by machines e-NLP Field of research exploring the use of NLP techniques in educational contexts
Definition 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 10/206
Web 2.0 & eLearning 2.0 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 11/206 ? Creation of large repositories with user generated discourse and user generated metadata ? Using repositories to create structured knowledge bases to improve NLP ? Repositories need advanced information management and NLP to be efficiently accessed
Some Observations 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 12/206 Content creationSemantic knowledge Wikis,Blogs,...
NLP eLearning2.0
Intuitive access
Feedback Loop : NLP & eLearning 2.0
Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 14/206
Computer-based Testing ? Definition : All forms of assessment delivered with the help of computers ? Also called : ? Computer Assisted/Aided Assessment ( CAA )? Adequate question types for CAA ( McKenna & Bull , 1999):? Multiple choice questions ( MCQs )? True/False questions ? Matching questions ? Ranking questions ? Sequencing questions ? etc.
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 15/206
Question Types ? Objective test items ? constrained answer , to be selected among a set of alternatives ? short answer ( word or phrase ) in response to a question ? objective and impartial scoring ? Examples :? Fill-in-the-blanks questions ? Multiple-choice questions ? Matching questions ? Subjective test items ? original answer ? variable length ? biased scoring ? Examples :? Short-answer essays ? Extended-response essays 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 16/206
Role of Test Items in Learning ? Summative assessment ? " Assessment of learning "? Measuring student achievement ? Formative assessment ? " Assessment for learning "? Active learning : encourage learners to practice and apply newly acquired knowledge by answering test items
NLP for CAA ? Generation of questions and exercises?Writing test questions , especially objective test items , is an extremely difficult and time consuming task for teachers ? Use of NLP to automatically generate objective test items , esp . for language learning ? Assessment and evaluation of answers to subjective test items ? Use of NLP to automatically :? Diagnose errors in short-answer essays ? Grade essays 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 18/206 Automatic Generation of Test Items ? Source data ? Corpora : texts should be chosen according to ? the learner model ( level , mastered vocabulary )? the instructor model ( target language , word category )? Lexical semantic resources , e.g . WordNet ? Tools ? Tokeniser and sentence splitter ? Lemmatiser ? Conjugation and declension tools ? POS tagger ? Parser and chunker 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 19/206
Multiple-Choice Questions ( MCQ ) ? Choose the correct answer among a set of possible answers ? Example ( Mitkov et al , 2006)Who was voted the best international footballer for 2004?(a ) Henry(b ) Beckham(c ) Ronaldinho(d ) Ronaldo ? Usually 3 to 5 alternative answers
StemKey
Distractors / Distracters 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 20/206
Distractors ? Distractors ( also distracters ) are the incorrect answers presented as a choice in a multiple-choice test ? Generation of " good " distractors ( McKenna & Bull , 1999; Duvall )? Ensure that there is only one correct response for single response MCQ ? The key should not always occur at the same position in the list of answers ? Distractors should be grammatically parallel with each other and approximately equal in length ? Distractors should be plausible and attractive ? However , distractors should not be too close to the correct answer and risk confusing students Automatic Generation of MCQs1. Selection of the key ? Unknown words that appear in a reading ( Heilman & Eskenazi , 2007) ? Domain-specific terms : ? Automatically extracted ( Mitkov et al , 2006) ? Present in a thesaurus , e.g . UMLS ( Karamanis et al , 2006)2. Generation of the stem ? Constrained patterns ( Heilman & Eskenazi , 2007):Which set of words are most related in meaning to " reject "?? Transformation of source clauses to stems , using transformation and agreement rules ( Mitkov et al , 2006):Transitive verbs require objects ? Which kind of verbs require objects ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 22/206 Automatic Generation of MCQs3. Generation of the distractors ? WordNet concepts which are semantically close to the key , e.g . hypernyms and cohyponyms ( Mitkov et al , 2006; Karamanis et al , 2006)Stem : " Which part of speech serves as the most central element in a clause?"Key : " verb ", Distractors : " noun ", " adjective ", " preposition "? Thesaurus-based and distributional similarity measures ( Mitkov et al , 2006)? Other NPs with the same head as the key , retrieved from a corpus ( Mitkov et al , 2006)Key : " verb ", Distractors : " modal verbs ", " phrasal verbs ", " active verbs " 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 23/206 Fill-in-the-Blank Questions ( FIB )? Also called cloze test ? Technique which dates from 1953 ( Wilson Taylor )? Consists of a portion of text with certain words removed ? The student is asked to " fill in the blanks "? Objective cloze items = multiple-choice cloze items , i.e . students are given a list of words to use in a cloze ? Subjective cloze items = students can choose the words ? Challenges :? Phrase the question so that only one correct answer is possible ? Spelling errors in objective cloze items 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 24/206
Fill-in-the-Blank Examples ? Blank = preposition ( Source : http://www.purl.org/net/WERTI ) ? Blank = verb to be conjugated ( Source : http://www.nonstopenglish.com/exercise.asp?exid=915)
Fill-in-the-Blank Question Generation 1. Selection of an input corpus2. POS tagging 3. Selection of the blanks in the input corpus4. Where needed , provide some information about the word in the blank , e.g . verb lemma when the test targets verb conjugation ( Aldabe et al , 2006) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 26/206
Selection of the Blanks ? Every " nth " ( e.g . fifth or eighth ) word in the text ( Coniam , 1997) ? Words in specified frequency ranges , e.g . only high frequency or low frequency words ( Coniam,1997) ? Words belonging to a given grammatical category ( Coniam , 1997; Aldabe et al , 2006) ? Open-class words , given their POS , and possibly targeted word sense ( Liu et al , 2005; Brown et al , 2005) ? Using machine learning , based on a pool of input questions used as training data ( Hoshino & Nakawaga , 2005) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 27/206
Objective Multiple-choice Cloze Items http://www.wordlearner.com Combination of a cloze item with multiple-choice answers 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 28/206
Generation of the Distractors ? Randomly chosen in the text from which the question was generated ( Hoshino & Nakagawa , 2005)? Same POS ( Coniam , 1997)? Similar frequency range ( Coniam , 1997)? For grammar questions , use a declension or a conjugation tool to generate different forms of the key , e.g . change case , number , person , mode , tense , etc . ( Aldabe et al , 2006, Chen et al , 2006)? Common student errors in the given context ( Lee & Seneff , 2007)? Collocations : frequent cooccurrence with either the left or the right context ( Lee & Seneff , 2007)? Open class words : semantic similarity based on distributional similarity ( Smith et al , 2008) or a thesaurus ( Sumita et al , 2005)
The Frequency Heuristic(Coniam , 1997) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 30/206
Verification of the Distractors ? Basic verifications :? there must be enough distractors ? there must be no duplicated distractors ( Aldabe et al , 2006)? Collocations : choose distractors that do not collocate with important words in the target sentence ( Liu et al , 2005; Smith et al , 2008)? Use of the web : if the sentence/phrase containing the distractor is frequent on the web , then the distractor should be rejected ( Sumita et al , 2005)The child's misery would move even the most ____ heart.(a ) torpid hits("the most torpid heart ") = 4(b ) invidious hits("the most invidious heart ") = 0(c ) stolid hits("the most stolid heart ") = 6(d ) obdurate hits("the most obdurate heart ") = 1 240 Good distractorsbecause infrequent 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 31/206 Student Project in the e-NLP Course ( Gurevych & Bernhard )? Based on " Automatic generation of cloze items for prepositions " ( Lee & Seneff , 2007)? Example:If you don't have anything planned for this evening , let's go __ a movie.(a ) to ( b ) of ( c ) on ( d ) null ? Tasks :? INPUT : sentence + key , OUTPUT : list of three distractors ? The three distractors must each be generated taking a different approach ? baseline : word frequencies ? collocations ? " creative " method :? Conclusion : a motivating and interesting project for students 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 32/206
Matching Test Items ? Task : match items on the left column with response items on the right column ? Kinds of elements matched:?Word ? Synonym ? Definition ? term?Word ? antonym ? Hypernym ? hyponym ? Historical event ? date ? etc.?Matching test items assess a learner's understanding of relationships
Matching Test Items http://www.thefreedictionary.com 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 34/206 Matching Test Items for Vocabulary Assessment ( Brown et al , 2005) Glosses for specific word senses in WordNet 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 35/206
Error Detection Questions ? Aim : detect and possibly correct errors , which can be marked or not ? Example ( Chen et al , 2006)Although maple trees are among the most colorful varieties ( A)in the fall , they lose its leaves sooner than oak trees . ( B ) ( C ) ( D)?Wrong statements are produced by the distractor generator 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 36/206
Evaluation of Generated Questions ? Student evaluation ? Difficulty and response time ? Comparison with results obtained for manually generated tests ( Heilman & Eskenazi , 2007)? Instructor evaluation ? Usability : " all distractors result in an inappropriate sentence " ( Liu et al , 2005; Lee & Seneff , 2007)? Postediting : count how many test items are accepted , rejected or revised by instructors during postediting ( Aldabe et al , 2006; Mitkov et al , 2006)
Prerequisites for Student Evaluation ? External assessment ? Evaluate the linguistic and / or factual knowledge of the students before they take the test , e.g . Nelson-Denny Reading Test , the Raven's Matrices Test , the Lexical Knowledge Battery ( Brown et al , 2005)? Self-assessment ? Have the students assess whether they know the key or not ( Heilman & Eskenazi , 2007)"Do you know the word ' w '?" 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 38/206 Item Analysis ? Investigate the quality of the test items ( Zurawski , 1998)? Quantitative item analysis :? Facility / Difficulty index ( p ): number of test takers who answered the item correctly divided by the total number of students who answered the item ? Discrimination index ( D ): " does the test item differentiate those who did well on the exam overall from those who did not ?" ? Divide the students in two groups : high-scoring and low-scoring ( above and below the median )? Compute the item difficulty separately for both groups : pupper and plower ? Discrimination index D = pupper - plower 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 39/206 Item Analysis ? ExampleThe child's misery would move even the most ____ heart.(a ) torpid chosen by 7 students(b ) invidious chosen by 1 students(c ) stolid chosen by 3 students(d ) obdurate chosen by 15 students#Students : 26? Difficulty index : 15 / 26 = 0.58 ? neither too difficult nor too simple ( recommended score : 0.5)? Discrimination index ? 9 out of 12 students in the high group found the correct answer ? 6 out of 14 students in the low group found the correct answer ? D = 9/12 ? 6/14 = 0.75 ? 0.43 = 0.32 ? The test item is a quite good discriminator 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 40/206
Item Analysis ? Item distractor analysis : examine the percentage of students who select each incorrect alternative , to determine if the distractors are functioning well
Well-designed item
Possibly miskeyed
Candidate for removal
Candidate for revision
Efficiency of the Automatic Generation of Test Items ? Even though automatically generated test items have to be postedited , this is still a lot faster than writing new test items from scratch.
?Mitkov et al (2006) report the following figures :? an average of 1 minute and 40 seconds was needed to postedit a test item in order to produce a worthy item ? an average of 6 minutes was needed to manually produce a test item 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 42/206
Summary ? The generation of questions and exercises is actually semiautomatic : the system's output has to be verified and modified by an instructor ? However , NLP-based systems considerably reduce the time spent by instructors to write test items , even if they have to manually correct the generated test items ? A great variety of NLP technologies and resources have been successfully used so far :? POS tagging and parsing?WSD ? Term extraction ? ...
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 43/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 44/206 ? Types of learner generated discourse:?Emerging in institutional settings , e.g . solutions to exercises?Emerging in informal settings , e.g . discussions in forums ? Language forms : written or spoken ? Relevant NLP technologies:?Automatic essay grading?Detecting meaning errors?Plagiarism detection?Quality assessment Assessment of Learner Generated Discourse ? Feedback to the student about her level of knowledge ? Feedback to the instructor about the progress of students ? learning ? Incentive to study certain things , to study them in certain ways , to master certain skills ? Formal data to determine the grade and/or making a pass/fail decision Importance of Institutional eAssessment 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 46/206 ? Advantages over traditional multiple-choice assessments ( Bennett & Ward , 1993) ? Major obstacle is the large cost and effort required for scoring ? Automatic systems :? Reduce these costs ? Facilitate extended feedback to students
Importance of FreeText Assessments 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 47/206 ? Proposed in the context of language learning , but applicable to different topics ? We will focus on essay grading Learning Exercise Spektrum Model(Bailey & Meurers 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 48/206 ? A major part of formal education ? Secondary students are taught structured essay formats to improve their writing skills ? Often used by universities in selecting applicants , e.g . admission essays ? Used to judge the mastery and comprehension of material ? Students are asked to explain , comment on , or assess a topic of study
What is an Essay ? ? Descriptive prompt ? ? Imagine that you have a pen pal from another country . Write a descriptive essay explaining how your school looks and sounds , and how your school makes you feel .? ? Persuasive prompt ? ? Some people think the school year should be lengthened at the expense of vacations . What is your opinion ? Give specific reasons to support your opinion.?Source : Y . Attali and J . Burstein . Automated essay scoring with e-rater v.2. The Journal of Technology , Learning , and Assessment , 4(3), February 2006.
Essay Prompts 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 50/206 Source : Marti A . Hearst , The Debate on Automated Essay Grading , IEEE Intelligent Systems , IEEE Educational Activities Department , 2000, 15, 22-37.
Research Development in Writing Evaluation 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 51/206 ? Intelligent Essay Assessor ( Landauer , Foltz & Laham , 1998)? Based on a statistical technique for summarizing the relations between words in a document , i.e . every word is a ? mini-feature ?? Intellimetric ( Elliot , 2001)? Based on hundreds of undisclosed features ? Project Essay Grade ( PEG , Page , 1994)? Based on dozens of mostly undisclosed features ? E-Rater ( Burstein et al , 1998)? The 1st version used more than 60 features ? E-rater 2.0 uses a small set of features
Most Prominent Systems 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 52/206 ? Humans evaluate various intrinsic variables of interest ? essay score :? Content adequacy ? Structure ? Argumentation ? Diction ? Fluency ? Correct language use ? Machines use approximations or possible correlates of intrinsic variables ? scoring model How Do Humans and Machines Rate Essays ?
How is a Scoring Model Created ? ? Analyze a few hundred essays : ? Written on a specific prompt ? Prescored by as many human raters as possible ? Identify most useful approximations ( classification features ) out of those available to the system ? Employ a statistical modeling procedure to combine the features and produce a machine-generated score 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 54/206 Validating the Meaning of Scores ( Yang et al 2002)? Relationship between human and machine scores of the same prompt :? Compare the machine-human and human-human agreement ( Burstein et al , 1998; Elliot , 2001; Landauer et al , 2001)? Estimate a true score as the one assigned by multiple raters ( Page , 1966)? Relationship between test scores and other similar measures :? Compare automatic scores with multiple-choice test results and teacher judgments ( Powers et al , 2002)? Understanding the scoring process , i.e . relative importance of different writing dimensions :? Most commonly used features in scoring models ( Burstein et al , 1998)? The most important component is content ( Landauer et al , 2001) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 55/206 Skepticism and Criticism ( Page and Petersen , 1995)? Three general objectives :? Humanistic ? never understand or appreciate an essay as a human ? Use automatic scoring as a second rater ? Defensive ? playful or hostile students produce " bad faith " essays ? a study by Powers et al (2001), a lot of data needed ? Construct ? computer-measured variables is not what is really important for an essay ? an improved ability to additionally provide diagnostic feedback 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 56/206
Features Used by eRater 2.0 ? Measures of :? Grammar , usage , typos ? Style ? Organization & development ? Lexical complexity ? Prompt-specific vocabulary usage ? Implemented in different writing analysis tools ? Based on an NLP foundation that provides instructional feedback to students in the webbased Criterion system
Writing Analysis Tools : Correctness ? Identify five main types of grammar , usage and mechanics errors :? Agreement and verb formation errors , wrong word use , missing punctuation , typographical errors ? Corpusbased approach :? Train the system on a large corpus of edited text ? Extract and count bigrams of words and POS ? Search for bigrams in essay that occur much less often ( Chodorow & Leacock , 2000) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 58/206 Writing Analysis Tools : Aspects of Style ? The writer may wish to revise :? The use of passive sentences ? Very long or very short sentences ? Overly repetitious words ( Burstein & Wolska , 2003) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 59/206 Writing Analysis Tools : Organization & Development ? Discourse elements present or absent in the essay ( Burstein , Marcu and Knight , 2003)? A linear representation of text as a sequence of :? Introductory material ? A thesis statement ? Main ideas ? Supporting ideas ? A conclusion ? Train a system on a large corpus of human annotated essays to identify " good " sequences ? Mandatory parts , > 3 main ideas , ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 60/206 Essay Annotated with Discourse Elements Source : Y . Attali and J . Burstein . Automated essay scoring with e-rater v.2. The Journal of Technology , Learning , and Assessment , 4(3), February 2006.
15 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 61/206 Writing Analysis Tools : Lexical Complexity ? Related to word-specific characteristics ? A measure of vocabulary-level , based on Breland , Jones and Jenkins (1994) Standardized Frequency Index across the words in an essay ? The average word length in characters in an essay 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 62/206 Writing Analysis Tools : Prompt-Specific Vocabulary Usage ? Intuition : good essays resemble each other in their word choice , as will poor essays ( within the same prompt ) ? Idea : compare an essay to a sample of essays from each score category ( usually 16)? Each essay and a set of training essays from each score category is converted to a vector ? Some function words are removed ? Each vector element is a weight based on a word frequency function ? Six cosine correlations are computed between the essay and each score category to determine the similarity 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 63/206
Scoring in eRater 2.0 ? Input : all features of all writing analysis tools ? Grammar , usage , mechanics , style (4 features )? Organization & development (2 features )? Lexical complexity (2 features )? Prompt-specific vocabulary usage (2 features ) ? Straightforward :? Apply a linear transformation on feature values to achieve a desired scale ? A weighted average of the standardized feature values 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 64/206
Future Directions ? Better standardization of scoring - a single scoring model for all prompts of a program or assessment ? Better understanding and control over the automated scores ? Cover more aspects of writing quality , devise new features ? Prefer features providing useful instructional feedback ? Detection of anomalous and bad-faith essays ? Characterize different types of anomalies ? Detect off-topic essays ( Higgins , Burstein and Attali , 2006) ? Plagiarism is representing the words or ideas of someone else as your own . Examples include , but are not limited to , failing to properly cite direct quotes and failing to give credit for someone else's ideas ?. University of Miami Honor Council , Honor Code?Plagiarize : To practice plagiarism upon ; to take and use as one's own the thoughts , writings , or inventions of another . ( With the thing , rarely the person , as object .)? Oxford English Dictionary Online
Plagiarism 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 66/206 ? Clearly define plagiarism to the students and use explicit examples ? Educate the students about the honor code and the ramifications if it is violated ? Create assignments that make plagiarism difficult ? Make sure the students are familiar with online resources ? Have the students submit evidence of the research process as well as the paper ? Avoid repeat assignments and paper topics ? Inform the students you are Internet savvy and you know about the paper mills ( visit the sites with the students to evaluate the quality of the work )? Inform the students that you use plagiarism detection software From ? Plagiarism in the 21st century ? Carrie Leslie . Lunch & Learn . 2004. Otto G . Richter Library
How to Avoid it ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 67/206 ? " Copy " work :? From another student ( intra-corpal )? From a source outside the corpus of submissions ( extra-corpal )? Self-plagiarism ? The Internet makes it easier than ever :? Download a term paper ? Fail to give proper credit to the source of an idea ? Copy extensive passages without attribution ? Inserting someone else?s phrases or sentences ( minimally paraphrased ) into your own prose and forget to supply a set of quotation marks
Main Ways of Plagiarism 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 68/206 ? Replacing odd or unusual words ? Changing formatting ? Adding filler words or phrases ? Changing headings ? Rephrasing sentences ? Removing or reordering sections ? Changing spelling ( usually from American English to British English , if the document is plagiari[s|z]ed from the Web ) ? Producing consistency by find-and-replace ( as an example , if some papers refer to the World Wide Web , some to the WWW , some to the Web , a student may perform a global find-and-replace to ensure consistency within the plagiarised document ) ? In programming , changing variable names and comments The use of electronic tools to support plagiarism detection : http://www.comp.leeds.ac.uk/hannah/CandIT/plagiarism.html Types of Techniques Used to Conceal Copying (1) Word-for-word plagiarism : direct copying of phrases or passages from a published text without quotation or acknowledgement.(2) Paraphrasing plagiarism : when words or syntax are changed ( rewritten ), but the source text can still be recognised.(3) Plagiarism of secondary sources : when original sources are referenced or quoted , but obtained from a secondary source text without looking up the original.(4) Plagiarism of the form of a source : the structure of an argument in a source is copied ( verbatim or rewritten)(5) Plagiarism of ideas : the reuse of an original thought from a source text without dependence on the words or form of the source(6) Plagiarism of authorship : the direct case of putting your own name to someone else?s work Based on Martin (1994) and Clough (2003)
Forms of Plagiarism 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 70/206 ? Use of advanced or technical vocabulary beyond that expected of the writer ? A large improvement in writing style compared to previous submitted work ? Inconsistencies within the written text itself , e.g . changes in vocabulary , style or quality ? Incoherent text where the flow is not consistent or smooth , which may signal that a passage has been cut-and-pasted from an existing electronic source ? A large degree of similarity between the content of two or more submitted texts . This may include similarity of style as well as content ? Shared spelling mistakes or errors between texts ? Dangling references , e.g . a reference appears in the text , but not in the bibliography ? Use of inconsistent referencing in the bibliography suggesting cut-and-paste
Based on Clough (2003)
Typical Plagiarism Indicators 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 71/206 ? Most popular plagiarism detection scheme :? Finding the overlap of matching subsequences and substrings ( consecutive tokens ) of length ? n ( where n is derived empirically )? The longer n becomes , the more unlikely it is that the same sequence of n tokens ( words or characters ) will appear in the same order in independently written texts ? A similarity function is used to capture the degree of overlap between the two texts represented by the sets of ngrams and a chosen threshold above which texts are deemed plagiarised ? Problem : larger Ngrams are rare , difficult to define thresholds
String Matching Algorithms 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 72/206 ? Figures taken from 769 texts in the METER corpus : Uniqueness of Ngrams ( from Clough 2003) ? Greedy String Tiling ( or GST : see , e.g . ( Wise,1993)), an algorithm which computes a 1:1 mapping between the tokens in a text pair in such a way that as much of one text as possible is covered with maximal nonoverlapping substrings ( called tiles ) from the other . ? This algorithm computes the longest common substrings ( greater than length n ) between two texts without having to define an ngram size a priori . ? Figure 1 represents a tiling of two sentences after running GST ( tiles are highlighted ) with a minimum match length of 1 word.
Longest Common SubstringsComputed between Two Sentences 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 74/206 ? The output of GST algorithm is a set of maximal matches between the text pair : [ for two years ], [ driver who ], [ into the ], [ a ], [ queen ], [ was ] and [ banned ]. ? Different quantitative measures to detect plagiarism , e.g .:? the minimum and maximum tile length ? the average tile length ? the dispersion of tile lengths ? a similarity score based on tile length ( similar to that for ngram containment ). ? The challenge is to capture these tiling patterns such that derived and nonderived texts are distinguishable.
Longest Common SubstringsComputed between Two Sentences 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 75/206 Example of Tiling for Derived and Non-Derived Text ( from Clough 2003) ? It has been empirically found that : ? derived texts ( top ) share longer matching substrings ? both the tiling for a derived and nonderived text pair are in most cases apparently different 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 76/206 ? Combining evidence from various sources , e.g . ? use a Na?ve Bayes probabilistic classifier to combine evidence from several measures of similarity taken from a GST tiling and make a decision : derived or not-derived ? Supervised learning : training data required ( texts which have already been classified as plagiarised or not ) ? Unsupervised learning : can also be helpful in grouping together texts which exhibit similar characteristics ( e.g . clustering ) Machine Learning in Plagiarism Detection Preserving longer matching ngrams and tile lengths to make the approach resistant to simple edits ? Allow small gaps to represent token deletion ? Detect simple word substitution ( using WordNet ) ? The insertion of certain words such as domain-specific terminology and function words ( e.g . conjunctions ) ? Simple reordering of tokens ( e.g . transposition)
Relaxing the Approach 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 78/206 ? Existing work involves minimal natural language processing ( NLP )? Areas of NLP that could aid plagiarism detection , particularly in identifying texts which exhibit similarity in semantics , structure or discourse , but differ in lexical overlap and syntax ? NLP methods include : ? morphological analysis , part-of-speech tagging , anaphora resolution , parsing ( syntactic and semantic ), coreference resolution , word sense disambiguation , and discourse processing ? Future work :? several similarity scores based on lexical overlap , syntax , semantics , discourse and other structural features
NLP in Plagiarism Detection 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 79/206
Online Internet Plagiarism Services ? Plagiarism.org www.plagiarism.org ? The largest online plagiarism service available ? IntegriGuard www.integrigaurd.com ? EVE2 www.canexus.com/eve/abouteve.shtml ? None of the services details their implementation details ? All of them are commercial , but plagiarism.org allows free trial 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 80/206 ? Automatic scoring ? Essays ( eRater , Burstein and Chodorow , 1999)? Longer texts ( AutoTutor , Wiemer-Hastings et al , 1999) ? Automatic diagnosis , i.e . content assessment ( CAM ) on learner data ? Language learning ( Bailey and Meurers , 2008)? Error detection in Crater ( Leacock , 2004)? 85% accuracy
Assessing Short Textual Answers ? Measures student understanding with little regard to writing skills ? Example question (4th grade math question used in the National Assessment for Educational Progress ( NAEP)):
C-Rater ( Chodorow 2004) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 82/206 Technology of c-Rater ? Content expert develops a scoring guide ? Gold standard responses ? Recognizing the equivalence of the response to the correct answers ? Essentially paraphrase recognition ? Analysis in terms of : ? predicate argument structure ? resolving the referent of any pronouns in the response ? regularizing over morphological variation ? matching on synonyms or similar words ? resolving the spelling of unrecognized words ? Mapping canonical representations to those of the gold standard responses ? Rulebased ? 11th grade reading comprehension items ? Exact agreement with human scorers 84% 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 83/206 ? Analysis of responses to short-answer comprehension tests ? 13 sentences in length ? Error codes :? Necessary concepts left out of learner response ? Response with extraneous , incorrect concepts ? An incorrect blend/substitution ( correct concept missing , incorrect one present )? Multiple incorrect concepts ? Human disagreement in 12%, eliminated from the evaluation data Detecting Meaning Errors ( Bailey and Meuerers , 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 84/206 ? Input :? Learner?s response , one + target responses , question , source reading passage ? String-based analysis filter ? Linguistic analysis : annotation , alignment , diagnosis
Technology of CAM ? Alignment maps new concepts from learner's response to those in target ? Token level ( abstraction from string to lemma , semantic type ( e.g . date , location )? Chunk level ? Relation level ? Diagnosis analyzes if the learner's response contains content errors ? Evaluation ? Handwritten rules 81% on the development data , 63% on the test data ? Machine learning ( TiMBL ), 88% accuracy on the test data for binary semantic error detection task ? Viable results
Technology of CAM 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 86/206 ? Nonnative speech scoring ( Bernstein 1999; Zechner and Bejar , 2006, Zechner et al , 2007)? SET-10 ( Bernstein 1999) focuses on the lower entropy language aspects ? Tasks such as ? reading ? or ? repetition ?? Highly predictable word sequences ? TOEFL Practice Online Speaking test ( Zechner et al , 2007)? Focus on spontaneous , high-entropy responses ? Test with Heterogeneous Tasks ( THT ) ( Zechner and Xi , 2008)? Ranges from reading speech to opinion giving ? Assess communicative competence
Automatically Scoring Speech 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 87/206 ? Dimensions of assessement :? Comprehensibility , accuracy , clarity , coherence , appropriateness ? Evident through :? Speaker?s pronunciation , fluency , use of grammar and vocabulary , development of ideas , sensitivity to communicative context
Test with Heterogeneous Tasks 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 88/206 1. Reading aloud2. Picture description ( medium-entropy )? Describe a picture in detail ? Rated on the combined impact of delivery , use of structures , vocabulary , content relevance and fullness (3-point scale)3. Open-end short-answer questions4. Constrained short-answer questions5. Respond to a voice mail6. Opinion task ( high-entropy )? State an opinion on an issue and support its with reasons , examples , arguments , etc .? Rated on the combined impact of fluency , pronunciation , intonation and stress , grammar , vocabulary , content relevance , and cohesion and ides progression (5-point scale)
THT Task Types ? Adapt a nonnative English speech recognizer ( trained on TOEFL Practice Online data ) to transcribed THT task responses ? Compute a set of relevant speech features based on the recognition output ? Build a scoring model using a subset of features to predict human scores
Technology of SpeechRater 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 90/206 ? Human agreement ( kappa ): around 0.50 ( Picture ) and 0.72 ( Opinion )? Opinion task ? multiple regression employing Equal , Expert , or Optimal Weights ; picture task ? CART 5.0 ( classificaiton trees)
Evaluation 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 91/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 92/206
Readability ? " Readability is what makes some texts easier to read than others " ( DuBay , 2004)? A text's readability can be estimated with readability formulas , which provide an objective prediction of text difficulty ? Aims : ? match reading materials with the abilities of the readers ? support authors in writing clearly understandable texts
Traditional Readability Measures
Formula Date Features Example values1948
Fog index 1952
SMOG grading 1969 - # words with more than 3 syllables Flesch index - average # syllables / word - average sentence length - 30 = " very difficult "- 70 = " easy "- # words with more than 2 syllables - average sentence length - 5 = comic books - 10 = newspapers - 0 to 6 = low-literate - 19+ = postgraduate 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 94/206
Readability Statistics ? Computed using the style command
Rotk?ppchen 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 95/206 Statistical Models for Reading Difficulty ? Based on statistical models representing norms , specific populations and individuals ( Brown & Eskenazi , 2004)? Different models are created for each level of reading difficulty ? Features :? Lexical features : word unigrams ( Collins-Thompson & Callan , 2005; Heilman et al , 2008)? Grammatical features : frequency of specific grammatical constructions ( Heilman et al , 2007) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 96/206 Document Retrieval for Reading Practice ? Reading proficiency is a widespread problem ? Only 29% of high school seniors in public schools across the USA were proficient in reading according to a 2005 NCES study ( Miltsakaki & Troutt , 2008)? Low reading proficiency may have dramatic consequences ( DuBay , 2004):? The strongest risk factor for injury in a traffic accident is the improper use of child safety seats ? 79 to 94% of car seats are used improperly ? Installation instructions are too difficult to read for 80% adult readers in the US ? Use readability measures to identify suitable and authentic documents , given a reader profile / reading grade Vygotsky's Zone of Proximal Development?Materials for assisted reading should be harder than the reader's tested reading level , but within the zone of proximal development ? Materials for unassisted reading , e.g . medicine inserts , instructions , should be as easy as possible http://www.education.vic.gov.au / 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 98/206
Read-X ( Miltsakaki & Troutt , 2008) ? http://net-read.blogspot.com/
Keywords
Texts
ReadingLevel
Yahoo ! Internet search
Text extraction
Readability analysis
Text classification 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 99/206
REAP search ( Heilman et al , 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 100/206
Text Simplification ? The readability of a text can be improved by transforming it into a simpler text ? Characteristics of manually simplified texts ( Petersen & Ostendorf , 2007) :? shorter sentences ? fewer and shorter phrases ? fewer adjectives , adverbs and coordinating conjunctions ? nouns are less often replaced with pronounsOriginal text : Congress gave Yosemite the money to repair damage from the 1997 flood.Abridged text : Congress gave the money after the 1997 flood Automatic Text Simplification ? Related techniques : summarisation and sentence compression ? Syntactic simplification :? Removal or replacement of difficult syntactic structures , using handbuilt transformational rules applied to dependency and parse trees ( Carroll et al , 1999; Inui et al , 2003)? Lexical simplification :? Goal : replace difficult words with simpler ones ( Carroll et al , 1999; Lal & R?ger , 2002)? Difficult words are identified using the number of syllables and/or frequency counts in a corpus ? Choose the simplest synonym for difficult words in WordNet 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 102/206
Vocabulary Assistance for Reading ? Overall goal : support vocabulary acquisition during reading for :? children , who learn to read ( Aist , 2001)? foreign language learners , who read texts in a foreign language ? Problem : a word's context may not provide enough information about its meaning ? Aim : augment documents with dynamically generated annotations about ( problematic ) words 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 103/206
Selection of Target Words ? All words are annotated ? Annotate selected words ? Manually selected target words ? Automatically selected target words ? ( Aist , 2001):? Words with few senses in WordNet ( to avoid WSD )? Not a trivially easy word : three or more letters long , not in a stop list of function words , not a number ? Not a proper noun ? Socially acceptable , e.g . no secondary slang meanings ? ( Mihalcea & Csomai , 2007): keyword extraction methods 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 104/206
Resources for Vocabulary Assistance ? WordNet ( Aist , 2001):? Extraction of comparison words for a target word : antonym , hypernym , synonym ? Generation of factoids :? eggshell can be a kind of natural covering ? Problems : ? some of the automatically generated factoids are too obscure or do not match the sense of the word used in the original text ? some of the comparison words may be harder to understand than the target word ? hypernyms do not always capture the key elements of the meaning of a word
Resources for vocabulary assistance ? Collaborative and online resources , e.g . Wikipedia , Wiktionary http://lingro.com / 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 106/206 Wikipedia and Wiktionary as Lexical-Semantic Resources + This image is licensed under the GFDL . It is based on Bild:Foerderturm-Kamen.jpg .? Structure Mining ? Content Mining ? Usage Mining = Lexical semantic resources 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 107/206 Wikipedia Article PageFirst paragraph ? First paragraph ? Definition / Gloss 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 108/206
Wikipedia ? Redirect Pages ? Synonyms ? Pope Benedict XVI ? Joseph Ratzinger ? Joseph Cardinal Ratzinger ? Spelling variations ? Benedict the Sixteenth ? Benedict the 16th ? Benedict 16th ? Benedict 16? Benedict XVI ? Benedict xvi ? Misspellings ? Josef Ratzinger ( instead of Joseph )? Abbreviations ? PB16
Wikipedia ? Categories ? Articles ? Hierarchy
Engines Energy conversion
Piston engines
Aircraft piston engine
Piston Engine ConfigurationsAutomobile engines 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 110/206
JWPL ? Wikipedia API ? Freely available for research purposes?http://www.ukp.tu-darmstadt.de/software/
CategoryGraph
Page
CategoryWikipedia
ParsedPage SectionParagraph
Link
Table ... MetaData 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 111/206 Wiktionary as Lexical-Semantic Resource ? Language ? Etymology ? Pronunciation ? Part-of-speech ? Word senses ? Synonyms ? Derived Terms ? Translations ? Abbreviations , Antonyms , Categories , Collocations , Examples , Glosses , Hypernyms , Hyponyms , Morphology , Quotations , Related terms , Troponyms 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 112/206
JWKTL ? Wiktionary API
LanguageWiktionaryWord
PoSWiktionary
Sense SynonymsTranslations
Etymology
Pronunciation ...?? Freely available for research purposes?http://www.ukp.tu-darmstadt.de/software /
Wikify ! ( Mihalcea & Csomai , 2007) ? Aim : link keywords ( important concepts ) in a document to the corresponding Wikipedia page ? Keywords extraction ? Ranking : tf.idf , ?2 independence test , keyphraseness?Word Sense Disambiguation to identify the target Wikipedia page :? Lesk algorithm : measure of contextual overlap between the Wikipedia page of the ambiguous word / phrase and the context where the ambiguous word / phrase occurs ? Machine Learning classifier 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 114/206 Spelling Error Detection and Correction ? Aim : identify and correct spelling errors ? Types of spelling errors :? Nonword spelling errorsoccured instead of occurredater instead of after , later , alter , water , ate?Word conflation or splitting ? ofthe , understandhme ? sp ent , th ebook ? Malapropisms : real-word spelling errors in open-class wordsdiary ? dairythere ? their ? they're 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 115/206
Research Problems ( Kukich , 1992) ? Nonword error detection ? From the early 1970s to the early 1980s ? Focus on efficient pattern-matching and string comparison techniques ? Isolated-word error correction ? Started in the early 1960s ? Context-dependent word correction ? Started in the early 1980s ? Use of statistical language modelsTextbook overviews : ( Jurafsky & Martin , 2008; Manning , Raghavan and Sch?tze , 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 116/206
Nonword Error Detection ? ngram analysis : ? ngram = n-letter subsequences of words or strings ? examine each letter ngram in an input string ? find the ngram in a table of ngram statistics compiled from a corpus of text ? highly infrequent ngrams indicate probable misspellings ? especially useful for optical character recognition devices ? Dictionary lookup :? check if an input string appears in a dictionary of acceptable words ? techniques : hash tables , tries , finite-state automata , Aho-Corasick algorithm , ternary search trees Isolated Word Error Correction1) Detection of errors in single words , out of context2) Generation of candidate corrections ? Distance/Proximity metric between the correct word and the erroneous word ? Minimum edit distance : minimum number of editing operations ( i.e ., insertions , deletions , and substitutions ) needed to transform one string into another "=" Match ; " o " Substitution ; "+" Insertion ; "-" Deletion3) Ranking of candidate corrections based on the distance/proximity metric or occurrence counts
Distance = 4 ( c ) www.levenshtein.net 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 118/206
Isolated Word Error Correction
Problem : even humans do not achieve 100% accuracy levels , given isolated misspelled strings ( Kukich , 1992): ? vver ? over , ever , very ? ? wekk ? week , well , weak ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 119/206
Context-dependent Error Correction ? Also called context-sensitive spelling correction ? Aim : correct real-word spelling errors , which cannot be identified by dictionary lookup ? Between 25% and 40% of spelling errors are valid English words ( Kukich , 1992)? Use the context to help detect and correct spelling errors ? Based on language models 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 120/206 Spelling Correction for Foreign Language Learners ( Heift & Rimrott , 2007)? 80% of the mispellings produced by nonnative writers of German are due to insufficient command of the foreign language:Metz for Fleisch ( from Metzger)tanzed for tanzte ( from danced )? These errors are difficult to correct for generic spell checkers ? need for rules that are geared towards common L2 errors ? Importance of feedback : learners are more likely to correct a mistake if the feedback contains explicit information on the error and correction suggestions
Grammar Checking ? Tasks :? Grammatical error detection : identify sentences which are grammatically ill-formed ? Grammatical error correction : correct grammatically ill-formed sentences?Methods :? Rulebased checking : use of manually written rules ? Syntax-based checking : use the output of a parser ? Statistics-based : use statistical information about ngram frequencies ? The methods usually focus on a specific part-of-speech 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 122/206
Grammatical Error Types ? According to ( Nicholls , 1999):? Insertion of an unnecessary word : * affect to their emotions ? Deletion of a word : * opportunity of job?Word or phrase that needs replacing : * every jobs?Word use in the wrong form : * knowledges ? Grammatical difficulties for ESL learners :? Prepositions : * arrive to the town , * most of people , * He is fond this book ( Chodorow et al , 2007)? Verb forms : I can't * skiing well , I don't want * have a baby ( Lee & Seneff , 2008)? Articles 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 123/206
Rulebased Grammar Checking ? Analyse errors in a corpus and write rules to identify and correct these errors , based on POS information ? Rule patterns should not occur in correct sentences ? Examples :? Language Tool ( Naber , 2003)? Open Source language checker ? Rules are defined in XML configuration files and include feedback messages ? GRANSKA ( Eeg-Olofsson & Knutsson , 2003)? Rules expressed in a specific rule language 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 124/206
Syntax-based Grammar Checking ? Template-matching on parse trees ( Lee & Seneff , 2008)? Automatic introduction of verb form errors in a corpus ? Parsing of the corpus ? Identification of templates in the " disturbed " parse trees
Statistics-based Grammar Checking ? Detection of unfrequent sequences of words and/or POS tags :? POS bigrams ( Atwell , 1987)? POS tags and function words ngrams ( Chodorow & Leacock , 2000)?Machine learning :? Maximum entropy model trained with contextual features and rule-based filters ( Chodorow et al , 2007)? Machine learning model based on automatically labelled sequential patterns ( Sun et al , 2007) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 126/206
The Tip of the Tongue Problem
Writers may want to look for words that express a given concept and are appropriate in a given contextProblem : in order to access words in a traditional dictionary , you have to know the word you are looking for 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 127/206 Dictionary Lookup ( Ferret & Zock , 2006) ? Tip of the tongue problem : ? domesticated animal , producing milk suitable for making cheese ? NOT ( cow , buffalo , sheep )?? goat ? The mental lexicon is a huge network of interconnected words and concepts ? The network is entered through the first word that comes to mind and the target word is retrieved thanks to connecting links 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 128/206
Internal Representation
Wikipedia Graph 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 130/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 131/206 ? Developed during last 25 years , typically the domains of e.g . mathematics , science and technology ? Goal : the ability to engage learners in rich natural language dialogue ? Significant learning gains beyond classroom environments :? Learning gains from computer tutors by approximately .3 to 1.0 grade unit ( Corbett et al 1999)? Learning gains from human tutors by .4 to 2.3 grade units , though ? modest domain knowledge ? no training in pedagogy ? rare use of sophisticated tutoring strategies Intelligent Tutoring Systems with Conversational Dialogue 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 132/206 ? System presents problems and questions to learners ? Learner types in / utters answers in natural language ? Lengthy multi-turn dialogues as complete solutions / answers evolve Interaction with Intelligent Tutoring Systems ? CIRCSIM ( Evens and Michael 2006)? BEETLE ( Zinn et al 2002) ? Geometry Explanation Tutor ( Aleven et al 2003) ? Why2/Atlas ( VanLehn et al 2002) ? students explain physical systems ? ITSpoke ( Litman et al 2006) ? builds upon Why2, spoken language based ? SCOT ( PonBarry et al 2006) ? ProPL ( Lane and VanLehn 2005) ? AutoTutor ( Graesser et al 2003) ? students answer deep questions about computer technology ? a core set of foundational requirements for mixed-initiative natural language interaction in tutorial dialogue
Research on ITS 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 134/206 ? Speech acts in tutorial dialogue ( Marineau et al 2000) ? Dialogue acts ' correlation with learning ( Forbes-Riley et al 2005, Core et al 2003, Ros ? et al 2003, Katz et al 2003) ? Student uncertainty in dialogue ( Liscombe et al 2005, Forbes-Riley and Litman 2005) ? Comparing textbased and spoken dialogue ( Litman et al 2006)
Corpus-Based Studies 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 135/206 Cognitive and Affective States in Learning ? ITS as platforms to investigate the impact of tutorial interactions on affective and motivational outcomes ( e.g . self-efficacy ) along with cognitive measures ( i.e . learning gains ) ? Goal : identifying tutorial strategies that balance the tradeoff between cognitive and affective learning outcomes ? Widespread methodology : investigate human-human tutorial dialogues ( e.g . Boyer et al 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 136/206 ? By dialogue initiative :? System initiative ? Mixed-initiative ? By interaction modality :? Text-based ? Speech-based
ITS Interaction Style ? Tutoring Research Group at the University of Memphis ( e.g . Graesser et al , 1999) ? Intended for college students who take an introductory course in computer literacy ? Fundamentals of computer hardware , operating system and the Internet ? Goals :? To comprehend student contributions ? To simulate dialogue moves of normal ( unskilled ) or sophisticated tutors
AutoTutor 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 138/206 Screenshot of AutoTutor(Graesser et al , 2001) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 139/206 ? Major problem is printed at the top of the screen?Major questions are generated from a curriculum script :? Questions invite lengthy explanations and deep reasoning?Why , how and what-if questions ? Deep reasoning rather than short snippets of shallow knowledge ? 10 to 30 turns for a single question from a curriculum script ? Learner?s contributions are typed in
Interface Description 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 140/206 Example Tutorial Dialogue(AutoTutor : Graesser et al , 2001) ? The answer is not graded ( good / bad / score ) ? Multi-turn conversation to extract more information from the student ? Students learn by constructing explanations and elaborations of the material ( e.g . Chi et al , 1994) Information Delivery versus Knowledge Construction 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 142/206 System Architecture1. Animated agent?Tree-dimensional2. Curriculum script ? Important concepts , questions , cases , and problems3. Speech act classifier?Segmenting , parsing student?s response , rule-based utterance classification4. Latent semantic analysis ( LSA)?Evaluating the quality of students ? contributions5. Dialogue move generator?Can include question answering , repeating the question , encouraging 6. Dialogue Advancer Network?Uses speech act and LSA to select next dialogue move and discourse marker7. Question answering tool 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 143/206 ? Dialogue moves :? E.g . open-ended pumps , e.g . What else ?? Tutors have a set of expectations about what to include into the answer ? Expectation-1? Expectation-2? AutoTutor decides what expectation to handle next and selects a dialogue move ? Hints ( indirect )? Prompts ( inbetween )? Assertions ( direct )? Exit the cycle when the student articulated the expected answer How to Engage the Student in Conversation ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 144/206 ? Match students utterances to expectations ? Statistical , corpus-based measure of representing knowledge ? Latent Semantic Analysis ( LSA ) ? max function considering the current utterance and all combinations with previous learner?s utterances ? An expectation is considered covered if it exceeds some threshold value How to Evaluate the Quality of the Answer ? ? Use LSA in conjunction with various criteria ? Use next expectation with the highest score below threshold ( zone of proximal development ) ? Use next expectation with the highest LSA overlap with the previous covered expectation ( coherence ) ? Further constraints to advance the agenda in an optimal way How to Select the Next Expectation to Cover ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 146/206 ? Three channels of feedback :? Backchannel ? acknowledge the learner?s input , based on important nouns , e.g . uhhuh ? Pedagogical feedback on the learner?s previous turn , based on LSA scores ? Negative , e.g . not really ? Neutral negative , e.g . okay ? Neutral positive , e.g . okay ? Positive , e.g . right ? Corrective feedback ? repair bugs and misconceptions ? Need to be explicitly anticipated
How to Give Feedback to a Student ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 147/206 ? Dialogue advancer network ( DAN ), mixed-initiative dialogue ? Formally an augmented state transition network ? Selection of dialogue move on turn N+1 is sensitive a large set of parameters computed from dialogue history ? Student : What does X mean?Tutor : answer by giving definition from a glossary ? Student : gives an assertionTutor : evaluate the quality and give short evaluative feedback
Dialogue Management 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 148/206 ? Pump ? Hint ? Splice ? Prompt ? Prompt response ? Elaboration ? Summary ? Five forms of immediate short-feedback
Types of Dialogue Moves ? Organizes the content of topics covered in the dialogue ? Each topic is associated with :? A set of expectations ? A set of hints and prompts for each expectation ? A set of anticipated bugs/misconceptions and their corrections ? ( optinally ) pictures or animations
Curriculum Script 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 150/206 ? Create an LSA space ? Identify a corpus of documents on the domain knowledge ? Lesson planner ? Create a curriculum script with deep reasoning questions and problems ? Compute LSA vectors on the content of curriculum scripts ? Prepare glossary of important terms and their definitions
Authoring Tools 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 151/206 1. Glossary of terms and definitions ( metacognition)2. LSA space for conceptual physics ( comprehension)3. Curriculum script with deep reasoning questions and associated answers ( production ) ? Most labour-intensive
Domain Adaptation Levels : 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 152/206 Why2 ( http://www.pitt.edu/~vanlehn/why2000.html )? Chi et al found that having students explain physical systems qualitatively positively correlated with learning outcomes ? Explanations can be done on formal and graphical languages , but also in natural languages ? Why2 targets to coach students explain physical systems in natural language ? Idea : ask the student to type in an explanation for a simple physical situation
Example dialogue 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 154/206 ? Student's utterance is analyzed to detect any misconceptions ? If a misconception is detected , a knowledge construction dialogue is initiated ( KCD ) ? Misconceptions are anticipated by collecting and analyzing a corpus of explanations from students
Dialogue Management 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 155/206 ? A speech-enabled version of Why2-Atlas tutoring system ? Workflow :? The student?s essay is parsed ? A set of dialogue topics concerning misconceptions or incomplete explanations is extracted ? ITSpoke than engages student in a dialogue that covers these topics ? Therefore , the student revises the essay ? End the tutoring problem ? Cause another round of dialogue/essay revision ITSpoke ( Intelligent Tutoring SPOKEn dialogue system ) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 156/206 ? Backend is Why2-Atlas system ( VanLehn et al 2002) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 159/206 ? Sphinx speech recognizer ( Huang et al , 1993)? Trained with example user utterances ? Domain adaptation by humancomputer typed corpus ? Language model enhancement by human-human spoken language corpus ? Festival speech synthesizer ( Black and Taylor , 1997)? Sentence-level syntactic and semantic analysis modules ( Ros ?, 2000)? Discourse and domain level processors ( Makatchev et al , 2002)
System Architecture 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 160/206
ITSpoke Annotated Dialogue Excerpt
Benefits of Spoken Interaction ? Benefits of human-human tutoring through spoken interacton ( Lemke , 1990; Chi et al 1994) ? Spontaneous self-explanantion occurs more frequently in spoken tutoring ( Hausmann and Chi , 2002) ? Speech contains prosodic and acoustic information to predict emotional states ( Ang et al , 2002; Batliner et al , 2000) ? Connection between learning and emotion ( Coles , 1999) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 162/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 163/206
Characteristics of Web 2.0 ? Collective intelligence ? Huge amount of data ? Fast growing ? Noise ? Duplicates ? Content of different quality 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 164/206 eLearning 2.0 ? Main characteristics:?Worldwide learning community ? Educational material produced both by students and teachers ? Tools:?Wikis ? Blogs ? Podcasts?Widgets ? ...
41 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 165/206 " CALL 2.0" 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 166/206
Widgets for CALL 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 167/206
Use of Web 2.0 Resources 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 168/206 Community-rule-based Grammar Checking ? A new paradigm ? http://community.languagetool.org Motivation : Information overload in E-Learning
QA-ELQuestion Answering for E-Learning 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 170/206
QA-ELQuestion Answering for E-Learning 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 171/206
Social Q&A Sites ? Solution to the problem of automatically answering learners ' questions : use repositories of already answered questions ( Bernhard & Gurevych , 2008) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 172/206 What is actually the Quality of Web 2.0 Resources??Wikipedia :? Open edit policy , yet high quality articles ( Giles , 2005)? 42 entries tested by experts ? average science entry in Wikipedia contained around four inaccuracies ? average science entry in Encyclopaedia Britannica contained around three inaccuracies ? Automatic assessment of the quality of these ressources :? Social Q&A sites ( Jeon et al , 2006; Agichtein et al , 2008)?Wikipedia ( Druck et al , 2008)? Forums ( Weimer et al , 2007; Weimer & Gurevych , 2007) ? Web 2.0 leads to massive amounts of data ? Users need content of good quality ? Current approach ? Users label the data for quality ? Labels are used for filtering ? Problems :? Happens rarely ? New item problem ? Premature negative consent ( Lampe and Resnick , 2004) Quality Assessment of User Generated Discourse 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 174/206 Markus Weimer and Iryna Gurevych . 2007. Predicting the Perceived Quality of Web Forum Posts . RANLP , Borovetz , Bulgaria.
Goal : Develop a system to automatically assess the perceived quality of forum posts
Case Study 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 175/206 ? Essay scoring ? Established in systems like eRater ( Attali and Burstein , 2006)? Very specialized approach : It is known what a ? good ? essay is ? Input on which features to use ? Automatically assessing review helpfulness ( Kim et al , 2006)? Goal : predict the helpfulness of product reviews on Amazon.com ? Also very specialized :? The rating task is clearly defined : helpful / not helpful for buying decision ? Dominant feature is metadata-dependent : star rating of the product
Related Work on Quality Assessment 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 176/206 ? Adapt to the quality standards of a user community ? Be independent of metadata-based features ? Apply the system to forums from different domains
Requirements
Approach in Weimer and Gurevych (2007) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 178/206 ? Surface ? Length in tokens ? Question Frequency ? Exclamation Frequency ? Capital WORD Frequency ? Lexical ? Spelling Error Frequency ? Swear Word Frequency ? Syntactic ? Part of speech distribution ? Form Specific ? IsHTML ? IsMail ? Quote Fraction ? URL Count ? Path Count ? Similarity ? Cosine between the post unigram and the forum unigram
Classification Features 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 179/206 ? Provided by Nabble.com ? Preprocessing of the data :? Removal Non-English posts ? Removal of posts with a rating of exactly 3 stars ? Binarization of the data into good/bad posts ? Three data sets :? ALL : All the posts ? SOFT : Posts from the software category at Nabble.com ? MISC : Posts from the other categories ? Data available upon request
Data 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 180/206
Descriptive Statistics ? Stratified tenfold cross validation with different feature sets ? Evaluation measure : mean average precision ? Features were extracted using Apache UIMA ? Classifier :? LibSVM ? Gauss Kernel ? Parameters C = 10, ? = 0.1? No model selection was performed ? Baseline : Majority class classifier
Experiments : Setup 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 182/206
Results 77,5 74,1 69,2 74,1 46,5 64,7 53,5 89,1 85,1 82,6 71,8 62,0 61,8 61,872,0 66,0 66,7 66,0 66,0 71,3 66,0 0,0 22,5 45,0 67,5 90,0 All Forum Specific Syntactic Lexical Similarity Surface Baseline
ALLSOFTMISC 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 183/206 true good true bad sumpred . good 1517 456 1973pred . bad 312 1133 1445sum 1829 1589 3418 true good true bad sumpred . good 490 72 562pred . bad 95 875 970sum 585 947 1532 true good true bad sumpred . good 1231 516 1747pred . bad 13 126 139sum 1244 642 1886
ALL
SOFT
MISC
Error Analysis : Confusion Matrix 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 184/206 ? Automatically generated mails ? Can be filtered out in preprocessing ? Non-textual content ? May be used as a feature , e.g . code examples in a software developer?s forum ? Very short posts ? Might be improved through metadata about the user or thread information ? Opinion based ratings ? Ratings based on domain knowledge ? Probably form the upper bound for our approach
Error Analysis : Typical Errors > Thank You for the fast response , but I?m not > sure if I understand you right . INTERRUPTs can > be interrupted ( by other interrupts or signals ) and > SIGNALS not.Yup . And I responded faster than my brain couldshift gears and got my INTERRUPT and SIGNAL crossed .> All my questions still remain!Believe J"org addressed everything in full . That thecompiler simply can?t know that other routines haveleft zero reg alone and the compiler expects tofind zero there.As for SREG , no telling what another routine wasdoing with the status bits so it too has to be savedand restored before any of its contents possibly getmodified . CISC CPUs do this for you when stackingthe IRQ , and on RTI.
Human rating : - System rating : +
Ratings Based on Domain Knowledge 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 186/206 > But you would impose US law even in a country > where smoking weed is legalGiven that most of our users and most significant press coverage is American , yes . That is why I drew the line there.Yes , I know it isn?t perfect . But it?s better than anything else I?ve seen . Human rating : - System rating : +
Opinion Based Ratings 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 187/206 ? Quality assessment is machine learnable ? The system performs best with forum specific features (~90%)? Even without forum specific features , the system gives satisfactory result (~82%)? Further experiments needed on :? different data sets ? types of user-generated discourse ? New classification features :? structure of the forum ? lexical semantic features
Conclusions 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 188/206 Introduction : eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application : electronic career guidance
Outline
The SIR project:Semantic Information Retrieval for Electronic Career Guidance funded by the German Research Foundation 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 190/206
Information Retrieval
Descriptions of professions
Documents 1. ...2. ..3. ? Ranked List of Professions
Essay about professional interests
Query
Electronic Career Guidance 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 191/206
Profession 3
Profession 1
Profession 2
Profession ... Essay
Profession ...
Profession ...
Profession ...
Semantic Relatedness
I like baking cakes...
...pastries......confectioner ... ... food processing industry
Vocabulary Mismatch Problem 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 192/206 ? Semantic relatedness ( SR ) as measure for document relevance Lexical-Semantic KnowledgeSemantic Relatedness Measure
Information Retrieval System
Semantic IR Models
Lexical Semantic Knowledge ? GermaNet : German lexical-semantic wordnet ? Nouns , verbs , adjectives ? 27,824 noun synsets , 8,810 verb synsets , 5,141 adjective synsets ? 60,646 words in synsets?Wikipedia ? Free online collaboratively constructed encyclopedia ? Articles , links , categories ( Zesch , Gurevych & M?hlh?user , 2007)?Wiktionary ? Free online collaboratively constructed dictionary?Words , categories , semantic relations ? http://www.ukp.tu-darmstadt.de/software/WikipediaAPI 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 194/206
Semantic Relatedness Measures ? Path length ( PL )? Pseudo glosses based ( Gurevych , 2005)? Information content based ? Resnik (1995)? Jiang & Conrath (1997)? Lin (1998)? Explicit semantic analysis ( Gabrilovich & Markovitch , 2007) 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 195/206 Experiments in Information Retrieval A ? Andererseits arbeite ich besonders gerne am Computer , kann programmieren in C , Python und VB und k?nnte mir deshalb auch vorstellen in der Software-Entwicklung zu arbeiten .? ? Topics - 30 essays of human subjects about professional interests ? Queries :- Nouns , Verbs , Adjectives - Nouns - Keywords ( set of 41 keywords)Profession 3
Profession 1
Profession 2
Profession ... Query
Profession ...
Profession ...
Profession ...
17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 196/206 ? Provided by the German Federal Labour Office ? Descriptions of 4,000 professions and 1,800 vocational trainings ? Prepared by professionals ? Evaluation on 529 descriptions of vocational trainings ? Using parts which describe profession itself , but not training or administrative details
Document Collection ? 41 keywords in 3 categories ? Ranked list of professions for each topic ? Automatically extracted from knowledge base ? Used for creating relevance judgments " Gold Standard " 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 198/206 41 Keywords educate , use/program computer , office , outside , animals/plants , ...
Essay Profession 1 Profession 2 Profession 3Human Annotation
Scoring
Profession 1Profes-sion 2 Profession 31. 2. 3. irrelevantrelevant
Relevance Judgments 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 199/206 ? Standard IR measures using relevance judgements ? Precision ? recall diagrams ? Mean average precision ? Rank correlation with knowledge-based ranked list ? Spearman?s Rank Correlation Coefficient ? Parameters :? Preprocessing configurations ? Semantic relatedness measures ? Lexical-semantic knowledge sources
Evaluation 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 200/206 Preprocessing Configurations & Measures , PrecisionRecall Preprocessing Configurations & MeasuresSpearman?s Rank Correlation 00,1 0,20,3 0,40,5 0,6
N , V , A Nouns Keywords
EBEB+SYNEB+HypoLINESA-WordESA-Text 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 202/206 ESA-Text tf.idf with Different Lexical-Semantic Resources
Nouns,Verbs,Adjectives Nouns Keywords0 0.050.1 0.150.2 0.250.3 0.350.4 0.450.5 0.550.6 0.65 Mean Average Precision WikipediaGermaNet HyperGermaNet RadialWiktionary 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 203/206 ? Opportunity for NLP and e-NLP ?? Remove knowledge acquisition bottleneck ? New forms of eLearning ? Excellent playground for NLP ?? eLearning 2.0 discourse types almost not studied ? Can we actually learn from BioNLP?
Some Thoughts on eLearning 2.0? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 204/206 ? Establish an international community ? ACL-associated meeting series ( e.g . ACL-BEA Workshop 2008)? Related Tutorials ? Resources :? Bibliography ? Research groups ? Projects ? Annotated corpora ? Tools
How to Promote e-NLP ? ? A lot more research is done on:?Computer-Assisted Language Learning ? Intelligent Tutoring Systems ? Information search for eLearning?Educational blogging?Annotations and social tagging?Analyzing collaborative learning processes automatically ? Learner?s corpora and resources ? eLearning standards , e.g . SCORM
What the tutorial has not covered ? 17.08.08 | Computer Science Department | Ubiquitous Knowledge Processing Lab | 206/206 Thank you ! http://www.ukp.tu-darmstadt.de /
