Coling 2010: Poster Volume , pages 498?506,
Beijing , August 2010
s???????Tz???????Gz????????Gh???????G??Gt??????????????G
y???Gs????????G
Hayeon Jang
Dept . of Linguistics
Seoul National University
hyan05@snu.ac.kr
Hyopil Shin
Dept . of Linguistics
Seoul National University
hpshin@snu.ac.kr
Abstract
In this paper , we propose language-specific methods of sentiment analysis in morphologically rich languages . In contrast of previous works confined to statistical methods , we make use of various linguistic features effectively . In particular , we make chunk structures by using the dependence relations of morpheme sequences to restrain semantic scope of influence of opinionated terms . In conclusion , our linguistic structural methods using chunking improve the results of sentiment analysis in Korean news corpus . This approach will aid sentiment analysis of other morphologically rich languages like Japanese and Turkish.
1 Introduction
The Internet is a global forum where citizens of the world gather to express their opinions . Online services exist for users to share their personal thoughts while the use of blogs and Twitter substitutes for private diaries . For this reason , sentiment analysis which automatically extracts and analyzes the subjectivities and sentiments ( or polarities ) in written texts has recently been receiving attention in the field of NLP.
Sentiment analysis of English employs various statistical and linguistic methods referencing such linguistic resources as The Berkeley Parser and SentiWordNet . In the case of Korean , however , most previous works have been confined to statistical methods which focus either on the frequency of words or relevance of cooccurring words only . This is because it is hard to find proper resources due to the nature of Korean , exhibiting such features as rich functional morphemes , a relatively free word-order and frequent deletion of primary elements of sentences like the subject and object . The major drawbacks of statistical-based approaches are the facts that the ? real ? meaning of the expressions which we feel when we read them cannot be reflected in the analysis , and that complex statistical measuring methods are computationally taxing.
In this paper , in order to overcome previous shortcomings , while making use of Korean case studies we propose a new approach for morphologically rich languages that makes effective use of linguistic information such as the semantic classes of words , semantic scope of negation terms like not , no , and the functional meaning of modal affixes . Especially , this approach makes chunk structures by using dependency relation of morpheme sequences to limit the semantic scope of influence of opinionated terms . This chunking method is simpler and more efficient than total syntactic parsing . In addition , we utilize subjectivity clues and contextual shifters whose effectiveness is established in previous references.
The contents of this paper are as follows : firstly , we review previous works related to our approaches . We follow up by introducing the framework and main processes of our approach are introduced . Finally , we describe our experiments and show how a linguistic approach is feasible in sentiment analysis of Korean as a morphologically rich language.
2 Related Work
Sentiment analysis research has been performed to distinguish the authors ? polarity ( sentiment orientation ) on certain topics from document-level ( Turney , 2002: Pang et al , 2002; Dave et al ., 2003) to sentence-level ( Hu and Liu , 2004; tence-level sentiment classification with our presupposition that the polarity of sentences in a single document can be diversified due to the inclusion of various subtopics.
Recently , much research has focused on sub-jectivity1 extraction that divides objective facts from subjective opinions in data . Pang and Riloff (2005) and Yu and Hatzivassiloglou (2003) trained sentence-level subjectivity classifiers and proved that performing sentiment analysis targeting selected subjective sentences only gets higher results . We adopt a method of Wiebe and Riloff (2005)?s methods which classifies sentences containing more than two lexical items associated with subjectivity and compare the result of the experiments on full and extracted subjective corpora.
The core of the proposed new approach is the use of structural information in morphologically rich languages in the process of sentiment analysis . Choi et al (2005) and Mao and Leba-non(2006) are representative of the structured sentiment analysis approach which takes advantage of Conditional Random Fields ( CRF ) to determine sentiment flow . McDonald et al (2007) also dealt with sentiment analysis , via the global joint-structural approach . Furthermore , since there are a lot of good parsers for English data , Meena and Prabhakr (2007) and Liu and Seneff (2009) utilized sentiment structure information by such parsers such as Berkeley Parser.
1 The term ? subjectivity ? is equivalent to Quick et al (1985)?s private state which was defined as the words and phrases expressing individual mental and emotional states.
In the case of Korean , much research applies dependency grammars for reducing the complexity of sentences to match the characteristics of Korean ( Kim and Lee , 2005; Nam et al , 2008) but this still causes problems which prohibit wide use . Therefore we suggest a new morphological chunking method that binds semantically related concatenations of morphemes . This helps to define boundaries of semantic scopes of opinionated terms and is faster , simpler and more efficient on sentiment analysis than a general full parser.
Our approach focuses on the role of contextual shifters as well . In this paper , the term ? contextual shifter ? covers both negation shifters and flow shifters : the former refers to the terms which can change semantic orientation of other terms from positive to negative and vise versa , the latter the terms which can control sentiment flow in sentences , for example , in English not , nobody ( negation shifters ), however , but ( flow shifters ). Kennedy and Inkpen (2006) did sentiment analysis of movie and product reviews by utilizing the contextual shifter information.
Miyoshi and Nakagami (2007) also used this method to see the advancement of the result on sentimental analysis of electric product reviews in Japanese . In this work , we make use of the functions of each shifter to properly modify the value of the terms in the sentences and limit the number of the features which have to be observed in the analysis process to increase efficiency.
Figure 1. Sentiment Analysis Framework
The process of sentiment analysis in this paper is described in Figure 1. In this section , we explain each step of the process in detail.
3.1 Morphological Analysis
Korean is an agglutinative language where roots and affixes which have their own functional meaning combine to form complete words . Consequently , sufficient morphological analysis is very important to catch the precise and deep meaning of such expressions . If a certain sentence is misunderstood by wrong morphological analysis , there will be a strong possibility that opinionated terms in the sentence cannot be correctly analyzed.
We used the KTS 2 which is opensource probability based Korean morphological analyzer . Although the probabilistic rules established in KTS are elaborate , the main source of inaccuracy is rooted in the inadequacy of the lexicon.
After categorizing all listed words in the sentence , the remaining words are mostly classified as general nouns . In this case , the terms which should play a role as important features in the process of sentiment analysis will be probably misunderstood.
(1) ?? ??? ?? nemu cinpuha-n nayyong too stale-AD3 content ? too stale contents ? (2) ??/ a ??/ ncs ?/ xpa nemu/a4 cinpu/ncs ha/xpa ?/ exm ??/ nc n/exm nayyong/nc (3) ?/ npp ??/ nc ?/ nc ne/npp mucin/nc pu/nc ?/ nc ??/ nc han/nc nayyong/nc 2 http://kldp.net/projects/kts / 3 Abbrebiates : AD(adnominal suffix ), NM(nominative particle ), IN(instrumental particle ), SC(subordinative conjuctive suffix ), CP(conjunctive particle ), PST(past tense suffix ), DC(declarative final suffix ), RE(retrospect-ive suffix ), CN(conjectural suffix ), PR(pronoun ), PP(pr-opositive suffix ), AC(auxiliary conjunctive suffix ), GE ( genitive particle ) 4 POS tags of KTS : a(adverb ), ncs(stative common noun ), xpa(adjective-derived suffix ), exm(adnominal suffix),nc ( common noun ), npp(personal pronoun ) ? you Mujin(place name ) wealth resentment contents ? For example , if sentence (1) which has to be analyzed as in (2) is incorrectly analyzed as in (3). This fault result ignores original spacing and randomly conjoins syllables in order to find the lexical items included in the dictionary because of the lack of lexicon . As the result , we cannot grasp the intended sentiment cinbu ? stale ? in respect to the object nayyong ? contents ? in the sentence . In order to solve such problems , we expanded the lexicon of KTS by adding 53,800 lexical items which are included in the Sejong5 dictionary.
3.2 Subjectivity and Polarity Tagging
News corpora have no marks representing polarity of sentences as exist in the grading systems found in movie review corpora . In addition news data contain relatively more objective sentences which corpora tend to refer to as facts , as compared with reviews . Therefore in the case of news corpora there is a need to process the annotation of subjectivity and polarity tags for each sentence manually.
In our work , two native Korean annotators manually attached polarity labels to each sentence . Sentences are classified as subjective when they contain opinions pertaining to a certain object . Even if the opinion is not expressed on the surface using direct sentiment terms , the sentences are classified as subjective when the annotator can feel the subjectivity through the tone of voice . In the case of sentences containing common sense polarity value words such as donation , murder , etc , terms do not work as the judgment criterion , rather the annotator?s judgment about the main theme of the sentence is applied . Only when the sentences are classified as subjective , the polarity tags are attached . The agreement rate of the two annotators in the manual annotation of polarity is 71%.
5 The 21 st century Sejong Project is one of the Korean information policies run by the Ministry of Culture and Tourism of Korea . The project was named after King Sejong the Great who invented Hangeul.
(http://www.sejong.or.kr /)
The subjective lexicon used in subjectivity extraction contains 2,469 lexical items which includes 1,851 nouns , 201 verbs , 247 adjectives , 124 adverbs , 44 suffixes , and 2 conjunctive particles . The lemmas of Sejong dictionary are classified by a total of 581 semantic classes . Among them are 23 subjectivity-related semantic classes which include Abusive Language , External Mental State , Internal Mental State etc . Firstly , we have registered those lexical items ? nouns , adjectives , verbs - under subjectivity-related semantic classes . Since they will be compared with morphologically analyzed data before subjectivity classification , all items were registered as tagged forms . Nouns took the biggest portion in the lexicon through this process , since adjectives and verbs which consist respectively of stative nouns ( ncs ) and active nouns ( nca ) plus derived suffixes ( xpa , xpv ) were all registered as nouns.
In Korean , sentiment can also be judged from particles and affixes having modal meaning.
(4)??? ????? ???? 3??? ???.
jengpwu-ka mwuungtap-ulo tayungha-nci 3il-ina cina-ss-ta.
Government-NM no response-IN action-SC 3days-CP pass-
PST-DC ? It already passed 3 days after government did not response ? (5) ? ??? ? ????? ?????.
ku paywu-ka an-nao-ass-te-lamyen coh-ass-ltheyntey the actor-NM not-star-PST-
RE-if nice-PST-CN ? It were nice , if the actor would not have starred the main character ? (6) ?? ?? ?????.
ku-ke cengmal masiss-ess-keyss-ta that-PR really delicious-
PST-CN-DC ? That must have been really delicious ? For example , conjunctive particle -( i)na in the sentence (4), final suffix - ltheyntey in (5), and prefinal suffix - keyss in (6) are very influential in judging the subjectivity of sentences . Therefore , we added those functional terms in the subjective lexicon.
We classified the sentences which contains more than two subjective items as subjective.
When the sentence contained less than five morphemes , however , we manage to judge the sentence as subjective even when only one subjective item shows . The result of subjectivity extraction is confirmed by the widely used statistical method , TFIDF , in the following section.
3.4 Term Weighting
In our process of sentiment analysis , every term gets its own values by using polarity dictionaries and contextual shifters . In this section we introduce our polarity dictionary and contextual shif-
Label Number of items Lexical items
Positive 2,285 (1838 nouns , 133 verbs , 314 adjectives ) Coh/pa ? good ?, kelcak/nc ? masterpiece ?, chincel/ncs ? kind ? Negative 2,964 (2300 nouns , 359 verbs , 305 adjective)
Nappu/pa ? bad ?, ssuleki/nc ? trash ?, koylophi/pv ? harass ? Cynical 21 ( adverbs ) celday/a ? Never ?, kyeu/a ? barely ? Intensifier 91 (80 adverbs , 10 nouns , 1 interjections ) acu/a ? very ?, hancung/a ? more ?, tanyeonkho/a ? decisively ? Conjectural 19 (13 final suffixes , 4 prefinal suffixes , 2 adnominal suffixes ) keyss/efp CN , lthenteyo/ef CN , l/exm CN Obligative 6 (4 final suffixes , 2 auxiliary conjunctive suffixes ) eya/ecx ? must ?, eyacyo/ef PP Quotative 5 ( final suffixes ) ntanunkun/ef DC , tayyo/ef DC
Table 1. Polarity Dictionary weighting methods of our approach is described.
Polarity dictionary : Table 1 shows our polarity dictionary used in sentiment classification.
In the same way as a subjective lexicon , all lexical items are registered in the shape of a tagged morpheme . In addition , every item has labels with its own functional categories.
First , Positive and Negative refer to the basic polarity value of individual terms of sentences.
The terms that are neither positive nor negative are classified as neutral . We registered nouns , adjectives and verbs included in Sejong dictio-nary?s semantic class related with emotion or evaluation such as Positive Property Human , Negative Property Human , etc . After that , we selected the terms that are generally used to express polarity from other review corpora and added them to the dictionary . Since we deal with online texts , we also added acronyms , neologisms and new words which are frequently used to express opinion online.
Next we add various functional lexical items that are from other parts of speech to the polarity dictionary . Cynical items play a role of adding negative nuance to sentences . Intensifiers emphasize the meaning of following expressions.
Conjectural , Obligative and Quotative items refer to something other than the author?s opinion.
Conjectural and Obligative means that the opinion included in the expressions is not actual but hypothetical . Quotative means that opinionated terms which are in same phrase express another person?s opinions.
To determine the value of the terms , our approach uses a very simple measuring method.
Every term initially gets +1 if Positive , -1 if Negative . All other words receive a value of 0.
In the next step , the contexts of the sentences are examined and the values are modified . In the case of simple classification which does not go through the chunking process , we consider the distance of content words in Korean sentences which have various auxiliaries and affixes , and set a [-2, +2] window . In the case of structural classification , we take advantage of structures made by chunking . If Positives and Negatives are neighboring , we modify the values of the terms to reflect the fact that they influence each other . When Cynical items appear with Positives , we multiply by -1 to the value of Positives.
When Cynicals appear with Negative items , we intensify the value of Negative by multiplying by 2. If Cynicals appear with neutral terms , we change the value of neutral terms to -1. The value of the terms which are affected by the Intensifier doubles , whereas the values of the terms which are in the scope of Conjectural , Obligative and Quotative items are reduced to half . In this way we control the importance of the terms in the sentence.
Contextual Shifters : contextual shifters in Korean consist of 13 negation shifters ( adverbs such as an/a ? not ?, mos/a ? cannot ? and auxiliary verbs such as anh/px ? not ?, mal/px ? stop ?) and 23 flow shifters ( sentence-conjunctive adverbs such as kulena/ajs , haciman/ajs ? but , though ?, subordinative conjuctive suffixes pnitaman/ecs , ntey/ecs CN and conjunctive suffixes such as eto/ecx AC).
Since negation shifters play the role of shifting the polarity of the sentiment terms in our approach , we multiply them by -1. In the case of flow shifters , we limit the number of features to the terms after the shifter appears . We deemed it more important to understand an author?s empathetic point , rather than to catch full sentiment flow in the sentences . Also such emphasized contents mostly exist after the flow shifters.
Therefore we utilize this characteristic to reduce the work load and to prevent confusions which are caused by other minor sentiment terms.
(7) ??? ?? ??? ???? ???? ????.
umak-to coh-ko yengsang-to coh-ass-nuntey sutholi-ka pyello-yess-ta music-also good-CN image-also good-CN story-NM not so good-PST-DC ? music was good and image also good though , story is not so good ,? For example , in the sentence (7) - nuntey functions as a flow shifter . Dealing with the words after ? nuntey , we can limit the object morphemes to 5 out of 14. Therefore , measuring load is significantly reduced , and furthermore , we can prevent the confusion from two positive terms coh ? good ? before the flow shifter.
502 3.5 Chunking using morphological dependency relation In our approach , instead of complete syntactic parsing we use a chunking method based on the dependency relation of morpheme sequences in terms of the provision that it is important to limit the semantic influential scopes of main opinionated expressions.
Korean is a head-final language : in terms of dependency grammar , governors are always located after their dependents . We reflect upon this characteristic to form a relation if a certain morpheme acts as the governor of a previous morpheme . Chunks ( small and mid nodes shown in figure 2.) are formed until an unrelated morpheme appears . The terms in a single chunk exert great semantic influence to control the value of each other . After determining the values of every morpheme in each chunk , this process is replicated at a higher level and finally the ultimate values of every term in the sentence are determined.
For example in Figure 2, the structure [[ chen+nyen]+uy ] [ seywel+i ] [ hulu+eto ] [ kkuthna+ci+anh+nun ] [ miwan+uy ] [ sarang ] is the result of the chunking process of the sentence chen-nyen-uy seywel-i hulu-eto kkuthna-ci anh-nun miwan-uy salang 1000-year-GE time-NM flow-CN finish-CN not-AD incomplete-GE love ? an incomplete love that has not finished even after 1000 years ?. If we focus on the terms after the flow shifter - eto , the negation shifter anh ? not ? in the first phrase only influences the verb kkuthna - ? finish ? in the same chunk . This limitation of semantic scope of the negation shifter eliminates the possibility that it excessively modifies the values of other unrelated elements.
Since the simple classification has a [-2, +2] window , miwan ? incomplete ? is also influenced by - anh . Then the value of miwan becomes +1 which is classified as a positive term , and the whole expression miwan-uy salang ? an incomplete love ? is misclassified as positive.
4 Experiment 4.1 Corpora
Since movie review data is commonly used for sentiment analysis , we primarily collected movie reviews . Following the comments of many previous works that it is hard to separate the sentences which mention the plot of movies from opinion sentences , especially short movie reviews which containing 1~2 sentences deliberately selected . The reason is that short reviews having limited space probably include opinions only . Movie review data of less than 20 characters was crawled from a representative movie site in Korea , Cine216. It contains 185,405 reviews ranging from December 31, 2003 to December 28, 2009 ( total 19.5MB).
Next , we collected 79,390 news articles from January 1, 2009 to April 7, 2010 ( total 146.6MB ) from the web site of the daily newspaper , The Hankyoreh7. The news data includes both objective and subjective sentences , and is categorized into 3 groups by the following characteristics : 71,612 general news articles , 3,743 opinionated news articles having subjective subtopics such as ? Yuna Kim , terrorism , etc .? and 3,432 editorial articles including columns and contributions . After randomly extracting 100 articles from each data group a Korean annotator attached subjectivity and polarity labels to each 6 http://www.cine21.com / 7 http://www.hani.co.kr / Figure 2. Chunking structure of the below sentence . ( A short movie reviews ) ??????????????????? chen-nyen-uy seywel-i hulu-eto kkuthna-ci anh-nun miwan-uy salang 1000-year-GE time-NM flow-CN finish-CN not-AD incomplete-GE love ? an incomplete love that has not finished even after 1000 years ? consists of 1,225 general news sentences , 1,185 subtopic news sentences and 2,592 sentences of editorial articles.
4.2 Experiment 1: Short Movie Reviews Table 2 shows the result of a 5-fold cross variation experiment on the sentiment analysis of short movie review data using SVMlight . The numbers in bold face are the values being larger than the baseline , the results using TFIDF . A subjectivity extraction experiment was not carried out because of the presumption that all movie reviews used in this work are subjective.
(There were a few reviews containing quotes from the movies or meaningless words only.
Such cases , however , were ignored .) In the case of movie review data , selected subjective data is regarded as having stronger subjectivity.
When subjective data is compared with total data by the same experimental methods , there are consistent improvements in sentiment analysis for the subjective data . It is no surprise that the sentences that contain a more intense level of subjectivity can be easily classified as correct polarity.
In addition , contrary to our expectations , the application of the simple classification method ( NO chunking ) gets the higher results in comparison with the structural classification method ( YES chunking ) regardless of the use of contex-8 Fmeasure = 2*precision*recall/(precision+recall ) tual shifters . This phenomenon can be analyzed based on the limited length of reviews and the characteristics of online data . First , most sentences have a simple structure like the sequence of nouns or noun phrases due to restricted writing space . For this reason , the effect of chunking and contextual shifters on sentiment classification is insignificant . Second , the data includes various terms only seen on the Internet , vulgarisms and ungrammatical words . Furthermore , there are the problems of word spacing and spelling . Because of these drawbacks of online data , morphological analysis errors frequently occurred . The errors are further propagated to structures as a result of chunking . For this reason , when the chunking method is used , contextual shifters are ineffective at all as shown the results using the chunking method in Table 1.
4.3 Experiment 2: News articles
Subjectivity Extraction : The results of a 5-fold cross variation experiment of subjectivity extraction using SVMlight are described in Table 3. In this experiment , we use the commonly used statistical method TFIDF to compare total data with subjective data in the three groups in the subjectivity classification task . In conclusion , the chosen subjective data of all groups get higher results . Especially in the cases of news articles and subtopic news articles which are less subjective than editorial articles , Fmeasure value is greatly increased.
Table 2. Sentiment analysis of short movie review corpora
Method total subjective
Accuracy (%) F-measure8 (%) Accuracy Fmeasure
TFIDF 87.67 93.431 90.02 94.748
NO chunking NO shifter 87.676 93.432 90.034 94.757 NO chunking YES shifters 87.674 93.433 90.018 94.745 YES chunking NO shifter 83.212 90.835 87.29 93.214 YES chunking YES shifters 83.212 90.835 87.29 93.214 Method Data Accuracy (%) Fmeasure (%)
TFIDF
News articles
Total 63.032 28.532
Subjective 82.00 89.919
Subtopic News articles
Total 61.95 32.287
Subjective 73.332 84.44
Editorial articles
Total 57.53 73.04
Subjective 87.23 93.18
Table 3. Subjectivity extraction of news corpora analysis on the three groups of news data are summarized in Figure 3. The white points in Figure 3 are the values being larger than the baseline , the results using TFIDF.
First of all , all of our proposed classification methods get higher results than TFIDF , except in the case of Fmeasure of subjective News data.
This shows that using language-specific features which inflect the target language?s linguistic characteristics well , without complex mathematical measuring techniques , we could get better results than statistical methods in sentiment classification.
Secondly , similar to the result of movie review corpora , mostly subjective data shows greatly improved results in experimental methods overall . This means that our subjectivity extraction works successfully.
Finally , in contrast to the results of experiment 1, we get higher values of sentiment classification by using chunking and contextual shifters . This implies that the restriction on semantic scope of opinionated terms and the methods reducing features and properly modifying values of polarity terms by using contextual shifters also have merits in sentiment analysis of data such as news which has complex sentence structure like news . Furthermore , this tendency is noticeable particularly in the subjective data of all three groups . This confirms the effectiveness of utilizing linguistic methods in subjectivity extraction and sentiment analysis for news data which tries to maintain objectivity.
5 Discussion and Further Work
In this paper , we verified that simple measurements utilizing language-specific features can improve the results of sentiment analysis . Particularly the chunking method using morphological dependency relations and the lexicon which contains suffixes and particles having important functional meanings is expected to aid the sentiment analysis of other agglutinative languages such as Turkish and Japanese . In addition , this approach of sentiment analysis can be applied to various applications for extracting important information on the Internet to monitor a certain brand?s reputations or to make social network for peoples who have similar opinions.
We have plans to confirm the results of this paper by experiments on corpora which are expanded in size and type in future work . We will also increase the number of lexical items of subjectivity lexicon and polarity dictionary . Furthermore , we will utilize other linguistic information such as synonym lists of Korean ontology and elaborate measuring methods using lin-guistic-specific features of morphologically rich languages effectively.
Figure 3. Sentiment analysis of news corpora Choi , Y ., C . Cardie , E . Riloff , and S . Patwardhan.
2005. Identifying sources of opinions with conditional random fields and extraction patterns . In
Proceedings of the HLT/EMNLP.
Dave , K ., S . Lawrence , and D . M . Pennock . 2003.
Mining the peanut gallery : Opinion extraction and semantic classification of product reviews . In Proceedings of the WWW-2003.
Hu , Minqing , and Bing Liu . 2004. Mining and summarizingcustomer reviews . In Proceedings of the
KDD.
Kennedy , A ., and D . Inkpen . 2006. Sentiment Classification of Movie and Product Reviews Using Contextual Valence Shifters . Computational Intelligence , 22(2):110?125.
Kim , Mi-Yong , and Jong-Hyeok Lee . 2005. Syntactic Analysis based on Subject-Clause Segmentation.
In Proceedings of the KCC 2005, 32(9):936-947.
In Korean.
Kim , S . M ., and E . Hovy . 2004. Determining the sentiment of opinions . In Preceeding of the COLING.
Liu , Jingjing , and Stephanie Seneff . 2009. Review sentiment scoring via a parse-and-paraphrase paradigm . In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language
Processing , 1(1).
Mao , Y ., and G . Lebanon . 2006. Isotonic conditional random fields and local sentiment flow . In Proceedings of the NIPS.
McDonald , R ., K . Hannan , T . Neylon , M . Wells , and J . Reynar . 2007. Structured Models for Fine-to-Coarse Sentiment Analysis . In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , 432?439.
Meena , Arun , and T . V . Prabhakar . 2007. Sentence Level Sentiment Analysis in the Presence of Conjuncts Using Linguistic Analysis . Lecture Notes in
Computer Science , 573-580. Springer.
Nam , Sang-Hyub , Seung-Hoon Na , Yeha Lee , Yong-Hun Lee , Jungi Kim , and Jong-Hyeok Lee . 2008.
Semi-Supeervised Learning for Sentiment Phrase Extraction by Combining Generative Model and Discriminative Model . In Proceedings of the KCC(Korea Computer Congress ) 2008, 35(1):268-273. in Korean.
Pang , Bo , Lillian Lee , and Shivakumar Vaithyanathan . 2002. Thumbs up ? Sentiment classification using machine learning techniques . In Proceedings of the ACL2002 conference on Empirical methods in natural language processing , 10.
Pang , Bo , and Lillian Lee . 2004. A sentimental education : Sentiment analysis using subjectivity summarization based on minimum cuts . In Proceedings of the ACL2004.
Polanyi , Livia , and Annie Zaenen . 2004. Contextual valence shifters . In Proceedings of the AAAI Symposium on Exploring Attitude and Affect in Text:
Theories and Applications.
Ptaszynski , Michal , Pawel Dybala , Wenhan Shi , Rafal Rzepka , and Kenji Araki . 2010. Contextual affect analysis : a system for verification of emotion appropriateness supported with Contextual Valence Shifters . International Journal of
Biometrics , 2(2):134-154.
Quirk , R ., S . Greenbaum , G . Leech , and J . Svartvik.
1985. A Comprehensive Grammar of the English
Language . Longman , New York.
Riloff , Ellen , and Janyce Wiebe . 2003. Learning extraction patterns for subjective expressions . In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing , 105-112.
Tetsuya , Miyoshi , and Nakagami Yu . 2007. Sentiment classification of customer reviews on electric products . In Proceeding of the IEEE International Conference on Systems Man and Cybernetics , 2028-2033.
Turney , P . D . 2002. Thumbs up or thumbs down ? Semantic orientation applied to unsupervised classification of reviews . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics ( ACL'02), 417-424.
Wiebe , Janyce , Theresa Wilson , Rebecca Bruce , Matthew Bell , and Melanie Martin . 2004. Learning subjective language . Computational Linguistics , 30(3).
Wiebe , Janyce , and E . Riloff . 2005. Creating subjective and objective sentence classifiers from unannotated texts . In Proceedings of the CICLing 2005, 486-497.
Wilson , Theresa , Janyce Wiebe , and Paul Hoffmann.
2005. Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis . In Proceedings of the
HLT/EMNLP , 347-354.
Yu , H ., and Hatzivassiloglou V . 2003. Towards answering opinion questions : Separating facts from opinions and identifying the polarity of opinion sentences . In Proceedings of EMNLP , 32.
506
